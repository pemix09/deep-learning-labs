{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Sieć Neuronowa Od Podstaw w Pythonie**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Biblioteki**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/Coding/deep learning/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # algebra liniowa\n",
    "import matplotlib.pyplot as plt # używane do rysowania wykresów\n",
    "from sklearn.datasets import load_digits # importowanie zbioru danych\n",
    "from sklearn.model_selection import train_test_split # podział danych na część treningową i testową\n",
    "from sklearn.preprocessing import MinMaxScaler # normalizacja danych\n",
    "from sklearn.preprocessing import OneHotEncoder # kodowanie one-hot\n",
    "import optuna # do hiperparametryzacji\n",
    "import warnings # ignorowanie ostrzeżeń\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Klasa NeuralNetwork**\n",
    "Metoda forward przyjmuje dane wejściowe X i przepuszcza je przez sieć. Oblicza sumy ważone (z1, z2) i stosuje funkcję aktywacji (sigmoid lub softmax, w zależności od funkcji straty) do tych sum, aby uzyskać aktywacje (a1, a2).\n",
    "\n",
    "Dla warstwy ukrytej zawsze stosuje się funkcję aktywacji sigmoid. Dla warstwy wyjściowej używana jest funkcja softmax, jeśli funkcja straty to 'categorical_crossentropy', w przeciwnym przypadku używana jest funkcja sigmoidalna. Wybór między sigmoidą a softmaxem zależy od charakteru zadania (klasyfikacja binarna/wieloklasowa).\n",
    "\n",
    "Ta metoda zwraca końcowy wynik (a2) sieci, który można wykorzystać do przewidywań.\n",
    "\n",
    "Metoda backward implementuje algorytm wstecznej propagacji, który służy do aktualizacji wag i przesunięć w sieci na podstawie błędu między przewidywanym wyjściem a rzeczywistym wyjściem (y).\n",
    "\n",
    "Oblicza gradienty funkcji straty dla wag i przesunięć (dw2, db2, dw1, db1) przy użyciu reguły łańcuchowej. Gradienty wskazują, o ile wagi i przesunięcia muszą zostać dostosowane, aby zminimalizować błąd.\n",
    "\n",
    "Współczynnik uczenia (learning_rate) kontroluje, jak duży krok jest podejmowany podczas aktualizacji. Następnie metoda aktualizuje wagi i przesunięcia przez odjęcie iloczynu współczynnika uczenia i odpowiadających gradientów.\n",
    "\n",
    "Różne obliczenia gradientowe są wykonywane w zależności od wybranej funkcji straty, co ilustruje elastyczność sieci w dostosowywaniu się do różnych zadań.\n",
    "\n",
    "Funkcje aktywacji (metody sigmoid, sigmoid_derivative, softmax)\n",
    "sigmoid: Ta metoda implementuje funkcję aktywacji sigmoidalną, która zmniejsza wartości wejściowe do zakresu od 0 do 1. Jest szczególnie przydatna w problemach klasyfikacji binarnej.\n",
    "\n",
    "sigmoid_derivative: Oblicza pochodną funkcji sigmoidalnej, która jest używana podczas wstecznej propagacji do obliczania gradientów.\n",
    "\n",
    "softmax: Funkcja softmax jest stosowana w problemach klasyfikacji wieloklasowej. Przekształca wyniki z sieci na prawdopodobieństwa, pobierając wykładnik dla każdego wyjścia, a następnie normalizując te wartości, aby sumowały się do 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\"\n",
    "    Prosta sieć neuronowa z jedną warstwą ukrytą.\n",
    "\n",
    "    Parametry:\n",
    "    -----------\n",
    "    input_size: int\n",
    "        Liczba cech wejściowych\n",
    "    hidden_size: int\n",
    "        Liczba neuronów w warstwie ukrytej\n",
    "    output_size: int\n",
    "        Liczba neuronów w warstwie wyjściowej\n",
    "    loss_func: str\n",
    "        Funkcja straty do użycia. Opcje to 'mse' dla błędu średniokwadratowego, 'log_loss' dla straty logistycznej i 'categorical_crossentropy' dla krzyżowej entropii kategorycznej.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size, loss_func='mse'):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.loss_func = loss_func\n",
    "        \n",
    "        # Inicjalizacja wag i przesunięć\n",
    "        self.weights1 = np.random.randn(self.input_size, self.hidden_size)\n",
    "        self.bias1 = np.zeros((1, self.hidden_size))\n",
    "        self.weights2 = np.random.randn(self.hidden_size, self.output_size)\n",
    "        self.bias2 = np.zeros((1, self.output_size))\n",
    "\n",
    "        # Śledzenie straty\n",
    "        self.train_loss = []\n",
    "        self.test_loss = []\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Wyświetl architekturę sieci neuronowej.\n",
    "        \"\"\"\n",
    "        return f\"Układ Sieci Neuronowej:\\nWarstwa Wejściowa: {self.input_size} neuronów\\nWarstwa Ukryta: {self.hidden_size} neuronów\\nWarstwa Wyjściowa: {self.output_size} neuronów\\nFunkcja Straty: {self.loss_func}\"\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Przeprowadź propagację w przód.\n",
    "        \n",
    "        Parametry:\n",
    "        -----------\n",
    "        X: numpy array\n",
    "            Dane wejściowe\n",
    "        \n",
    "        Zwraca:\n",
    "        --------\n",
    "        numpy array\n",
    "            Przewidziane wyjście\n",
    "        \"\"\"\n",
    "        # Przeprowadź propagację w przód\n",
    "        self.z1 = np.dot(X, self.weights1) + self.bias1\n",
    "        self.a1 = self.sigmoid(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.weights2) + self.bias2\n",
    "        if self.loss_func == 'categorical_crossentropy':\n",
    "            self.a2 = self.softmax(self.z2)\n",
    "        else:\n",
    "            self.a2 = self.sigmoid(self.z2)\n",
    "        return self.a2\n",
    "    \n",
    "    def backward(self, X, y, learning_rate):\n",
    "        \"\"\"\n",
    "        Przeprowadź propagację wsteczną.\n",
    "\n",
    "        Parametry:\n",
    "        -----------\n",
    "        X: numpy array\n",
    "            Dane wejściowe\n",
    "        y: numpy array\n",
    "            Docelowe wyjście\n",
    "        learning_rate: float\n",
    "            Współczynnik uczenia\n",
    "        \"\"\"\n",
    "        # Przeprowadź propagację wsteczną\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        # Oblicz gradienty\n",
    "        if self.loss_func == 'mse':\n",
    "            self.dz2 = self.a2 - y\n",
    "        elif self.loss_func == 'log_loss':\n",
    "            self.dz2 = -(y/self.a2 - (1-y)/(1-self.a2))\n",
    "        elif self.loss_func == 'categorical_crossentropy':\n",
    "            self.dz2 = self.a2 - y\n",
    "        else:\n",
    "            raise ValueError('Nieprawidłowa funkcja straty')\n",
    "        \n",
    "        self.dw2 = (1 / m) * np.dot(self.a1.T, self.dz2)\n",
    "        self.db2 = (1 / m) * np.sum(self.dz2, axis=0)\n",
    "        self.dz1 = np.dot(self.dz2, self.weights2.T) * self.sigmoid_derivative(self.a1)\n",
    "        self.dw1 = (1 / m) * np.dot(X.T, self.dz1)\n",
    "        self.db1 = (1 / m) * np.sum(self.dz1, axis=0)\n",
    "        \n",
    "        # Zaktualizuj wagi i przesunięcia\n",
    "        self.weights2 -= learning_rate * self.dw2\n",
    "        self.bias2 -= learning_rate * self.db2\n",
    "        self.weights1 -= learning_rate * self.dw1\n",
    "        self.bias1 -= learning_rate * self.db1\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        Funkcja aktywacji sigmoidalna.\n",
    "        \n",
    "        Parametry:\n",
    "        -----------\n",
    "        x: numpy array\n",
    "            Dane wejściowe\n",
    "        \n",
    "        Zwraca:\n",
    "        --------\n",
    "        numpy array\n",
    "            Wynik funkcji sigmoidalnej\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        \"\"\"\n",
    "        Pochodna funkcji aktywacji sigmoidalnej.\n",
    "\n",
    "        Parametry:\n",
    "        -----------\n",
    "        x: numpy array\n",
    "            Dane wejściowe\n",
    "        \n",
    "        Zwraca:\n",
    "        --------\n",
    "        numpy array\n",
    "            Wynik pochodnej funkcji sigmoidalnej\n",
    "        \"\"\"\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        \"\"\"\n",
    "        Funkcja aktywacji softmax.\n",
    "\n",
    "        Parametry:\n",
    "        -----------\n",
    "        x: numpy array\n",
    "            Dane wejściowe\n",
    "        \n",
    "        Zwraca:\n",
    "        --------\n",
    "        numpy array\n",
    "            Wynik funkcji softmax\n",
    "        \"\"\"\n",
    "        exps = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exps/np.sum(exps, axis=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Trainer Class**\n",
    "Inicjalizuje listy train_loss i test_loss w celu śledzenia wartości strat podczas fazy treningu i testowania, umożliwiając monitorowanie wydajności modelu w czasie.\n",
    "\n",
    "Obliczanie straty (metoda calculate_loss)\n",
    "Ta metoda oblicza stratę pomiędzy przewidywanymi wynikami (y_pred) a prawdziwymi wynikami (y_true), korzystając z określonej funkcji straty. Jest to kluczowe dla oceny wydajności modelu i do przeprowadzania wstecznej propagacji.\n",
    "\n",
    "Metoda obsługuje trzy rodzaje funkcji straty:\n",
    "\n",
    "Mean Squared Error (‘mse’): Stosowane w zadaniach regresji, oblicza średnią kwadratów różnic między przewidywanymi a prawdziwymi wartościami.\n",
    "\n",
    "Logistic Loss (‘log_loss’): Odpowiednie dla problemów klasyfikacji binarnej, oblicza stratę za pomocą metody log-wiarygodności.\n",
    "\n",
    "Categorical Crossentropy (‘categorical_crossentropy’): Idealne do zadań klasyfikacji wieloklasowej, mierzy rozbieżność między prawdziwymi etykietami a przewidywaniami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \"\"\"\n",
    "    Klasa do trenowania sieci neuronowej.\n",
    "\n",
    "    Parametry:\n",
    "    -----------\n",
    "    model: NeuralNetwork\n",
    "        Model sieci neuronowej do trenowania\n",
    "    loss_func: str\n",
    "        Funkcja straty do użycia. Opcje to 'mse' dla błędu średniokwadratowego, 'log_loss' dla straty logistycznej, i 'categorical_crossentropy' dla krzyżowej entropii kategorycznej.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, loss_func='mse'):\n",
    "        self.model = model\n",
    "        self.loss_func = loss_func\n",
    "        self.train_loss = []\n",
    "        self.test_loss = []\n",
    "\n",
    "    def calculate_loss(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Oblicz stratę.\n",
    "\n",
    "        Parametry:\n",
    "        -----------\n",
    "        y_true: numpy array\n",
    "            Prawdziwe wyjście\n",
    "        y_pred: numpy array\n",
    "            Przewidziane wyjście\n",
    "        \n",
    "        Zwraca:\n",
    "        --------\n",
    "        float\n",
    "            Strata\n",
    "        \"\"\"\n",
    "        if self.loss_func == 'mse':\n",
    "            return np.mean((y_pred - y_true)**2)\n",
    "        elif self.loss_func == 'log_loss':\n",
    "            return -np.mean(y_true*np.log(y_pred) + (1-y_true)*np.log(1-y_pred))\n",
    "        elif self.loss_func == 'categorical_crossentropy':\n",
    "            return -np.mean(y_true*np.log(y_pred))\n",
    "        else:\n",
    "            raise ValueError('Nieprawidłowa funkcja straty')\n",
    "\n",
    "    def train(self, X_train, y_train, X_test, y_test, epochs, learning_rate):\n",
    "        \"\"\"\n",
    "        Trenuj sieć neuronową.\n",
    "\n",
    "        Parametry:\n",
    "        -----------\n",
    "        X_train: numpy array\n",
    "            Dane wejściowe treningowe\n",
    "        y_train: numpy array\n",
    "            Docelowe wyjście treningowe\n",
    "        X_test: numpy array\n",
    "            Dane wejściowe testowe\n",
    "        y_test: numpy array\n",
    "            Docelowe wyjście testowe\n",
    "        epochs: int\n",
    "            Liczba epok trenowania modelu\n",
    "        learning_rate: float\n",
    "            Współczynnik uczenia\n",
    "        \"\"\"\n",
    "        for _ in range(epochs):\n",
    "            self.model.forward(X_train)\n",
    "            self.model.backward(X_train, y_train, learning_rate)\n",
    "            train_loss = self.calculate_loss(y_train, self.model.a2)\n",
    "            self.train_loss.append(train_loss)\n",
    "            \n",
    "            self.model.forward(X_test)\n",
    "            test_loss = self.calculate_loss(y_test, self.model.a2)\n",
    "            self.test_loss.append(test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Metoda train zarządza procesem uczenia przez określoną liczbę epok, korzystając z danych treningowych (X_train, y_train) i testowych (X_test, y_test). Przyjmuje również parametr learning_rate, który wpływa na wielkość kroku w aktualizacji parametrów podczas wstecznej propagacji.\n",
    "\n",
    "Dla każdej epoki (cyklu treningowego) metoda wykonuje następujące kroki:\n",
    "\n",
    "1. Przejście W Przód na Danych Treningowych: Wykorzystuje metodę forward modelu do obliczenia przewidywanych wyników dla danych treningowych.\n",
    "\n",
    "2. Wsteczne Przejście (Aktualizacja Parametrów): Stosuje metodę backward modelu, wykorzystując dane treningowe i etykiety (y_train), oraz learning_rate do aktualizacji wag i przesunięć modelu na podstawie obliczonych gradientów z straty.\n",
    "\n",
    "3. Obliczenie Straty Treningowej: Strata treningowa jest obliczana przy użyciu metody calculate_loss z etykietami treningowymi i przewidywaniami. Następnie ta strata jest dodawana do listy train_loss w celu monitorowania.\n",
    "\n",
    "4. Przejście W Przód na Danych Testowych: Podobnie, metoda oblicza przewidywania dla danych testowych, aby ocenić wydajność modelu na danych niewidzianych podczas uczenia.\n",
    "\n",
    "5. Obliczenie Straty Testowej: Oblicza stratę testową przy użyciu etykiet testowych i przewidywań, dodając tę stratę do listy test_loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Wczytywanie danych**\n",
    "Zestaw danych używany tutaj to zestaw danych cyfr, który jest powszechnie stosowany do zadań klasyfikacji polegających na rozpoznawaniu ręcznie pisanych cyfr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Wczytaj zbiór danych dotyczący cyfr\n",
    "cyfry = load_digits()\n",
    "\n",
    "# Wyświetl pierwsze 10 obrazków\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(10):\n",
    "    axes[i].imshow(cyfry.images[i], cmap='gray')\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f\"Etykieta: {cyfry.target[i]}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Przetwarzanie danych**\n",
    "Cechy zbioru danych są przeskalowane do zakresu od 0 do 1 za pomocą MinMaxScaler. Jest to powszechne przetwarzanie wstępne mające na celu zapewnienie, że wszystkie cechy wejściowe mają tę samą skalę, co może pomóc sieci neuronowej w skuteczniejszym uczeniu się.\n",
    "\n",
    "Przeskalowane cechy są przechowywane w X, a etykiety docelowe (określające, jaką cyfrę reprezentuje każde zdjęcie) są przechowywane w y.\n",
    "Ponieważ to zadanie klasyfikacji obejmuje wiele klas, etykiety docelowe są kodowane jednohotowkowo za pomocą OneHotEncoder. Kodowanie jednohotowkowe przekształca kategoryczne dane docelowe w format, który jest łatwiejszy do zrozumienia i pracy przez sieci neuronowe, zwłaszcza w przypadku zadań klasyfikacji.\n",
    "\n",
    "Zestaw danych jest dzielony na zbiory treningowy i testowy za pomocą funkcji train_test_split, gdzie 80% danych jest używanych do treningu, a 20% do testów. Taki podział pozwala na trening modelu na jednej części danych, a następnie ocenę jego wydajności na oddzielnej, niewidocznej części, aby sprawdzić, jak dobrze generalizuje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przetwórz zbiór danych\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(cyfry.data)\n",
    "y = cyfry.target\n",
    "\n",
    "# Dokonaj kodowania one-hot dla danych wyjściowych\n",
    "koder = OneHotEncoder()\n",
    "y_jednokodowane = koder.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Podziel zbiór danych na zestawy treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_jednokodowane, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Stworzenie SSN**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Układ Sieci Neuronowej:\n",
      "Warstwa Wejściowa: 64 neuronów\n",
      "Warstwa Ukryta: 64 neuronów\n",
      "Warstwa Wyjściowa: 10 neuronów\n",
      "Funkcja Straty: categorical_crossentropy\n"
     ]
    }
   ],
   "source": [
    "# Utwórz instancję klasy NeuralNetwork\n",
    "rozmiar_wejscia = X.shape[1]\n",
    "rozmiar_warstwy_ukrytej = 64\n",
    "rozmiar_wyjscia = len(np.unique(y))\n",
    "funkcja_straty = 'categorical_crossentropy'\n",
    "epoki = 1000\n",
    "wspolczynnik_uczenia = 0.1\n",
    "\n",
    "nn = NeuralNetwork(rozmiar_wejscia, rozmiar_warstwy_ukrytej, rozmiar_wyjscia, funkcja_straty)\n",
    "\n",
    "# Wyświetl architekturę sieci neuronowej\n",
    "print(nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Trening SSN**\n",
    "\n",
    "Po przeprowadzeniu treningu wydajność modelu jest oceniana na zbiorze testowym. Ponieważ cele zostały zakodowane na gorąco, funkcja np.argmax jest używana do przekształcenia zakodowanych na gorąco przewidywań z powrotem na postać etykiet. Dokładność modelu jest obliczana poprzez porównanie tych przewidywanych etykiet z rzeczywistymi etykietami (etykiety_y_test), a następnie wypisana.\n",
    "\n",
    "Teraz ten kod brakuje kilku funkcji aktywacji, o których rozmawialiśmy, usprawnień takich jak SGD lub optymalizator Adam, i nie tylko. Pozostawiam to Tobie, abyś mógł uzupełnić luki swoim kodem. W ten sposób naprawdę opanujesz sieci neuronowe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1437,64) and (1437,64) not aligned: 64 (dim 1) != 1437 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m trener \u001b[38;5;241m=\u001b[39m Trainer(nn, funkcja_straty)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoki\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwspolczynnik_uczenia\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Przekonwertuj y_test z kodowania one-hot na etykiety\u001b[39;00m\n\u001b[1;32m      5\u001b[0m etykiety_y_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_test, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 64\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, X_train, y_train, X_test, y_test, epochs, learning_rate)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mforward(X_train)\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_loss(y_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39ma2)\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[13], line 90\u001b[0m, in \u001b[0;36mNeuralNetwork.backward\u001b[0;34m(self, X, y, learning_rate)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdw2 \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m m) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma1\u001b[38;5;241m.\u001b[39mT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdz2)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb2 \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m m) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdz2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdz1 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdz2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid_derivative\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ma1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdw1 \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m m) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X\u001b[38;5;241m.\u001b[39mT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdz1)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb1 \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m m) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdz1, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Coding/deep learning/.venv/lib/python3.12/site-packages/numpy/matrixlib/defmatrix.py:219\u001b[0m, in \u001b[0;36mmatrix.__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__mul__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, (N\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) :\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;66;03m# This promotes 1-D vectors to row vectors\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masmatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isscalar(other) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(other, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__rmul__\u001b[39m\u001b[38;5;124m'\u001b[39m) :\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m N\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m, other)\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (1437,64) and (1437,64) not aligned: 64 (dim 1) != 1437 (dim 0)"
     ]
    }
   ],
   "source": [
    "trener = Trainer(nn, funkcja_straty)\n",
    "trener.train(X_train, y_train, X_test, y_test, epoki, wspolczynnik_uczenia)\n",
    "\n",
    "# Przekonwertuj y_test z kodowania one-hot na etykiety\n",
    "etykiety_y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Oceń wydajność sieci neuronowej\n",
    "prognozy = np.argmax(nn.forward(X_test), axis=1)\n",
    "dokladnosc = np.mean(prognozy == etykiety_y_test)\n",
    "print(f\"Dokładność: {dokladnosc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Plot Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trener.train_loss, label='Strata na zbiorze treningowym')\n",
    "plt.plot(trener.test_loss, label='Strata na zbiorze testowym')\n",
    "plt.title('Strata na zbiorze treningowym i testowym')\n",
    "plt.xlabel('Epoki')\n",
    "plt.ylabel('Strata')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Fine-Tune SSN !!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-05 10:17:09,928] A new study created in memory with name: nn_study\n",
      "[I 2024-04-05 10:18:10,776] Trial 0 finished with value: 0.3861111111111111 and parameters: {'hidden_size': 98, 'learning_rate': 0.0005540564999109057, 'epochs': 9785}. Best is trial 0 with value: 0.3861111111111111.\n",
      "[I 2024-04-05 10:18:19,119] Trial 1 finished with value: 0.03888888888888889 and parameters: {'hidden_size': 49, 'learning_rate': 0.00013337602615959065, 'epochs': 2282}. Best is trial 0 with value: 0.3861111111111111.\n",
      "[I 2024-04-05 10:18:22,387] Trial 2 finished with value: 0.825 and parameters: {'hidden_size': 95, 'learning_rate': 0.04022409158733184, 'epochs': 888}. Best is trial 2 with value: 0.825.\n",
      "[I 2024-04-05 10:18:24,282] Trial 3 finished with value: 0.09444444444444444 and parameters: {'hidden_size': 97, 'learning_rate': 0.0006415072681855609, 'epochs': 618}. Best is trial 2 with value: 0.825.\n",
      "[I 2024-04-05 10:18:48,054] Trial 4 finished with value: 0.7888888888888889 and parameters: {'hidden_size': 127, 'learning_rate': 0.0028046281252030124, 'epochs': 7410}. Best is trial 2 with value: 0.825.\n",
      "[I 2024-04-05 10:19:39,805] Trial 5 finished with value: 0.39166666666666666 and parameters: {'hidden_size': 94, 'learning_rate': 0.0006137868548493884, 'epochs': 9709}. Best is trial 2 with value: 0.825.\n",
      "[I 2024-04-05 10:19:58,455] Trial 6 finished with value: 0.4444444444444444 and parameters: {'hidden_size': 119, 'learning_rate': 0.0012390211044731895, 'epochs': 6337}. Best is trial 2 with value: 0.825.\n",
      "[I 2024-04-05 10:20:02,738] Trial 7 finished with value: 0.875 and parameters: {'hidden_size': 122, 'learning_rate': 0.030748461145928312, 'epochs': 1545}. Best is trial 7 with value: 0.875.\n",
      "[I 2024-04-05 10:20:29,844] Trial 8 finished with value: 0.9527777777777777 and parameters: {'hidden_size': 72, 'learning_rate': 0.016454642621342632, 'epochs': 8877}. Best is trial 8 with value: 0.9527777777777777.\n",
      "[I 2024-04-05 10:20:46,989] Trial 9 finished with value: 0.3 and parameters: {'hidden_size': 91, 'learning_rate': 0.0008108801492155336, 'epochs': 4959}. Best is trial 8 with value: 0.9527777777777777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze badanie: {'hidden_size': 72, 'learning_rate': 0.016454642621342632, 'epochs': 8877}\n",
      "Najlepsza wartość: 0.9527777777777777\n"
     ]
    }
   ],
   "source": [
    "def cel(trial):\n",
    "    # Definiuj hiperparametry\n",
    "    hidden_size = trial.suggest_int('hidden_size', 32, 128)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n",
    "    epochs = trial.suggest_int('epochs', 500, 10000)\n",
    "\n",
    "    # Twórz i trenuj sieć neuronową\n",
    "    nn = NeuralNetwork(rozmiar_wejscia, rozmiar_warstwy_ukrytej, rozmiar_wyjscia, funkcja_straty)\n",
    "    trener = Trainer(nn, funkcja_straty)\n",
    "    trener.train(X_train, y_train, X_test, y_test, epochs, learning_rate)\n",
    "\n",
    "    # Oceniaj wydajność sieci neuronowej\n",
    "    prognozy = np.argmax(nn.forward(X_test), axis=1)\n",
    "    dokładność = np.mean(prognozy == etykiety_y_test)\n",
    "\n",
    "    return dokładność\n",
    "\n",
    "# Twórz obiekt badania i optymalizuj funkcję celu\n",
    "badanie = optuna.create_study(study_name='nn_study', direction='maximize')\n",
    "badanie.optimize(cel, n_trials=10)\n",
    "\n",
    "# Drukuj najlepsze hiperparametry\n",
    "print(f\"Najlepsze badanie: {badanie.best_trial.params}\")\n",
    "print(f\"Najlepsza wartość: {badanie.best_trial.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Prognoza**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsza dokładność: 94.44%\n"
     ]
    }
   ],
   "source": [
    "best_nn = NeuralNetwork(rozmiar_wejscia, badanie.best_trial.params['hidden_size'], rozmiar_wyjscia, funkcja_straty)\n",
    "best_trainer = Trainer(best_nn, funkcja_straty)\n",
    "best_trainer.train(X_train, y_train, X_test, y_test, badanie.best_trial.params['epochs'], badanie.best_trial.params['learning_rate'])\n",
    "\n",
    "# Oceń wydajność najlepszej sieci neuronowej\n",
    "predictions = np.argmax(best_nn.forward(X_test), axis=1)\n",
    "accuracy = np.mean(predictions == etykiety_y_test)\n",
    "print(f\"Najlepsza dokładność: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **To samo w TensorFlow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# Wczytaj zbiór danych cyfr\n",
    "digits = load_digits()\n",
    "\n",
    "# Przeskaluj cechy do zakresu od 0 do 1\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(digits.data)\n",
    "\n",
    "# Zakoduj etykiety docelowe w formacie \"one-hot\"\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_onehot = encoder.fit_transform(digits.target.reshape(-1, 1))\n",
    "\n",
    "# Podziel zbiór danych na zestawy treningowe i testowe\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_onehot, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Definija sieci**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zdefiniuj architekturę modelu\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(len(np.unique(digits.target)), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Skompiluj model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skompiluj model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Trening modelu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "45/45 - 1s - loss: 1.9596 - accuracy: 0.4468 - val_loss: 1.6840 - val_accuracy: 0.6889 - 627ms/epoch - 14ms/step\n",
      "Epoch 2/1000\n",
      "45/45 - 0s - loss: 1.4010 - accuracy: 0.8107 - val_loss: 1.1302 - val_accuracy: 0.8528 - 82ms/epoch - 2ms/step\n",
      "Epoch 3/1000\n",
      "45/45 - 0s - loss: 0.9541 - accuracy: 0.8720 - val_loss: 0.7645 - val_accuracy: 0.9056 - 65ms/epoch - 1ms/step\n",
      "Epoch 4/1000\n",
      "45/45 - 0s - loss: 0.6632 - accuracy: 0.9179 - val_loss: 0.5458 - val_accuracy: 0.9056 - 58ms/epoch - 1ms/step\n",
      "Epoch 5/1000\n",
      "45/45 - 0s - loss: 0.4941 - accuracy: 0.9241 - val_loss: 0.4210 - val_accuracy: 0.9222 - 59ms/epoch - 1ms/step\n",
      "Epoch 6/1000\n",
      "45/45 - 0s - loss: 0.3966 - accuracy: 0.9374 - val_loss: 0.3466 - val_accuracy: 0.9250 - 56ms/epoch - 1ms/step\n",
      "Epoch 7/1000\n",
      "45/45 - 0s - loss: 0.3235 - accuracy: 0.9436 - val_loss: 0.2927 - val_accuracy: 0.9194 - 65ms/epoch - 1ms/step\n",
      "Epoch 8/1000\n",
      "45/45 - 0s - loss: 0.2786 - accuracy: 0.9485 - val_loss: 0.2573 - val_accuracy: 0.9361 - 57ms/epoch - 1ms/step\n",
      "Epoch 9/1000\n",
      "45/45 - 0s - loss: 0.2424 - accuracy: 0.9569 - val_loss: 0.2232 - val_accuracy: 0.9417 - 59ms/epoch - 1ms/step\n",
      "Epoch 10/1000\n",
      "45/45 - 0s - loss: 0.2183 - accuracy: 0.9569 - val_loss: 0.2049 - val_accuracy: 0.9500 - 55ms/epoch - 1ms/step\n",
      "Epoch 11/1000\n",
      "45/45 - 0s - loss: 0.1964 - accuracy: 0.9617 - val_loss: 0.1908 - val_accuracy: 0.9472 - 58ms/epoch - 1ms/step\n",
      "Epoch 12/1000\n",
      "45/45 - 0s - loss: 0.1833 - accuracy: 0.9659 - val_loss: 0.1804 - val_accuracy: 0.9472 - 99ms/epoch - 2ms/step\n",
      "Epoch 13/1000\n",
      "45/45 - 0s - loss: 0.1673 - accuracy: 0.9715 - val_loss: 0.1675 - val_accuracy: 0.9583 - 66ms/epoch - 1ms/step\n",
      "Epoch 14/1000\n",
      "45/45 - 0s - loss: 0.1550 - accuracy: 0.9708 - val_loss: 0.1576 - val_accuracy: 0.9611 - 67ms/epoch - 1ms/step\n",
      "Epoch 15/1000\n",
      "45/45 - 0s - loss: 0.1453 - accuracy: 0.9722 - val_loss: 0.1494 - val_accuracy: 0.9583 - 66ms/epoch - 1ms/step\n",
      "Epoch 16/1000\n",
      "45/45 - 0s - loss: 0.1369 - accuracy: 0.9763 - val_loss: 0.1428 - val_accuracy: 0.9639 - 69ms/epoch - 2ms/step\n",
      "Epoch 17/1000\n",
      "45/45 - 0s - loss: 0.1267 - accuracy: 0.9798 - val_loss: 0.1367 - val_accuracy: 0.9611 - 58ms/epoch - 1ms/step\n",
      "Epoch 18/1000\n",
      "45/45 - 0s - loss: 0.1185 - accuracy: 0.9784 - val_loss: 0.1300 - val_accuracy: 0.9667 - 55ms/epoch - 1ms/step\n",
      "Epoch 19/1000\n",
      "45/45 - 0s - loss: 0.1146 - accuracy: 0.9819 - val_loss: 0.1253 - val_accuracy: 0.9694 - 56ms/epoch - 1ms/step\n",
      "Epoch 20/1000\n",
      "45/45 - 0s - loss: 0.1074 - accuracy: 0.9819 - val_loss: 0.1224 - val_accuracy: 0.9694 - 55ms/epoch - 1ms/step\n",
      "Epoch 21/1000\n",
      "45/45 - 0s - loss: 0.1023 - accuracy: 0.9826 - val_loss: 0.1209 - val_accuracy: 0.9639 - 59ms/epoch - 1ms/step\n",
      "Epoch 22/1000\n",
      "45/45 - 0s - loss: 0.0964 - accuracy: 0.9861 - val_loss: 0.1161 - val_accuracy: 0.9667 - 60ms/epoch - 1ms/step\n",
      "Epoch 23/1000\n",
      "45/45 - 0s - loss: 0.0928 - accuracy: 0.9840 - val_loss: 0.1138 - val_accuracy: 0.9722 - 101ms/epoch - 2ms/step\n",
      "Epoch 24/1000\n",
      "45/45 - 0s - loss: 0.0887 - accuracy: 0.9861 - val_loss: 0.1116 - val_accuracy: 0.9722 - 69ms/epoch - 2ms/step\n",
      "Epoch 25/1000\n",
      "45/45 - 0s - loss: 0.0847 - accuracy: 0.9868 - val_loss: 0.1096 - val_accuracy: 0.9722 - 63ms/epoch - 1ms/step\n",
      "Epoch 26/1000\n",
      "45/45 - 0s - loss: 0.0800 - accuracy: 0.9875 - val_loss: 0.1074 - val_accuracy: 0.9722 - 64ms/epoch - 1ms/step\n",
      "Epoch 27/1000\n",
      "45/45 - 0s - loss: 0.0752 - accuracy: 0.9889 - val_loss: 0.1060 - val_accuracy: 0.9750 - 69ms/epoch - 2ms/step\n",
      "Epoch 28/1000\n",
      "45/45 - 0s - loss: 0.0725 - accuracy: 0.9875 - val_loss: 0.1047 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 29/1000\n",
      "45/45 - 0s - loss: 0.0685 - accuracy: 0.9896 - val_loss: 0.1031 - val_accuracy: 0.9778 - 60ms/epoch - 1ms/step\n",
      "Epoch 30/1000\n",
      "45/45 - 0s - loss: 0.0658 - accuracy: 0.9896 - val_loss: 0.1015 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 31/1000\n",
      "45/45 - 0s - loss: 0.0636 - accuracy: 0.9910 - val_loss: 0.1007 - val_accuracy: 0.9750 - 65ms/epoch - 1ms/step\n",
      "Epoch 32/1000\n",
      "45/45 - 0s - loss: 0.0612 - accuracy: 0.9923 - val_loss: 0.0996 - val_accuracy: 0.9722 - 64ms/epoch - 1ms/step\n",
      "Epoch 33/1000\n",
      "45/45 - 0s - loss: 0.0577 - accuracy: 0.9916 - val_loss: 0.0982 - val_accuracy: 0.9778 - 109ms/epoch - 2ms/step\n",
      "Epoch 34/1000\n",
      "45/45 - 0s - loss: 0.0563 - accuracy: 0.9930 - val_loss: 0.0983 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 35/1000\n",
      "45/45 - 0s - loss: 0.0529 - accuracy: 0.9923 - val_loss: 0.0965 - val_accuracy: 0.9778 - 64ms/epoch - 1ms/step\n",
      "Epoch 36/1000\n",
      "45/45 - 0s - loss: 0.0506 - accuracy: 0.9923 - val_loss: 0.0973 - val_accuracy: 0.9722 - 64ms/epoch - 1ms/step\n",
      "Epoch 37/1000\n",
      "45/45 - 0s - loss: 0.0499 - accuracy: 0.9930 - val_loss: 0.0977 - val_accuracy: 0.9778 - 70ms/epoch - 2ms/step\n",
      "Epoch 38/1000\n",
      "45/45 - 0s - loss: 0.0482 - accuracy: 0.9923 - val_loss: 0.0940 - val_accuracy: 0.9750 - 65ms/epoch - 1ms/step\n",
      "Epoch 39/1000\n",
      "45/45 - 0s - loss: 0.0456 - accuracy: 0.9951 - val_loss: 0.0941 - val_accuracy: 0.9778 - 59ms/epoch - 1ms/step\n",
      "Epoch 40/1000\n",
      "45/45 - 0s - loss: 0.0441 - accuracy: 0.9930 - val_loss: 0.0933 - val_accuracy: 0.9722 - 61ms/epoch - 1ms/step\n",
      "Epoch 41/1000\n",
      "45/45 - 0s - loss: 0.0423 - accuracy: 0.9958 - val_loss: 0.0943 - val_accuracy: 0.9722 - 55ms/epoch - 1ms/step\n",
      "Epoch 42/1000\n",
      "45/45 - 0s - loss: 0.0407 - accuracy: 0.9951 - val_loss: 0.0929 - val_accuracy: 0.9722 - 95ms/epoch - 2ms/step\n",
      "Epoch 43/1000\n",
      "45/45 - 0s - loss: 0.0388 - accuracy: 0.9958 - val_loss: 0.0920 - val_accuracy: 0.9750 - 70ms/epoch - 2ms/step\n",
      "Epoch 44/1000\n",
      "45/45 - 0s - loss: 0.0370 - accuracy: 0.9965 - val_loss: 0.0923 - val_accuracy: 0.9750 - 63ms/epoch - 1ms/step\n",
      "Epoch 45/1000\n",
      "45/45 - 0s - loss: 0.0357 - accuracy: 0.9958 - val_loss: 0.0908 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 46/1000\n",
      "45/45 - 0s - loss: 0.0345 - accuracy: 0.9958 - val_loss: 0.0915 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 47/1000\n",
      "45/45 - 0s - loss: 0.0337 - accuracy: 0.9958 - val_loss: 0.0915 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 48/1000\n",
      "45/45 - 0s - loss: 0.0317 - accuracy: 0.9965 - val_loss: 0.0913 - val_accuracy: 0.9722 - 82ms/epoch - 2ms/step\n",
      "Epoch 49/1000\n",
      "45/45 - 0s - loss: 0.0309 - accuracy: 0.9972 - val_loss: 0.0906 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 50/1000\n",
      "45/45 - 0s - loss: 0.0303 - accuracy: 0.9972 - val_loss: 0.0907 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 51/1000\n",
      "45/45 - 0s - loss: 0.0293 - accuracy: 0.9972 - val_loss: 0.0913 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 52/1000\n",
      "45/45 - 0s - loss: 0.0279 - accuracy: 0.9972 - val_loss: 0.0921 - val_accuracy: 0.9722 - 62ms/epoch - 1ms/step\n",
      "Epoch 53/1000\n",
      "45/45 - 0s - loss: 0.0277 - accuracy: 0.9972 - val_loss: 0.0923 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 54/1000\n",
      "45/45 - 0s - loss: 0.0266 - accuracy: 0.9958 - val_loss: 0.0915 - val_accuracy: 0.9778 - 63ms/epoch - 1ms/step\n",
      "Epoch 55/1000\n",
      "45/45 - 0s - loss: 0.0254 - accuracy: 0.9979 - val_loss: 0.0911 - val_accuracy: 0.9750 - 55ms/epoch - 1ms/step\n",
      "Epoch 56/1000\n",
      "45/45 - 0s - loss: 0.0243 - accuracy: 0.9979 - val_loss: 0.0898 - val_accuracy: 0.9750 - 63ms/epoch - 1ms/step\n",
      "Epoch 57/1000\n",
      "45/45 - 0s - loss: 0.0242 - accuracy: 0.9972 - val_loss: 0.0901 - val_accuracy: 0.9778 - 58ms/epoch - 1ms/step\n",
      "Epoch 58/1000\n",
      "45/45 - 0s - loss: 0.0224 - accuracy: 0.9979 - val_loss: 0.0919 - val_accuracy: 0.9750 - 112ms/epoch - 2ms/step\n",
      "Epoch 59/1000\n",
      "45/45 - 0s - loss: 0.0230 - accuracy: 0.9972 - val_loss: 0.0942 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 60/1000\n",
      "45/45 - 0s - loss: 0.0210 - accuracy: 0.9979 - val_loss: 0.0902 - val_accuracy: 0.9778 - 62ms/epoch - 1ms/step\n",
      "Epoch 61/1000\n",
      "45/45 - 0s - loss: 0.0205 - accuracy: 0.9979 - val_loss: 0.0892 - val_accuracy: 0.9722 - 57ms/epoch - 1ms/step\n",
      "Epoch 62/1000\n",
      "45/45 - 0s - loss: 0.0207 - accuracy: 0.9979 - val_loss: 0.0916 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 63/1000\n",
      "45/45 - 0s - loss: 0.0196 - accuracy: 0.9979 - val_loss: 0.0898 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 64/1000\n",
      "45/45 - 0s - loss: 0.0183 - accuracy: 0.9979 - val_loss: 0.0899 - val_accuracy: 0.9778 - 67ms/epoch - 1ms/step\n",
      "Epoch 65/1000\n",
      "45/45 - 0s - loss: 0.0180 - accuracy: 0.9986 - val_loss: 0.0900 - val_accuracy: 0.9778 - 98ms/epoch - 2ms/step\n",
      "Epoch 66/1000\n",
      "45/45 - 0s - loss: 0.0169 - accuracy: 0.9979 - val_loss: 0.0911 - val_accuracy: 0.9722 - 66ms/epoch - 1ms/step\n",
      "Epoch 67/1000\n",
      "45/45 - 0s - loss: 0.0179 - accuracy: 0.9979 - val_loss: 0.0908 - val_accuracy: 0.9778 - 63ms/epoch - 1ms/step\n",
      "Epoch 68/1000\n",
      "45/45 - 0s - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.0908 - val_accuracy: 0.9778 - 57ms/epoch - 1ms/step\n",
      "Epoch 69/1000\n",
      "45/45 - 0s - loss: 0.0161 - accuracy: 0.9993 - val_loss: 0.0905 - val_accuracy: 0.9778 - 63ms/epoch - 1ms/step\n",
      "Epoch 70/1000\n",
      "45/45 - 0s - loss: 0.0151 - accuracy: 0.9993 - val_loss: 0.0909 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 71/1000\n",
      "45/45 - 0s - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 72/1000\n",
      "45/45 - 0s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0912 - val_accuracy: 0.9778 - 58ms/epoch - 1ms/step\n",
      "Epoch 73/1000\n",
      "45/45 - 0s - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0914 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 74/1000\n",
      "45/45 - 0s - loss: 0.0135 - accuracy: 0.9993 - val_loss: 0.0908 - val_accuracy: 0.9750 - 106ms/epoch - 2ms/step\n",
      "Epoch 75/1000\n",
      "45/45 - 0s - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.0906 - val_accuracy: 0.9750 - 66ms/epoch - 1ms/step\n",
      "Epoch 76/1000\n",
      "45/45 - 0s - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0910 - val_accuracy: 0.9750 - 77ms/epoch - 2ms/step\n",
      "Epoch 77/1000\n",
      "45/45 - 0s - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0910 - val_accuracy: 0.9722 - 59ms/epoch - 1ms/step\n",
      "Epoch 78/1000\n",
      "45/45 - 0s - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 79/1000\n",
      "45/45 - 0s - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0925 - val_accuracy: 0.9722 - 58ms/epoch - 1ms/step\n",
      "Epoch 80/1000\n",
      "45/45 - 0s - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0914 - val_accuracy: 0.9778 - 56ms/epoch - 1ms/step\n",
      "Epoch 81/1000\n",
      "45/45 - 0s - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9778 - 58ms/epoch - 1ms/step\n",
      "Epoch 82/1000\n",
      "45/45 - 0s - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9722 - 59ms/epoch - 1ms/step\n",
      "Epoch 83/1000\n",
      "45/45 - 0s - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9722 - 55ms/epoch - 1ms/step\n",
      "Epoch 84/1000\n",
      "45/45 - 0s - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0918 - val_accuracy: 0.9722 - 56ms/epoch - 1ms/step\n",
      "Epoch 85/1000\n",
      "45/45 - 0s - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 86/1000\n",
      "45/45 - 0s - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0926 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 87/1000\n",
      "45/45 - 0s - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0938 - val_accuracy: 0.9722 - 56ms/epoch - 1ms/step\n",
      "Epoch 88/1000\n",
      "45/45 - 0s - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0925 - val_accuracy: 0.9778 - 54ms/epoch - 1ms/step\n",
      "Epoch 89/1000\n",
      "45/45 - 0s - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0936 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 90/1000\n",
      "45/45 - 0s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0936 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 91/1000\n",
      "45/45 - 0s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 0.9722 - 59ms/epoch - 1ms/step\n",
      "Epoch 92/1000\n",
      "45/45 - 0s - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0945 - val_accuracy: 0.9722 - 96ms/epoch - 2ms/step\n",
      "Epoch 93/1000\n",
      "45/45 - 0s - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 0.9778 - 78ms/epoch - 2ms/step\n",
      "Epoch 94/1000\n",
      "45/45 - 0s - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 0.9722 - 56ms/epoch - 1ms/step\n",
      "Epoch 95/1000\n",
      "45/45 - 0s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0969 - val_accuracy: 0.9722 - 59ms/epoch - 1ms/step\n",
      "Epoch 96/1000\n",
      "45/45 - 0s - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9722 - 58ms/epoch - 1ms/step\n",
      "Epoch 97/1000\n",
      "45/45 - 0s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 98/1000\n",
      "45/45 - 0s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 99/1000\n",
      "45/45 - 0s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9722 - 61ms/epoch - 1ms/step\n",
      "Epoch 100/1000\n",
      "45/45 - 0s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9750 - 66ms/epoch - 1ms/step\n",
      "Epoch 101/1000\n",
      "45/45 - 0s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9778 - 70ms/epoch - 2ms/step\n",
      "Epoch 102/1000\n",
      "45/45 - 0s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 0.9750 - 84ms/epoch - 2ms/step\n",
      "Epoch 103/1000\n",
      "45/45 - 0s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9750 - 68ms/epoch - 2ms/step\n",
      "Epoch 104/1000\n",
      "45/45 - 0s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0980 - val_accuracy: 0.9722 - 56ms/epoch - 1ms/step\n",
      "Epoch 105/1000\n",
      "45/45 - 0s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 106/1000\n",
      "45/45 - 0s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 0.9722 - 55ms/epoch - 1ms/step\n",
      "Epoch 107/1000\n",
      "45/45 - 0s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0975 - val_accuracy: 0.9778 - 56ms/epoch - 1ms/step\n",
      "Epoch 108/1000\n",
      "45/45 - 0s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0974 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 109/1000\n",
      "45/45 - 0s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0981 - val_accuracy: 0.9778 - 55ms/epoch - 1ms/step\n",
      "Epoch 110/1000\n",
      "45/45 - 0s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0991 - val_accuracy: 0.9722 - 60ms/epoch - 1ms/step\n",
      "Epoch 111/1000\n",
      "45/45 - 0s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9722 - 59ms/epoch - 1ms/step\n",
      "Epoch 112/1000\n",
      "45/45 - 0s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 113/1000\n",
      "45/45 - 0s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.9722 - 66ms/epoch - 1ms/step\n",
      "Epoch 114/1000\n",
      "45/45 - 0s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0999 - val_accuracy: 0.9778 - 64ms/epoch - 1ms/step\n",
      "Epoch 115/1000\n",
      "45/45 - 0s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1026 - val_accuracy: 0.9722 - 59ms/epoch - 1ms/step\n",
      "Epoch 116/1000\n",
      "45/45 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1009 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 117/1000\n",
      "45/45 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0999 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 118/1000\n",
      "45/45 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 119/1000\n",
      "45/45 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1017 - val_accuracy: 0.9778 - 60ms/epoch - 1ms/step\n",
      "Epoch 120/1000\n",
      "45/45 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1025 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 121/1000\n",
      "45/45 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 0.9778 - 57ms/epoch - 1ms/step\n",
      "Epoch 122/1000\n",
      "45/45 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1029 - val_accuracy: 0.9722 - 61ms/epoch - 1ms/step\n",
      "Epoch 123/1000\n",
      "45/45 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9722 - 58ms/epoch - 1ms/step\n",
      "Epoch 124/1000\n",
      "45/45 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1053 - val_accuracy: 0.9722 - 60ms/epoch - 1ms/step\n",
      "Epoch 125/1000\n",
      "45/45 - 0s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1030 - val_accuracy: 0.9778 - 65ms/epoch - 1ms/step\n",
      "Epoch 126/1000\n",
      "45/45 - 0s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 0.9778 - 70ms/epoch - 2ms/step\n",
      "Epoch 127/1000\n",
      "45/45 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9750 - 74ms/epoch - 2ms/step\n",
      "Epoch 128/1000\n",
      "45/45 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9778 - 64ms/epoch - 1ms/step\n",
      "Epoch 129/1000\n",
      "45/45 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1045 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 130/1000\n",
      "45/45 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1076 - val_accuracy: 0.9722 - 58ms/epoch - 1ms/step\n",
      "Epoch 131/1000\n",
      "45/45 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1039 - val_accuracy: 0.9750 - 53ms/epoch - 1ms/step\n",
      "Epoch 132/1000\n",
      "45/45 - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9722 - 61ms/epoch - 1ms/step\n",
      "Epoch 133/1000\n",
      "45/45 - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1052 - val_accuracy: 0.9778 - 57ms/epoch - 1ms/step\n",
      "Epoch 134/1000\n",
      "45/45 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9778 - 77ms/epoch - 2ms/step\n",
      "Epoch 135/1000\n",
      "45/45 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1073 - val_accuracy: 0.9722 - 60ms/epoch - 1ms/step\n",
      "Epoch 136/1000\n",
      "45/45 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 0.9778 - 59ms/epoch - 1ms/step\n",
      "Epoch 137/1000\n",
      "45/45 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 0.9778 - 115ms/epoch - 3ms/step\n",
      "Epoch 138/1000\n",
      "45/45 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1081 - val_accuracy: 0.9722 - 59ms/epoch - 1ms/step\n",
      "Epoch 139/1000\n",
      "45/45 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1075 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 140/1000\n",
      "45/45 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1076 - val_accuracy: 0.9778 - 66ms/epoch - 1ms/step\n",
      "Epoch 141/1000\n",
      "45/45 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1074 - val_accuracy: 0.9778 - 74ms/epoch - 2ms/step\n",
      "Epoch 142/1000\n",
      "45/45 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1081 - val_accuracy: 0.9778 - 76ms/epoch - 2ms/step\n",
      "Epoch 143/1000\n",
      "45/45 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1087 - val_accuracy: 0.9750 - 70ms/epoch - 2ms/step\n",
      "Epoch 144/1000\n",
      "45/45 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1091 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 145/1000\n",
      "45/45 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9778 - 60ms/epoch - 1ms/step\n",
      "Epoch 146/1000\n",
      "45/45 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1093 - val_accuracy: 0.9778 - 56ms/epoch - 1ms/step\n",
      "Epoch 147/1000\n",
      "45/45 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1111 - val_accuracy: 0.9778 - 58ms/epoch - 1ms/step\n",
      "Epoch 148/1000\n",
      "45/45 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1112 - val_accuracy: 0.9722 - 57ms/epoch - 1ms/step\n",
      "Epoch 149/1000\n",
      "45/45 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1122 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 150/1000\n",
      "45/45 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1116 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 151/1000\n",
      "45/45 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 152/1000\n",
      "45/45 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 153/1000\n",
      "45/45 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 154/1000\n",
      "45/45 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1121 - val_accuracy: 0.9778 - 58ms/epoch - 1ms/step\n",
      "Epoch 155/1000\n",
      "45/45 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 0.9778 - 57ms/epoch - 1ms/step\n",
      "Epoch 156/1000\n",
      "45/45 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1138 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 157/1000\n",
      "45/45 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1142 - val_accuracy: 0.9778 - 76ms/epoch - 2ms/step\n",
      "Epoch 158/1000\n",
      "45/45 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1135 - val_accuracy: 0.9778 - 63ms/epoch - 1ms/step\n",
      "Epoch 159/1000\n",
      "45/45 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1130 - val_accuracy: 0.9778 - 57ms/epoch - 1ms/step\n",
      "Epoch 160/1000\n",
      "45/45 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1136 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 161/1000\n",
      "45/45 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1147 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 162/1000\n",
      "45/45 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1135 - val_accuracy: 0.9778 - 58ms/epoch - 1ms/step\n",
      "Epoch 163/1000\n",
      "45/45 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1138 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 164/1000\n",
      "45/45 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1180 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 165/1000\n",
      "45/45 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1163 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 166/1000\n",
      "45/45 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1168 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 167/1000\n",
      "45/45 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1172 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 168/1000\n",
      "45/45 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1170 - val_accuracy: 0.9722 - 56ms/epoch - 1ms/step\n",
      "Epoch 169/1000\n",
      "45/45 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1200 - val_accuracy: 0.9722 - 53ms/epoch - 1ms/step\n",
      "Epoch 170/1000\n",
      "45/45 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1174 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 171/1000\n",
      "45/45 - 0s - loss: 9.9215e-04 - accuracy: 1.0000 - val_loss: 0.1183 - val_accuracy: 0.9722 - 61ms/epoch - 1ms/step\n",
      "Epoch 172/1000\n",
      "45/45 - 0s - loss: 9.7143e-04 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 173/1000\n",
      "45/45 - 0s - loss: 9.2816e-04 - accuracy: 1.0000 - val_loss: 0.1189 - val_accuracy: 0.9750 - 72ms/epoch - 2ms/step\n",
      "Epoch 174/1000\n",
      "45/45 - 0s - loss: 9.1240e-04 - accuracy: 1.0000 - val_loss: 0.1196 - val_accuracy: 0.9778 - 70ms/epoch - 2ms/step\n",
      "Epoch 175/1000\n",
      "45/45 - 0s - loss: 9.1654e-04 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9778 - 70ms/epoch - 2ms/step\n",
      "Epoch 176/1000\n",
      "45/45 - 0s - loss: 9.0971e-04 - accuracy: 1.0000 - val_loss: 0.1199 - val_accuracy: 0.9750 - 80ms/epoch - 2ms/step\n",
      "Epoch 177/1000\n",
      "45/45 - 0s - loss: 8.4172e-04 - accuracy: 1.0000 - val_loss: 0.1190 - val_accuracy: 0.9778 - 58ms/epoch - 1ms/step\n",
      "Epoch 178/1000\n",
      "45/45 - 0s - loss: 8.4841e-04 - accuracy: 1.0000 - val_loss: 0.1206 - val_accuracy: 0.9778 - 107ms/epoch - 2ms/step\n",
      "Epoch 179/1000\n",
      "45/45 - 0s - loss: 8.0415e-04 - accuracy: 1.0000 - val_loss: 0.1209 - val_accuracy: 0.9778 - 63ms/epoch - 1ms/step\n",
      "Epoch 180/1000\n",
      "45/45 - 0s - loss: 7.7678e-04 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 0.9778 - 68ms/epoch - 2ms/step\n",
      "Epoch 181/1000\n",
      "45/45 - 0s - loss: 7.4852e-04 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 0.9750 - 64ms/epoch - 1ms/step\n",
      "Epoch 182/1000\n",
      "45/45 - 0s - loss: 7.4464e-04 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 0.9722 - 64ms/epoch - 1ms/step\n",
      "Epoch 183/1000\n",
      "45/45 - 0s - loss: 7.3055e-04 - accuracy: 1.0000 - val_loss: 0.1250 - val_accuracy: 0.9750 - 65ms/epoch - 1ms/step\n",
      "Epoch 184/1000\n",
      "45/45 - 0s - loss: 7.2229e-04 - accuracy: 1.0000 - val_loss: 0.1233 - val_accuracy: 0.9778 - 54ms/epoch - 1ms/step\n",
      "Epoch 185/1000\n",
      "45/45 - 0s - loss: 7.1506e-04 - accuracy: 1.0000 - val_loss: 0.1242 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 186/1000\n",
      "45/45 - 0s - loss: 6.8723e-04 - accuracy: 1.0000 - val_loss: 0.1225 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 187/1000\n",
      "45/45 - 0s - loss: 6.4254e-04 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 188/1000\n",
      "45/45 - 0s - loss: 6.8371e-04 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 189/1000\n",
      "45/45 - 0s - loss: 6.4342e-04 - accuracy: 1.0000 - val_loss: 0.1251 - val_accuracy: 0.9750 - 54ms/epoch - 1ms/step\n",
      "Epoch 190/1000\n",
      "45/45 - 0s - loss: 6.1390e-04 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 0.9778 - 58ms/epoch - 1ms/step\n",
      "Epoch 191/1000\n",
      "45/45 - 0s - loss: 5.9922e-04 - accuracy: 1.0000 - val_loss: 0.1263 - val_accuracy: 0.9722 - 55ms/epoch - 1ms/step\n",
      "Epoch 192/1000\n",
      "45/45 - 0s - loss: 5.8477e-04 - accuracy: 1.0000 - val_loss: 0.1248 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 193/1000\n",
      "45/45 - 0s - loss: 5.7354e-04 - accuracy: 1.0000 - val_loss: 0.1255 - val_accuracy: 0.9778 - 54ms/epoch - 1ms/step\n",
      "Epoch 194/1000\n",
      "45/45 - 0s - loss: 5.9393e-04 - accuracy: 1.0000 - val_loss: 0.1252 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 195/1000\n",
      "45/45 - 0s - loss: 5.3391e-04 - accuracy: 1.0000 - val_loss: 0.1277 - val_accuracy: 0.9722 - 62ms/epoch - 1ms/step\n",
      "Epoch 196/1000\n",
      "45/45 - 0s - loss: 5.4983e-04 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9778 - 69ms/epoch - 2ms/step\n",
      "Epoch 197/1000\n",
      "45/45 - 0s - loss: 5.2209e-04 - accuracy: 1.0000 - val_loss: 0.1263 - val_accuracy: 0.9750 - 89ms/epoch - 2ms/step\n",
      "Epoch 198/1000\n",
      "45/45 - 0s - loss: 5.1182e-04 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 199/1000\n",
      "45/45 - 0s - loss: 4.9586e-04 - accuracy: 1.0000 - val_loss: 0.1278 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 200/1000\n",
      "45/45 - 0s - loss: 4.8351e-04 - accuracy: 1.0000 - val_loss: 0.1293 - val_accuracy: 0.9778 - 60ms/epoch - 1ms/step\n",
      "Epoch 201/1000\n",
      "45/45 - 0s - loss: 4.6964e-04 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 202/1000\n",
      "45/45 - 0s - loss: 4.7214e-04 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.9722 - 64ms/epoch - 1ms/step\n",
      "Epoch 203/1000\n",
      "45/45 - 0s - loss: 4.6263e-04 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 0.9750 - 64ms/epoch - 1ms/step\n",
      "Epoch 204/1000\n",
      "45/45 - 0s - loss: 4.4049e-04 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 0.9722 - 82ms/epoch - 2ms/step\n",
      "Epoch 205/1000\n",
      "45/45 - 0s - loss: 4.3430e-04 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 206/1000\n",
      "45/45 - 0s - loss: 4.2238e-04 - accuracy: 1.0000 - val_loss: 0.1307 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 207/1000\n",
      "45/45 - 0s - loss: 3.9986e-04 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 0.9750 - 55ms/epoch - 1ms/step\n",
      "Epoch 208/1000\n",
      "45/45 - 0s - loss: 3.9694e-04 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 0.9750 - 55ms/epoch - 1ms/step\n",
      "Epoch 209/1000\n",
      "45/45 - 0s - loss: 4.0453e-04 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 210/1000\n",
      "45/45 - 0s - loss: 3.8674e-04 - accuracy: 1.0000 - val_loss: 0.1328 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 211/1000\n",
      "45/45 - 0s - loss: 3.6352e-04 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 0.9722 - 55ms/epoch - 1ms/step\n",
      "Epoch 212/1000\n",
      "45/45 - 0s - loss: 3.6462e-04 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.9722 - 57ms/epoch - 1ms/step\n",
      "Epoch 213/1000\n",
      "45/45 - 0s - loss: 3.6354e-04 - accuracy: 1.0000 - val_loss: 0.1353 - val_accuracy: 0.9722 - 57ms/epoch - 1ms/step\n",
      "Epoch 214/1000\n",
      "45/45 - 0s - loss: 3.5712e-04 - accuracy: 1.0000 - val_loss: 0.1355 - val_accuracy: 0.9722 - 58ms/epoch - 1ms/step\n",
      "Epoch 215/1000\n",
      "45/45 - 0s - loss: 3.4361e-04 - accuracy: 1.0000 - val_loss: 0.1355 - val_accuracy: 0.9722 - 54ms/epoch - 1ms/step\n",
      "Epoch 216/1000\n",
      "45/45 - 0s - loss: 3.3647e-04 - accuracy: 1.0000 - val_loss: 0.1347 - val_accuracy: 0.9750 - 63ms/epoch - 1ms/step\n",
      "Epoch 217/1000\n",
      "45/45 - 0s - loss: 3.2277e-04 - accuracy: 1.0000 - val_loss: 0.1358 - val_accuracy: 0.9722 - 55ms/epoch - 1ms/step\n",
      "Epoch 218/1000\n",
      "45/45 - 0s - loss: 3.1126e-04 - accuracy: 1.0000 - val_loss: 0.1349 - val_accuracy: 0.9750 - 102ms/epoch - 2ms/step\n",
      "Epoch 219/1000\n",
      "45/45 - 0s - loss: 3.0396e-04 - accuracy: 1.0000 - val_loss: 0.1375 - val_accuracy: 0.9722 - 64ms/epoch - 1ms/step\n",
      "Epoch 220/1000\n",
      "45/45 - 0s - loss: 3.1344e-04 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.9778 - 58ms/epoch - 1ms/step\n",
      "Epoch 221/1000\n",
      "45/45 - 0s - loss: 3.1048e-04 - accuracy: 1.0000 - val_loss: 0.1365 - val_accuracy: 0.9722 - 57ms/epoch - 1ms/step\n",
      "Epoch 222/1000\n",
      "45/45 - 0s - loss: 2.8650e-04 - accuracy: 1.0000 - val_loss: 0.1360 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 223/1000\n",
      "45/45 - 0s - loss: 2.7634e-04 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 224/1000\n",
      "45/45 - 0s - loss: 2.6764e-04 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 225/1000\n",
      "45/45 - 0s - loss: 2.6246e-04 - accuracy: 1.0000 - val_loss: 0.1399 - val_accuracy: 0.9722 - 58ms/epoch - 1ms/step\n",
      "Epoch 226/1000\n",
      "45/45 - 0s - loss: 2.6858e-04 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9722 - 57ms/epoch - 1ms/step\n",
      "Epoch 227/1000\n",
      "45/45 - 0s - loss: 2.5726e-04 - accuracy: 1.0000 - val_loss: 0.1395 - val_accuracy: 0.9750 - 54ms/epoch - 1ms/step\n",
      "Epoch 228/1000\n",
      "45/45 - 0s - loss: 2.4653e-04 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 229/1000\n",
      "45/45 - 0s - loss: 2.4726e-04 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 230/1000\n",
      "45/45 - 0s - loss: 2.3333e-04 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 0.9722 - 56ms/epoch - 1ms/step\n",
      "Epoch 231/1000\n",
      "45/45 - 0s - loss: 2.2876e-04 - accuracy: 1.0000 - val_loss: 0.1435 - val_accuracy: 0.9778 - 53ms/epoch - 1ms/step\n",
      "Epoch 232/1000\n",
      "45/45 - 0s - loss: 2.2885e-04 - accuracy: 1.0000 - val_loss: 0.1419 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 233/1000\n",
      "45/45 - 0s - loss: 2.2089e-04 - accuracy: 1.0000 - val_loss: 0.1413 - val_accuracy: 0.9750 - 54ms/epoch - 1ms/step\n",
      "Epoch 234/1000\n",
      "45/45 - 0s - loss: 2.1361e-04 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 235/1000\n",
      "45/45 - 0s - loss: 2.0641e-04 - accuracy: 1.0000 - val_loss: 0.1423 - val_accuracy: 0.9722 - 59ms/epoch - 1ms/step\n",
      "Epoch 236/1000\n",
      "45/45 - 0s - loss: 1.9962e-04 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 237/1000\n",
      "45/45 - 0s - loss: 1.9752e-04 - accuracy: 1.0000 - val_loss: 0.1445 - val_accuracy: 0.9722 - 58ms/epoch - 1ms/step\n",
      "Epoch 238/1000\n",
      "45/45 - 0s - loss: 1.9676e-04 - accuracy: 1.0000 - val_loss: 0.1439 - val_accuracy: 0.9722 - 62ms/epoch - 1ms/step\n",
      "Epoch 239/1000\n",
      "45/45 - 0s - loss: 1.8997e-04 - accuracy: 1.0000 - val_loss: 0.1446 - val_accuracy: 0.9722 - 63ms/epoch - 1ms/step\n",
      "Epoch 240/1000\n",
      "45/45 - 0s - loss: 1.8501e-04 - accuracy: 1.0000 - val_loss: 0.1427 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 241/1000\n",
      "45/45 - 0s - loss: 1.8533e-04 - accuracy: 1.0000 - val_loss: 0.1459 - val_accuracy: 0.9722 - 56ms/epoch - 1ms/step\n",
      "Epoch 242/1000\n",
      "45/45 - 0s - loss: 1.8164e-04 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9722 - 57ms/epoch - 1ms/step\n",
      "Epoch 243/1000\n",
      "45/45 - 0s - loss: 1.7259e-04 - accuracy: 1.0000 - val_loss: 0.1466 - val_accuracy: 0.9722 - 91ms/epoch - 2ms/step\n",
      "Epoch 244/1000\n",
      "45/45 - 0s - loss: 1.7104e-04 - accuracy: 1.0000 - val_loss: 0.1467 - val_accuracy: 0.9750 - 63ms/epoch - 1ms/step\n",
      "Epoch 245/1000\n",
      "45/45 - 0s - loss: 1.6212e-04 - accuracy: 1.0000 - val_loss: 0.1461 - val_accuracy: 0.9722 - 63ms/epoch - 1ms/step\n",
      "Epoch 246/1000\n",
      "45/45 - 0s - loss: 1.6765e-04 - accuracy: 1.0000 - val_loss: 0.1484 - val_accuracy: 0.9722 - 68ms/epoch - 2ms/step\n",
      "Epoch 247/1000\n",
      "45/45 - 0s - loss: 1.6034e-04 - accuracy: 1.0000 - val_loss: 0.1464 - val_accuracy: 0.9750 - 54ms/epoch - 1ms/step\n",
      "Epoch 248/1000\n",
      "45/45 - 0s - loss: 1.5465e-04 - accuracy: 1.0000 - val_loss: 0.1458 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 249/1000\n",
      "45/45 - 0s - loss: 1.4735e-04 - accuracy: 1.0000 - val_loss: 0.1464 - val_accuracy: 0.9750 - 55ms/epoch - 1ms/step\n",
      "Epoch 250/1000\n",
      "45/45 - 0s - loss: 1.4403e-04 - accuracy: 1.0000 - val_loss: 0.1492 - val_accuracy: 0.9722 - 58ms/epoch - 1ms/step\n",
      "Epoch 251/1000\n",
      "45/45 - 0s - loss: 1.4162e-04 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.9722 - 82ms/epoch - 2ms/step\n",
      "Epoch 252/1000\n",
      "45/45 - 0s - loss: 1.3976e-04 - accuracy: 1.0000 - val_loss: 0.1493 - val_accuracy: 0.9722 - 55ms/epoch - 1ms/step\n",
      "Epoch 253/1000\n",
      "45/45 - 0s - loss: 1.3161e-04 - accuracy: 1.0000 - val_loss: 0.1486 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 254/1000\n",
      "45/45 - 0s - loss: 1.3177e-04 - accuracy: 1.0000 - val_loss: 0.1495 - val_accuracy: 0.9722 - 54ms/epoch - 1ms/step\n",
      "Epoch 255/1000\n",
      "45/45 - 0s - loss: 1.2839e-04 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9722 - 59ms/epoch - 1ms/step\n",
      "Epoch 256/1000\n",
      "45/45 - 0s - loss: 1.2522e-04 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 257/1000\n",
      "45/45 - 0s - loss: 1.2669e-04 - accuracy: 1.0000 - val_loss: 0.1502 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 258/1000\n",
      "45/45 - 0s - loss: 1.1897e-04 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.9722 - 73ms/epoch - 2ms/step\n",
      "Epoch 259/1000\n",
      "45/45 - 0s - loss: 1.1734e-04 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9750 - 136ms/epoch - 3ms/step\n",
      "Epoch 260/1000\n",
      "45/45 - 0s - loss: 1.1444e-04 - accuracy: 1.0000 - val_loss: 0.1501 - val_accuracy: 0.9750 - 74ms/epoch - 2ms/step\n",
      "Epoch 261/1000\n",
      "45/45 - 0s - loss: 1.1292e-04 - accuracy: 1.0000 - val_loss: 0.1523 - val_accuracy: 0.9722 - 66ms/epoch - 1ms/step\n",
      "Epoch 262/1000\n",
      "45/45 - 0s - loss: 1.1188e-04 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.9750 - 68ms/epoch - 2ms/step\n",
      "Epoch 263/1000\n",
      "45/45 - 0s - loss: 1.0972e-04 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 264/1000\n",
      "45/45 - 0s - loss: 1.0874e-04 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9750 - 68ms/epoch - 2ms/step\n",
      "Epoch 265/1000\n",
      "45/45 - 0s - loss: 1.0196e-04 - accuracy: 1.0000 - val_loss: 0.1541 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 266/1000\n",
      "45/45 - 0s - loss: 1.0281e-04 - accuracy: 1.0000 - val_loss: 0.1559 - val_accuracy: 0.9722 - 59ms/epoch - 1ms/step\n",
      "Epoch 267/1000\n",
      "45/45 - 0s - loss: 9.8476e-05 - accuracy: 1.0000 - val_loss: 0.1543 - val_accuracy: 0.9750 - 55ms/epoch - 1ms/step\n",
      "Epoch 268/1000\n",
      "45/45 - 0s - loss: 9.2800e-05 - accuracy: 1.0000 - val_loss: 0.1565 - val_accuracy: 0.9722 - 58ms/epoch - 1ms/step\n",
      "Epoch 269/1000\n",
      "45/45 - 0s - loss: 9.2464e-05 - accuracy: 1.0000 - val_loss: 0.1558 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 270/1000\n",
      "45/45 - 0s - loss: 8.9867e-05 - accuracy: 1.0000 - val_loss: 0.1575 - val_accuracy: 0.9722 - 57ms/epoch - 1ms/step\n",
      "Epoch 271/1000\n",
      "45/45 - 0s - loss: 8.8457e-05 - accuracy: 1.0000 - val_loss: 0.1567 - val_accuracy: 0.9722 - 57ms/epoch - 1ms/step\n",
      "Epoch 272/1000\n",
      "45/45 - 0s - loss: 8.6857e-05 - accuracy: 1.0000 - val_loss: 0.1551 - val_accuracy: 0.9750 - 64ms/epoch - 1ms/step\n",
      "Epoch 273/1000\n",
      "45/45 - 0s - loss: 8.9519e-05 - accuracy: 1.0000 - val_loss: 0.1561 - val_accuracy: 0.9750 - 65ms/epoch - 1ms/step\n",
      "Epoch 274/1000\n",
      "45/45 - 0s - loss: 8.3137e-05 - accuracy: 1.0000 - val_loss: 0.1587 - val_accuracy: 0.9722 - 59ms/epoch - 1ms/step\n",
      "Epoch 275/1000\n",
      "45/45 - 0s - loss: 7.9489e-05 - accuracy: 1.0000 - val_loss: 0.1566 - val_accuracy: 0.9750 - 55ms/epoch - 1ms/step\n",
      "Epoch 276/1000\n",
      "45/45 - 0s - loss: 8.0037e-05 - accuracy: 1.0000 - val_loss: 0.1588 - val_accuracy: 0.9722 - 56ms/epoch - 1ms/step\n",
      "Epoch 277/1000\n",
      "45/45 - 0s - loss: 7.5315e-05 - accuracy: 1.0000 - val_loss: 0.1576 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 278/1000\n",
      "45/45 - 0s - loss: 7.7196e-05 - accuracy: 1.0000 - val_loss: 0.1605 - val_accuracy: 0.9750 - 51ms/epoch - 1ms/step\n",
      "Epoch 279/1000\n",
      "45/45 - 0s - loss: 7.2203e-05 - accuracy: 1.0000 - val_loss: 0.1593 - val_accuracy: 0.9722 - 54ms/epoch - 1ms/step\n",
      "Epoch 280/1000\n",
      "45/45 - 0s - loss: 7.0721e-05 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 281/1000\n",
      "45/45 - 0s - loss: 7.0820e-05 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9750 - 53ms/epoch - 1ms/step\n",
      "Epoch 282/1000\n",
      "45/45 - 0s - loss: 6.8391e-05 - accuracy: 1.0000 - val_loss: 0.1609 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 283/1000\n",
      "45/45 - 0s - loss: 6.7854e-05 - accuracy: 1.0000 - val_loss: 0.1614 - val_accuracy: 0.9722 - 56ms/epoch - 1ms/step\n",
      "Epoch 284/1000\n",
      "45/45 - 0s - loss: 6.5164e-05 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 285/1000\n",
      "45/45 - 0s - loss: 6.3994e-05 - accuracy: 1.0000 - val_loss: 0.1618 - val_accuracy: 0.9722 - 52ms/epoch - 1ms/step\n",
      "Epoch 286/1000\n",
      "45/45 - 0s - loss: 6.1650e-05 - accuracy: 1.0000 - val_loss: 0.1639 - val_accuracy: 0.9722 - 55ms/epoch - 1ms/step\n",
      "Epoch 287/1000\n",
      "45/45 - 0s - loss: 6.0590e-05 - accuracy: 1.0000 - val_loss: 0.1634 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 288/1000\n",
      "45/45 - 0s - loss: 5.8616e-05 - accuracy: 1.0000 - val_loss: 0.1621 - val_accuracy: 0.9722 - 57ms/epoch - 1ms/step\n",
      "Epoch 289/1000\n",
      "45/45 - 0s - loss: 5.7370e-05 - accuracy: 1.0000 - val_loss: 0.1631 - val_accuracy: 0.9722 - 58ms/epoch - 1ms/step\n",
      "Epoch 290/1000\n",
      "45/45 - 0s - loss: 5.5843e-05 - accuracy: 1.0000 - val_loss: 0.1625 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 291/1000\n",
      "45/45 - 0s - loss: 5.5007e-05 - accuracy: 1.0000 - val_loss: 0.1649 - val_accuracy: 0.9722 - 56ms/epoch - 1ms/step\n",
      "Epoch 292/1000\n",
      "45/45 - 0s - loss: 5.4862e-05 - accuracy: 1.0000 - val_loss: 0.1664 - val_accuracy: 0.9722 - 53ms/epoch - 1ms/step\n",
      "Epoch 293/1000\n",
      "45/45 - 0s - loss: 5.1309e-05 - accuracy: 1.0000 - val_loss: 0.1635 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 294/1000\n",
      "45/45 - 0s - loss: 5.1774e-05 - accuracy: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9750 - 55ms/epoch - 1ms/step\n",
      "Epoch 295/1000\n",
      "45/45 - 0s - loss: 4.9416e-05 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9722 - 66ms/epoch - 1ms/step\n",
      "Epoch 296/1000\n",
      "45/45 - 0s - loss: 4.8883e-05 - accuracy: 1.0000 - val_loss: 0.1661 - val_accuracy: 0.9722 - 58ms/epoch - 1ms/step\n",
      "Epoch 297/1000\n",
      "45/45 - 0s - loss: 4.7775e-05 - accuracy: 1.0000 - val_loss: 0.1667 - val_accuracy: 0.9750 - 54ms/epoch - 1ms/step\n",
      "Epoch 298/1000\n",
      "45/45 - 0s - loss: 4.5816e-05 - accuracy: 1.0000 - val_loss: 0.1662 - val_accuracy: 0.9750 - 54ms/epoch - 1ms/step\n",
      "Epoch 299/1000\n",
      "45/45 - 0s - loss: 4.5830e-05 - accuracy: 1.0000 - val_loss: 0.1663 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 300/1000\n",
      "45/45 - 0s - loss: 4.5228e-05 - accuracy: 1.0000 - val_loss: 0.1678 - val_accuracy: 0.9722 - 58ms/epoch - 1ms/step\n",
      "Epoch 301/1000\n",
      "45/45 - 0s - loss: 4.3047e-05 - accuracy: 1.0000 - val_loss: 0.1690 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 302/1000\n",
      "45/45 - 0s - loss: 4.2761e-05 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 0.9722 - 52ms/epoch - 1ms/step\n",
      "Epoch 303/1000\n",
      "45/45 - 0s - loss: 4.2207e-05 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 0.9722 - 59ms/epoch - 1ms/step\n",
      "Epoch 304/1000\n",
      "45/45 - 0s - loss: 4.0218e-05 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 305/1000\n",
      "45/45 - 0s - loss: 4.0169e-05 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 0.9722 - 100ms/epoch - 2ms/step\n",
      "Epoch 306/1000\n",
      "45/45 - 0s - loss: 3.8873e-05 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 0.9750 - 65ms/epoch - 1ms/step\n",
      "Epoch 307/1000\n",
      "45/45 - 0s - loss: 3.8635e-05 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 308/1000\n",
      "45/45 - 0s - loss: 3.6704e-05 - accuracy: 1.0000 - val_loss: 0.1745 - val_accuracy: 0.9722 - 57ms/epoch - 1ms/step\n",
      "Epoch 309/1000\n",
      "45/45 - 0s - loss: 4.0646e-05 - accuracy: 1.0000 - val_loss: 0.1737 - val_accuracy: 0.9722 - 54ms/epoch - 1ms/step\n",
      "Epoch 310/1000\n",
      "45/45 - 0s - loss: 3.6451e-05 - accuracy: 1.0000 - val_loss: 0.1723 - val_accuracy: 0.9722 - 57ms/epoch - 1ms/step\n",
      "Epoch 311/1000\n",
      "45/45 - 0s - loss: 3.4015e-05 - accuracy: 1.0000 - val_loss: 0.1723 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 312/1000\n",
      "45/45 - 0s - loss: 3.4081e-05 - accuracy: 1.0000 - val_loss: 0.1743 - val_accuracy: 0.9750 - 55ms/epoch - 1ms/step\n",
      "Epoch 313/1000\n",
      "45/45 - 0s - loss: 3.3268e-05 - accuracy: 1.0000 - val_loss: 0.1731 - val_accuracy: 0.9750 - 54ms/epoch - 1ms/step\n",
      "Epoch 314/1000\n",
      "45/45 - 0s - loss: 3.1280e-05 - accuracy: 1.0000 - val_loss: 0.1730 - val_accuracy: 0.9750 - 55ms/epoch - 1ms/step\n",
      "Epoch 315/1000\n",
      "45/45 - 0s - loss: 3.1226e-05 - accuracy: 1.0000 - val_loss: 0.1744 - val_accuracy: 0.9722 - 54ms/epoch - 1ms/step\n",
      "Epoch 316/1000\n",
      "45/45 - 0s - loss: 2.9978e-05 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 0.9750 - 55ms/epoch - 1ms/step\n",
      "Epoch 317/1000\n",
      "45/45 - 0s - loss: 2.9902e-05 - accuracy: 1.0000 - val_loss: 0.1750 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 318/1000\n",
      "45/45 - 0s - loss: 2.9577e-05 - accuracy: 1.0000 - val_loss: 0.1743 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 319/1000\n",
      "45/45 - 0s - loss: 2.8460e-05 - accuracy: 1.0000 - val_loss: 0.1748 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 320/1000\n",
      "45/45 - 0s - loss: 2.7529e-05 - accuracy: 1.0000 - val_loss: 0.1745 - val_accuracy: 0.9750 - 52ms/epoch - 1ms/step\n",
      "Epoch 321/1000\n",
      "45/45 - 0s - loss: 2.6840e-05 - accuracy: 1.0000 - val_loss: 0.1770 - val_accuracy: 0.9722 - 58ms/epoch - 1ms/step\n",
      "Epoch 322/1000\n",
      "45/45 - 0s - loss: 2.5605e-05 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 323/1000\n",
      "45/45 - 0s - loss: 2.6633e-05 - accuracy: 1.0000 - val_loss: 0.1764 - val_accuracy: 0.9750 - 55ms/epoch - 1ms/step\n",
      "Epoch 324/1000\n",
      "45/45 - 0s - loss: 2.5418e-05 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 0.9722 - 53ms/epoch - 1ms/step\n",
      "Epoch 325/1000\n",
      "45/45 - 0s - loss: 2.4281e-05 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 326/1000\n",
      "45/45 - 0s - loss: 2.4092e-05 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9750 - 55ms/epoch - 1ms/step\n",
      "Epoch 327/1000\n",
      "45/45 - 0s - loss: 2.4913e-05 - accuracy: 1.0000 - val_loss: 0.1775 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 328/1000\n",
      "45/45 - 0s - loss: 2.3029e-05 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 0.9722 - 54ms/epoch - 1ms/step\n",
      "Epoch 329/1000\n",
      "45/45 - 0s - loss: 2.3361e-05 - accuracy: 1.0000 - val_loss: 0.1798 - val_accuracy: 0.9722 - 57ms/epoch - 1ms/step\n",
      "Epoch 330/1000\n",
      "45/45 - 0s - loss: 2.1655e-05 - accuracy: 1.0000 - val_loss: 0.1795 - val_accuracy: 0.9750 - 54ms/epoch - 1ms/step\n",
      "Epoch 331/1000\n",
      "45/45 - 0s - loss: 2.1091e-05 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9722 - 54ms/epoch - 1ms/step\n",
      "Epoch 332/1000\n",
      "45/45 - 0s - loss: 2.1142e-05 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9722 - 57ms/epoch - 1ms/step\n",
      "Epoch 333/1000\n",
      "45/45 - 0s - loss: 2.0260e-05 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9750 - 63ms/epoch - 1ms/step\n",
      "Epoch 334/1000\n",
      "45/45 - 0s - loss: 2.0000e-05 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 0.9750 - 72ms/epoch - 2ms/step\n",
      "Epoch 335/1000\n",
      "45/45 - 0s - loss: 1.9544e-05 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9750 - 64ms/epoch - 1ms/step\n",
      "Epoch 336/1000\n",
      "45/45 - 0s - loss: 2.0052e-05 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 0.9722 - 55ms/epoch - 1ms/step\n",
      "Epoch 337/1000\n",
      "45/45 - 0s - loss: 1.8955e-05 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9722 - 79ms/epoch - 2ms/step\n",
      "Epoch 338/1000\n",
      "45/45 - 0s - loss: 1.8131e-05 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 339/1000\n",
      "45/45 - 0s - loss: 1.8354e-05 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 0.9750 - 63ms/epoch - 1ms/step\n",
      "Epoch 340/1000\n",
      "45/45 - 0s - loss: 1.8705e-05 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.9750 - 73ms/epoch - 2ms/step\n",
      "Epoch 341/1000\n",
      "45/45 - 0s - loss: 1.7481e-05 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9750 - 76ms/epoch - 2ms/step\n",
      "Epoch 342/1000\n",
      "45/45 - 0s - loss: 1.6228e-05 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9750 - 53ms/epoch - 1ms/step\n",
      "Epoch 343/1000\n",
      "45/45 - 0s - loss: 1.6084e-05 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 0.9750 - 101ms/epoch - 2ms/step\n",
      "Epoch 344/1000\n",
      "45/45 - 0s - loss: 1.5875e-05 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9750 - 69ms/epoch - 2ms/step\n",
      "Epoch 345/1000\n",
      "45/45 - 0s - loss: 1.5886e-05 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 0.9750 - 54ms/epoch - 1ms/step\n",
      "Epoch 346/1000\n",
      "45/45 - 0s - loss: 1.5541e-05 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 0.9694 - 55ms/epoch - 1ms/step\n",
      "Epoch 347/1000\n",
      "45/45 - 0s - loss: 1.5115e-05 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 348/1000\n",
      "45/45 - 0s - loss: 1.4484e-05 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 349/1000\n",
      "45/45 - 0s - loss: 1.3860e-05 - accuracy: 1.0000 - val_loss: 0.1873 - val_accuracy: 0.9750 - 54ms/epoch - 1ms/step\n",
      "Epoch 350/1000\n",
      "45/45 - 0s - loss: 1.3622e-05 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9722 - 54ms/epoch - 1ms/step\n",
      "Epoch 351/1000\n",
      "45/45 - 0s - loss: 1.3817e-05 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 352/1000\n",
      "45/45 - 0s - loss: 1.3135e-05 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 0.9750 - 54ms/epoch - 1ms/step\n",
      "Epoch 353/1000\n",
      "45/45 - 0s - loss: 1.2786e-05 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9750 - 65ms/epoch - 1ms/step\n",
      "Epoch 354/1000\n",
      "45/45 - 0s - loss: 1.2640e-05 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9750 - 73ms/epoch - 2ms/step\n",
      "Epoch 355/1000\n",
      "45/45 - 0s - loss: 1.2523e-05 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 356/1000\n",
      "45/45 - 0s - loss: 1.1883e-05 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 0.9750 - 66ms/epoch - 1ms/step\n",
      "Epoch 357/1000\n",
      "45/45 - 0s - loss: 1.1550e-05 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9722 - 66ms/epoch - 1ms/step\n",
      "Epoch 358/1000\n",
      "45/45 - 0s - loss: 1.1526e-05 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.9750 - 72ms/epoch - 2ms/step\n",
      "Epoch 359/1000\n",
      "45/45 - 0s - loss: 1.0974e-05 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9750 - 70ms/epoch - 2ms/step\n",
      "Epoch 360/1000\n",
      "45/45 - 0s - loss: 1.0712e-05 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 361/1000\n",
      "45/45 - 0s - loss: 1.1111e-05 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 0.9750 - 64ms/epoch - 1ms/step\n",
      "Epoch 362/1000\n",
      "45/45 - 0s - loss: 1.0245e-05 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 363/1000\n",
      "45/45 - 0s - loss: 1.0054e-05 - accuracy: 1.0000 - val_loss: 0.1931 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 364/1000\n",
      "45/45 - 0s - loss: 1.0430e-05 - accuracy: 1.0000 - val_loss: 0.1919 - val_accuracy: 0.9722 - 65ms/epoch - 1ms/step\n",
      "Epoch 365/1000\n",
      "45/45 - 0s - loss: 1.1066e-05 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 366/1000\n",
      "45/45 - 0s - loss: 9.7260e-06 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9750 - 65ms/epoch - 1ms/step\n",
      "Epoch 367/1000\n",
      "45/45 - 0s - loss: 9.1290e-06 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 368/1000\n",
      "45/45 - 0s - loss: 8.8974e-06 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9750 - 65ms/epoch - 1ms/step\n",
      "Epoch 369/1000\n",
      "45/45 - 0s - loss: 8.6574e-06 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9750 - 71ms/epoch - 2ms/step\n",
      "Epoch 370/1000\n",
      "45/45 - 0s - loss: 8.7613e-06 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 0.9722 - 74ms/epoch - 2ms/step\n",
      "Epoch 371/1000\n",
      "45/45 - 0s - loss: 8.8065e-06 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9750 - 67ms/epoch - 1ms/step\n",
      "Epoch 372/1000\n",
      "45/45 - 0s - loss: 8.3240e-06 - accuracy: 1.0000 - val_loss: 0.1963 - val_accuracy: 0.9750 - 70ms/epoch - 2ms/step\n",
      "Epoch 373/1000\n",
      "45/45 - 0s - loss: 8.1903e-06 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.9750 - 65ms/epoch - 1ms/step\n",
      "Epoch 374/1000\n",
      "45/45 - 0s - loss: 7.8377e-06 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9750 - 83ms/epoch - 2ms/step\n",
      "Epoch 375/1000\n",
      "45/45 - 0s - loss: 7.6354e-06 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 376/1000\n",
      "45/45 - 0s - loss: 7.3254e-06 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9750 - 68ms/epoch - 2ms/step\n",
      "Epoch 377/1000\n",
      "45/45 - 0s - loss: 7.0808e-06 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9750 - 76ms/epoch - 2ms/step\n",
      "Epoch 378/1000\n",
      "45/45 - 0s - loss: 7.0390e-06 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9750 - 92ms/epoch - 2ms/step\n",
      "Epoch 379/1000\n",
      "45/45 - 0s - loss: 7.2575e-06 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9750 - 55ms/epoch - 1ms/step\n",
      "Epoch 380/1000\n",
      "45/45 - 0s - loss: 6.9326e-06 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9722 - 56ms/epoch - 1ms/step\n",
      "Epoch 381/1000\n",
      "45/45 - 0s - loss: 6.5820e-06 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 382/1000\n",
      "45/45 - 0s - loss: 6.5460e-06 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 383/1000\n",
      "45/45 - 0s - loss: 6.5237e-06 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 0.9722 - 59ms/epoch - 1ms/step\n",
      "Epoch 384/1000\n",
      "45/45 - 0s - loss: 6.1488e-06 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9722 - 57ms/epoch - 1ms/step\n",
      "Epoch 385/1000\n",
      "45/45 - 0s - loss: 6.3210e-06 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9722 - 55ms/epoch - 1ms/step\n",
      "Epoch 386/1000\n",
      "45/45 - 0s - loss: 5.8897e-06 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9750 - 53ms/epoch - 1ms/step\n",
      "Epoch 387/1000\n",
      "45/45 - 0s - loss: 5.7993e-06 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9750 - 54ms/epoch - 1ms/step\n",
      "Epoch 388/1000\n",
      "45/45 - 0s - loss: 5.6982e-06 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9750 - 52ms/epoch - 1ms/step\n",
      "Epoch 389/1000\n",
      "45/45 - 0s - loss: 5.6316e-06 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9722 - 57ms/epoch - 1ms/step\n",
      "Epoch 390/1000\n",
      "45/45 - 0s - loss: 5.3917e-06 - accuracy: 1.0000 - val_loss: 0.2051 - val_accuracy: 0.9722 - 56ms/epoch - 1ms/step\n",
      "Epoch 391/1000\n",
      "45/45 - 0s - loss: 5.2917e-06 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.9722 - 56ms/epoch - 1ms/step\n",
      "Epoch 392/1000\n",
      "45/45 - 0s - loss: 5.1031e-06 - accuracy: 1.0000 - val_loss: 0.2053 - val_accuracy: 0.9750 - 55ms/epoch - 1ms/step\n",
      "Epoch 393/1000\n",
      "45/45 - 0s - loss: 5.0860e-06 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 394/1000\n",
      "45/45 - 0s - loss: 5.1289e-06 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9722 - 52ms/epoch - 1ms/step\n",
      "Epoch 395/1000\n",
      "45/45 - 0s - loss: 4.8221e-06 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 396/1000\n",
      "45/45 - 0s - loss: 4.7350e-06 - accuracy: 1.0000 - val_loss: 0.2061 - val_accuracy: 0.9722 - 64ms/epoch - 1ms/step\n",
      "Epoch 397/1000\n",
      "45/45 - 0s - loss: 4.6034e-06 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9722 - 60ms/epoch - 1ms/step\n",
      "Epoch 398/1000\n",
      "45/45 - 0s - loss: 4.6955e-06 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.9722 - 56ms/epoch - 1ms/step\n",
      "Epoch 399/1000\n",
      "45/45 - 0s - loss: 4.4025e-06 - accuracy: 1.0000 - val_loss: 0.2071 - val_accuracy: 0.9750 - 52ms/epoch - 1ms/step\n",
      "Epoch 400/1000\n",
      "45/45 - 0s - loss: 4.3023e-06 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 401/1000\n",
      "45/45 - 0s - loss: 4.1231e-06 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9750 - 52ms/epoch - 1ms/step\n",
      "Epoch 402/1000\n",
      "45/45 - 0s - loss: 4.0640e-06 - accuracy: 1.0000 - val_loss: 0.2093 - val_accuracy: 0.9750 - 51ms/epoch - 1ms/step\n",
      "Epoch 403/1000\n",
      "45/45 - 0s - loss: 3.9950e-06 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9750 - 51ms/epoch - 1ms/step\n",
      "Epoch 404/1000\n",
      "45/45 - 0s - loss: 3.9654e-06 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9722 - 52ms/epoch - 1ms/step\n",
      "Epoch 405/1000\n",
      "45/45 - 0s - loss: 3.8935e-06 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 406/1000\n",
      "45/45 - 0s - loss: 3.7722e-06 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 407/1000\n",
      "45/45 - 0s - loss: 3.7647e-06 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9722 - 84ms/epoch - 2ms/step\n",
      "Epoch 408/1000\n",
      "45/45 - 0s - loss: 3.6197e-06 - accuracy: 1.0000 - val_loss: 0.2131 - val_accuracy: 0.9722 - 64ms/epoch - 1ms/step\n",
      "Epoch 409/1000\n",
      "45/45 - 0s - loss: 3.6983e-06 - accuracy: 1.0000 - val_loss: 0.2136 - val_accuracy: 0.9722 - 56ms/epoch - 1ms/step\n",
      "Epoch 410/1000\n",
      "45/45 - 0s - loss: 3.3884e-06 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9750 - 54ms/epoch - 1ms/step\n",
      "Epoch 411/1000\n",
      "45/45 - 0s - loss: 3.2903e-06 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 0.9750 - 54ms/epoch - 1ms/step\n",
      "Epoch 412/1000\n",
      "45/45 - 0s - loss: 3.2474e-06 - accuracy: 1.0000 - val_loss: 0.2119 - val_accuracy: 0.9750 - 55ms/epoch - 1ms/step\n",
      "Epoch 413/1000\n",
      "45/45 - 0s - loss: 3.1584e-06 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9750 - 99ms/epoch - 2ms/step\n",
      "Epoch 414/1000\n",
      "45/45 - 0s - loss: 3.0935e-06 - accuracy: 1.0000 - val_loss: 0.2136 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 415/1000\n",
      "45/45 - 0s - loss: 3.0396e-06 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9722 - 53ms/epoch - 1ms/step\n",
      "Epoch 416/1000\n",
      "45/45 - 0s - loss: 2.9503e-06 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9750 - 53ms/epoch - 1ms/step\n",
      "Epoch 417/1000\n",
      "45/45 - 0s - loss: 2.9552e-06 - accuracy: 1.0000 - val_loss: 0.2146 - val_accuracy: 0.9722 - 56ms/epoch - 1ms/step\n",
      "Epoch 418/1000\n",
      "45/45 - 0s - loss: 2.8571e-06 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9750 - 51ms/epoch - 1ms/step\n",
      "Epoch 419/1000\n",
      "45/45 - 0s - loss: 2.7009e-06 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9722 - 52ms/epoch - 1ms/step\n",
      "Epoch 420/1000\n",
      "45/45 - 0s - loss: 2.6943e-06 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9722 - 55ms/epoch - 1ms/step\n",
      "Epoch 421/1000\n",
      "45/45 - 0s - loss: 2.6708e-06 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9750 - 53ms/epoch - 1ms/step\n",
      "Epoch 422/1000\n",
      "45/45 - 0s - loss: 2.5569e-06 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9722 - 55ms/epoch - 1ms/step\n",
      "Epoch 423/1000\n",
      "45/45 - 0s - loss: 2.4806e-06 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 424/1000\n",
      "45/45 - 0s - loss: 2.4787e-06 - accuracy: 1.0000 - val_loss: 0.2165 - val_accuracy: 0.9722 - 52ms/epoch - 1ms/step\n",
      "Epoch 425/1000\n",
      "45/45 - 0s - loss: 2.4258e-06 - accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.9722 - 57ms/epoch - 1ms/step\n",
      "Epoch 426/1000\n",
      "45/45 - 0s - loss: 2.3341e-06 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9750 - 84ms/epoch - 2ms/step\n",
      "Epoch 427/1000\n",
      "45/45 - 0s - loss: 2.2747e-06 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 428/1000\n",
      "45/45 - 0s - loss: 2.3988e-06 - accuracy: 1.0000 - val_loss: 0.2191 - val_accuracy: 0.9750 - 66ms/epoch - 1ms/step\n",
      "Epoch 429/1000\n",
      "45/45 - 0s - loss: 2.2163e-06 - accuracy: 1.0000 - val_loss: 0.2214 - val_accuracy: 0.9722 - 59ms/epoch - 1ms/step\n",
      "Epoch 430/1000\n",
      "45/45 - 0s - loss: 2.1362e-06 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9722 - 58ms/epoch - 1ms/step\n",
      "Epoch 431/1000\n",
      "45/45 - 0s - loss: 2.1495e-06 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9722 - 58ms/epoch - 1ms/step\n",
      "Epoch 432/1000\n",
      "45/45 - 0s - loss: 2.0510e-06 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9750 - 53ms/epoch - 1ms/step\n",
      "Epoch 433/1000\n",
      "45/45 - 0s - loss: 2.0694e-06 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9722 - 66ms/epoch - 1ms/step\n",
      "Epoch 434/1000\n",
      "45/45 - 0s - loss: 2.0178e-06 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9750 - 69ms/epoch - 2ms/step\n",
      "Epoch 435/1000\n",
      "45/45 - 0s - loss: 1.8744e-06 - accuracy: 1.0000 - val_loss: 0.2233 - val_accuracy: 0.9750 - 54ms/epoch - 1ms/step\n",
      "Epoch 436/1000\n",
      "45/45 - 0s - loss: 1.8778e-06 - accuracy: 1.0000 - val_loss: 0.2226 - val_accuracy: 0.9750 - 75ms/epoch - 2ms/step\n",
      "Epoch 437/1000\n",
      "45/45 - 0s - loss: 1.8197e-06 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.9722 - 87ms/epoch - 2ms/step\n",
      "Epoch 438/1000\n",
      "45/45 - 0s - loss: 1.8209e-06 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9750 - 100ms/epoch - 2ms/step\n",
      "Epoch 439/1000\n",
      "45/45 - 0s - loss: 1.7505e-06 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9722 - 88ms/epoch - 2ms/step\n",
      "Epoch 440/1000\n",
      "45/45 - 0s - loss: 1.6848e-06 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9750 - 89ms/epoch - 2ms/step\n",
      "Epoch 441/1000\n",
      "45/45 - 0s - loss: 1.6751e-06 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 0.9722 - 134ms/epoch - 3ms/step\n",
      "Epoch 442/1000\n",
      "45/45 - 0s - loss: 1.6375e-06 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 443/1000\n",
      "45/45 - 0s - loss: 1.5831e-06 - accuracy: 1.0000 - val_loss: 0.2251 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 444/1000\n",
      "45/45 - 0s - loss: 1.5597e-06 - accuracy: 1.0000 - val_loss: 0.2275 - val_accuracy: 0.9722 - 58ms/epoch - 1ms/step\n",
      "Epoch 445/1000\n",
      "45/45 - 0s - loss: 1.5203e-06 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 446/1000\n",
      "45/45 - 0s - loss: 1.5104e-06 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9750 - 81ms/epoch - 2ms/step\n",
      "Epoch 447/1000\n",
      "45/45 - 0s - loss: 1.4178e-06 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 0.9722 - 67ms/epoch - 1ms/step\n",
      "Epoch 448/1000\n",
      "45/45 - 0s - loss: 1.4239e-06 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.9722 - 56ms/epoch - 1ms/step\n",
      "Epoch 449/1000\n",
      "45/45 - 0s - loss: 1.4046e-06 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 450/1000\n",
      "45/45 - 0s - loss: 1.3520e-06 - accuracy: 1.0000 - val_loss: 0.2296 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 451/1000\n",
      "45/45 - 0s - loss: 1.3461e-06 - accuracy: 1.0000 - val_loss: 0.2296 - val_accuracy: 0.9750 - 55ms/epoch - 1ms/step\n",
      "Epoch 452/1000\n",
      "45/45 - 0s - loss: 1.2852e-06 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.9722 - 57ms/epoch - 1ms/step\n",
      "Epoch 453/1000\n",
      "45/45 - 0s - loss: 1.2750e-06 - accuracy: 1.0000 - val_loss: 0.2300 - val_accuracy: 0.9722 - 57ms/epoch - 1ms/step\n",
      "Epoch 454/1000\n",
      "45/45 - 0s - loss: 1.2458e-06 - accuracy: 1.0000 - val_loss: 0.2282 - val_accuracy: 0.9722 - 57ms/epoch - 1ms/step\n",
      "Epoch 455/1000\n",
      "45/45 - 0s - loss: 1.2462e-06 - accuracy: 1.0000 - val_loss: 0.2300 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 456/1000\n",
      "45/45 - 0s - loss: 1.1866e-06 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 457/1000\n",
      "45/45 - 0s - loss: 1.1562e-06 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9722 - 54ms/epoch - 1ms/step\n",
      "Epoch 458/1000\n",
      "45/45 - 0s - loss: 1.1392e-06 - accuracy: 1.0000 - val_loss: 0.2323 - val_accuracy: 0.9750 - 55ms/epoch - 1ms/step\n",
      "Epoch 459/1000\n",
      "45/45 - 0s - loss: 1.0991e-06 - accuracy: 1.0000 - val_loss: 0.2324 - val_accuracy: 0.9750 - 55ms/epoch - 1ms/step\n",
      "Epoch 460/1000\n",
      "45/45 - 0s - loss: 1.1128e-06 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 461/1000\n",
      "45/45 - 0s - loss: 1.0676e-06 - accuracy: 1.0000 - val_loss: 0.2327 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 462/1000\n",
      "45/45 - 0s - loss: 1.0841e-06 - accuracy: 1.0000 - val_loss: 0.2337 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 463/1000\n",
      "45/45 - 0s - loss: 1.0015e-06 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 464/1000\n",
      "45/45 - 0s - loss: 9.9340e-07 - accuracy: 1.0000 - val_loss: 0.2341 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 465/1000\n",
      "45/45 - 0s - loss: 9.9855e-07 - accuracy: 1.0000 - val_loss: 0.2345 - val_accuracy: 0.9750 - 54ms/epoch - 1ms/step\n",
      "Epoch 466/1000\n",
      "45/45 - 0s - loss: 9.6022e-07 - accuracy: 1.0000 - val_loss: 0.2346 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 467/1000\n",
      "45/45 - 0s - loss: 9.2024e-07 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9750 - 77ms/epoch - 2ms/step\n",
      "Epoch 468/1000\n",
      "45/45 - 0s - loss: 9.3633e-07 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9722 - 54ms/epoch - 1ms/step\n",
      "Epoch 469/1000\n",
      "45/45 - 0s - loss: 9.0721e-07 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 470/1000\n",
      "45/45 - 0s - loss: 8.9900e-07 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 471/1000\n",
      "45/45 - 0s - loss: 8.4607e-07 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9722 - 53ms/epoch - 1ms/step\n",
      "Epoch 472/1000\n",
      "45/45 - 0s - loss: 8.5337e-07 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 473/1000\n",
      "45/45 - 0s - loss: 8.2127e-07 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 0.9750 - 55ms/epoch - 1ms/step\n",
      "Epoch 474/1000\n",
      "45/45 - 0s - loss: 7.9962e-07 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9722 - 101ms/epoch - 2ms/step\n",
      "Epoch 475/1000\n",
      "45/45 - 0s - loss: 8.0327e-07 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9722 - 64ms/epoch - 1ms/step\n",
      "Epoch 476/1000\n",
      "45/45 - 0s - loss: 7.5798e-07 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 477/1000\n",
      "45/45 - 0s - loss: 7.4354e-07 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9722 - 61ms/epoch - 1ms/step\n",
      "Epoch 478/1000\n",
      "45/45 - 0s - loss: 7.3798e-07 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 479/1000\n",
      "45/45 - 0s - loss: 7.0911e-07 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 480/1000\n",
      "45/45 - 0s - loss: 7.1144e-07 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9750 - 66ms/epoch - 1ms/step\n",
      "Epoch 481/1000\n",
      "45/45 - 0s - loss: 6.8365e-07 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 482/1000\n",
      "45/45 - 0s - loss: 6.7012e-07 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 483/1000\n",
      "45/45 - 0s - loss: 6.5262e-07 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 484/1000\n",
      "45/45 - 0s - loss: 6.3180e-07 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 485/1000\n",
      "45/45 - 0s - loss: 6.2491e-07 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 486/1000\n",
      "45/45 - 0s - loss: 6.1040e-07 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 487/1000\n",
      "45/45 - 0s - loss: 5.9505e-07 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 488/1000\n",
      "45/45 - 0s - loss: 6.0301e-07 - accuracy: 1.0000 - val_loss: 0.2439 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 489/1000\n",
      "45/45 - 0s - loss: 5.9745e-07 - accuracy: 1.0000 - val_loss: 0.2441 - val_accuracy: 0.9722 - 60ms/epoch - 1ms/step\n",
      "Epoch 490/1000\n",
      "45/45 - 0s - loss: 5.5291e-07 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 491/1000\n",
      "45/45 - 0s - loss: 5.4619e-07 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 492/1000\n",
      "45/45 - 0s - loss: 5.4262e-07 - accuracy: 1.0000 - val_loss: 0.2443 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 493/1000\n",
      "45/45 - 0s - loss: 5.3374e-07 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 494/1000\n",
      "45/45 - 0s - loss: 5.1607e-07 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9750 - 83ms/epoch - 2ms/step\n",
      "Epoch 495/1000\n",
      "45/45 - 0s - loss: 5.1234e-07 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9750 - 63ms/epoch - 1ms/step\n",
      "Epoch 496/1000\n",
      "45/45 - 0s - loss: 4.9990e-07 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 0.9750 - 64ms/epoch - 1ms/step\n",
      "Epoch 497/1000\n",
      "45/45 - 0s - loss: 5.0255e-07 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 498/1000\n",
      "45/45 - 0s - loss: 4.8878e-07 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.9750 - 64ms/epoch - 1ms/step\n",
      "Epoch 499/1000\n",
      "45/45 - 0s - loss: 4.6572e-07 - accuracy: 1.0000 - val_loss: 0.2477 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 500/1000\n",
      "45/45 - 0s - loss: 4.5875e-07 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9722 - 62ms/epoch - 1ms/step\n",
      "Epoch 501/1000\n",
      "45/45 - 0s - loss: 4.4199e-07 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 502/1000\n",
      "45/45 - 0s - loss: 4.4846e-07 - accuracy: 1.0000 - val_loss: 0.2477 - val_accuracy: 0.9722 - 58ms/epoch - 1ms/step\n",
      "Epoch 503/1000\n",
      "45/45 - 0s - loss: 4.3071e-07 - accuracy: 1.0000 - val_loss: 0.2488 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 504/1000\n",
      "45/45 - 0s - loss: 4.1254e-07 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9722 - 62ms/epoch - 1ms/step\n",
      "Epoch 505/1000\n",
      "45/45 - 0s - loss: 4.0997e-07 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 506/1000\n",
      "45/45 - 0s - loss: 3.8890e-07 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9750 - 63ms/epoch - 1ms/step\n",
      "Epoch 507/1000\n",
      "45/45 - 0s - loss: 3.9380e-07 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 508/1000\n",
      "45/45 - 0s - loss: 3.8135e-07 - accuracy: 1.0000 - val_loss: 0.2505 - val_accuracy: 0.9750 - 103ms/epoch - 2ms/step\n",
      "Epoch 509/1000\n",
      "45/45 - 0s - loss: 3.7239e-07 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.9722 - 69ms/epoch - 2ms/step\n",
      "Epoch 510/1000\n",
      "45/45 - 0s - loss: 3.6493e-07 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.9722 - 65ms/epoch - 1ms/step\n",
      "Epoch 511/1000\n",
      "45/45 - 0s - loss: 3.6916e-07 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9722 - 66ms/epoch - 1ms/step\n",
      "Epoch 512/1000\n",
      "45/45 - 0s - loss: 3.5033e-07 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.9750 - 67ms/epoch - 1ms/step\n",
      "Epoch 513/1000\n",
      "45/45 - 0s - loss: 3.4493e-07 - accuracy: 1.0000 - val_loss: 0.2514 - val_accuracy: 0.9750 - 63ms/epoch - 1ms/step\n",
      "Epoch 514/1000\n",
      "45/45 - 0s - loss: 3.2909e-07 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.9722 - 58ms/epoch - 1ms/step\n",
      "Epoch 515/1000\n",
      "45/45 - 0s - loss: 3.2950e-07 - accuracy: 1.0000 - val_loss: 0.2535 - val_accuracy: 0.9722 - 60ms/epoch - 1ms/step\n",
      "Epoch 516/1000\n",
      "45/45 - 0s - loss: 3.1905e-07 - accuracy: 1.0000 - val_loss: 0.2519 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 517/1000\n",
      "45/45 - 0s - loss: 3.2478e-07 - accuracy: 1.0000 - val_loss: 0.2535 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 518/1000\n",
      "45/45 - 0s - loss: 3.1200e-07 - accuracy: 1.0000 - val_loss: 0.2531 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 519/1000\n",
      "45/45 - 0s - loss: 3.0080e-07 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 520/1000\n",
      "45/45 - 0s - loss: 2.9815e-07 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9722 - 83ms/epoch - 2ms/step\n",
      "Epoch 521/1000\n",
      "45/45 - 0s - loss: 2.9093e-07 - accuracy: 1.0000 - val_loss: 0.2536 - val_accuracy: 0.9722 - 61ms/epoch - 1ms/step\n",
      "Epoch 522/1000\n",
      "45/45 - 0s - loss: 2.9018e-07 - accuracy: 1.0000 - val_loss: 0.2561 - val_accuracy: 0.9750 - 63ms/epoch - 1ms/step\n",
      "Epoch 523/1000\n",
      "45/45 - 0s - loss: 2.7815e-07 - accuracy: 1.0000 - val_loss: 0.2551 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 524/1000\n",
      "45/45 - 0s - loss: 2.7525e-07 - accuracy: 1.0000 - val_loss: 0.2561 - val_accuracy: 0.9750 - 64ms/epoch - 1ms/step\n",
      "Epoch 525/1000\n",
      "45/45 - 0s - loss: 2.7235e-07 - accuracy: 1.0000 - val_loss: 0.2560 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 526/1000\n",
      "45/45 - 0s - loss: 2.6248e-07 - accuracy: 1.0000 - val_loss: 0.2572 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 527/1000\n",
      "45/45 - 0s - loss: 2.5957e-07 - accuracy: 1.0000 - val_loss: 0.2567 - val_accuracy: 0.9722 - 62ms/epoch - 1ms/step\n",
      "Epoch 528/1000\n",
      "45/45 - 0s - loss: 2.5567e-07 - accuracy: 1.0000 - val_loss: 0.2571 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 529/1000\n",
      "45/45 - 0s - loss: 2.5061e-07 - accuracy: 1.0000 - val_loss: 0.2578 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 530/1000\n",
      "45/45 - 0s - loss: 2.4116e-07 - accuracy: 1.0000 - val_loss: 0.2560 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 531/1000\n",
      "45/45 - 0s - loss: 2.3950e-07 - accuracy: 1.0000 - val_loss: 0.2571 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 532/1000\n",
      "45/45 - 0s - loss: 2.3842e-07 - accuracy: 1.0000 - val_loss: 0.2582 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 533/1000\n",
      "45/45 - 0s - loss: 2.2705e-07 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 534/1000\n",
      "45/45 - 0s - loss: 2.2108e-07 - accuracy: 1.0000 - val_loss: 0.2593 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 535/1000\n",
      "45/45 - 0s - loss: 2.1984e-07 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.9722 - 60ms/epoch - 1ms/step\n",
      "Epoch 536/1000\n",
      "45/45 - 0s - loss: 2.1303e-07 - accuracy: 1.0000 - val_loss: 0.2593 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 537/1000\n",
      "45/45 - 0s - loss: 2.1668e-07 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.9750 - 101ms/epoch - 2ms/step\n",
      "Epoch 538/1000\n",
      "45/45 - 0s - loss: 2.0897e-07 - accuracy: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.9750 - 72ms/epoch - 2ms/step\n",
      "Epoch 539/1000\n",
      "45/45 - 0s - loss: 2.1088e-07 - accuracy: 1.0000 - val_loss: 0.2612 - val_accuracy: 0.9750 - 64ms/epoch - 1ms/step\n",
      "Epoch 540/1000\n",
      "45/45 - 0s - loss: 1.9835e-07 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9750 - 66ms/epoch - 1ms/step\n",
      "Epoch 541/1000\n",
      "45/45 - 0s - loss: 1.9495e-07 - accuracy: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 542/1000\n",
      "45/45 - 0s - loss: 1.9072e-07 - accuracy: 1.0000 - val_loss: 0.2619 - val_accuracy: 0.9750 - 63ms/epoch - 1ms/step\n",
      "Epoch 543/1000\n",
      "45/45 - 0s - loss: 1.8690e-07 - accuracy: 1.0000 - val_loss: 0.2619 - val_accuracy: 0.9750 - 63ms/epoch - 1ms/step\n",
      "Epoch 544/1000\n",
      "45/45 - 0s - loss: 1.8682e-07 - accuracy: 1.0000 - val_loss: 0.2621 - val_accuracy: 0.9750 - 63ms/epoch - 1ms/step\n",
      "Epoch 545/1000\n",
      "45/45 - 0s - loss: 1.8035e-07 - accuracy: 1.0000 - val_loss: 0.2616 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 546/1000\n",
      "45/45 - 0s - loss: 1.7869e-07 - accuracy: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.9750 - 80ms/epoch - 2ms/step\n",
      "Epoch 547/1000\n",
      "45/45 - 0s - loss: 1.7214e-07 - accuracy: 1.0000 - val_loss: 0.2630 - val_accuracy: 0.9722 - 60ms/epoch - 1ms/step\n",
      "Epoch 548/1000\n",
      "45/45 - 0s - loss: 1.7313e-07 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 549/1000\n",
      "45/45 - 0s - loss: 1.7238e-07 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 550/1000\n",
      "45/45 - 0s - loss: 1.6757e-07 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9750 - 55ms/epoch - 1ms/step\n",
      "Epoch 551/1000\n",
      "45/45 - 0s - loss: 1.6558e-07 - accuracy: 1.0000 - val_loss: 0.2637 - val_accuracy: 0.9722 - 59ms/epoch - 1ms/step\n",
      "Epoch 552/1000\n",
      "45/45 - 0s - loss: 1.5787e-07 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.9722 - 64ms/epoch - 1ms/step\n",
      "Epoch 553/1000\n",
      "45/45 - 0s - loss: 1.5936e-07 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 554/1000\n",
      "45/45 - 0s - loss: 1.5895e-07 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9722 - 58ms/epoch - 1ms/step\n",
      "Epoch 555/1000\n",
      "45/45 - 0s - loss: 1.5471e-07 - accuracy: 1.0000 - val_loss: 0.2649 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 556/1000\n",
      "45/45 - 0s - loss: 1.4650e-07 - accuracy: 1.0000 - val_loss: 0.2647 - val_accuracy: 0.9722 - 60ms/epoch - 1ms/step\n",
      "Epoch 557/1000\n",
      "45/45 - 0s - loss: 1.4318e-07 - accuracy: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 558/1000\n",
      "45/45 - 0s - loss: 1.4078e-07 - accuracy: 1.0000 - val_loss: 0.2653 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 559/1000\n",
      "45/45 - 0s - loss: 1.4376e-07 - accuracy: 1.0000 - val_loss: 0.2660 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 560/1000\n",
      "45/45 - 0s - loss: 1.3522e-07 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 561/1000\n",
      "45/45 - 0s - loss: 1.3348e-07 - accuracy: 1.0000 - val_loss: 0.2676 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 562/1000\n",
      "45/45 - 0s - loss: 1.3348e-07 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 563/1000\n",
      "45/45 - 0s - loss: 1.2950e-07 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 564/1000\n",
      "45/45 - 0s - loss: 1.2991e-07 - accuracy: 1.0000 - val_loss: 0.2683 - val_accuracy: 0.9722 - 63ms/epoch - 1ms/step\n",
      "Epoch 565/1000\n",
      "45/45 - 0s - loss: 1.2668e-07 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 566/1000\n",
      "45/45 - 0s - loss: 1.2717e-07 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 567/1000\n",
      "45/45 - 0s - loss: 1.2079e-07 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 568/1000\n",
      "45/45 - 0s - loss: 1.1855e-07 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.9750 - 67ms/epoch - 1ms/step\n",
      "Epoch 569/1000\n",
      "45/45 - 0s - loss: 1.2037e-07 - accuracy: 1.0000 - val_loss: 0.2689 - val_accuracy: 0.9722 - 123ms/epoch - 3ms/step\n",
      "Epoch 570/1000\n",
      "45/45 - 0s - loss: 1.1730e-07 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9722 - 82ms/epoch - 2ms/step\n",
      "Epoch 571/1000\n",
      "45/45 - 0s - loss: 1.1224e-07 - accuracy: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 572/1000\n",
      "45/45 - 0s - loss: 1.1033e-07 - accuracy: 1.0000 - val_loss: 0.2691 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 573/1000\n",
      "45/45 - 0s - loss: 1.0917e-07 - accuracy: 1.0000 - val_loss: 0.2693 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 574/1000\n",
      "45/45 - 0s - loss: 1.1025e-07 - accuracy: 1.0000 - val_loss: 0.2697 - val_accuracy: 0.9750 - 66ms/epoch - 1ms/step\n",
      "Epoch 575/1000\n",
      "45/45 - 0s - loss: 1.0569e-07 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9750 - 65ms/epoch - 1ms/step\n",
      "Epoch 576/1000\n",
      "45/45 - 0s - loss: 1.0146e-07 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.9750 - 65ms/epoch - 1ms/step\n",
      "Epoch 577/1000\n",
      "45/45 - 0s - loss: 1.0395e-07 - accuracy: 1.0000 - val_loss: 0.2698 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 578/1000\n",
      "45/45 - 0s - loss: 9.8138e-08 - accuracy: 1.0000 - val_loss: 0.2716 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 579/1000\n",
      "45/45 - 0s - loss: 9.9465e-08 - accuracy: 1.0000 - val_loss: 0.2717 - val_accuracy: 0.9722 - 60ms/epoch - 1ms/step\n",
      "Epoch 580/1000\n",
      "45/45 - 0s - loss: 9.6313e-08 - accuracy: 1.0000 - val_loss: 0.2712 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 581/1000\n",
      "45/45 - 0s - loss: 9.4654e-08 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 582/1000\n",
      "45/45 - 0s - loss: 9.3244e-08 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 583/1000\n",
      "45/45 - 0s - loss: 9.1253e-08 - accuracy: 1.0000 - val_loss: 0.2729 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 584/1000\n",
      "45/45 - 0s - loss: 9.0008e-08 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9750 - 64ms/epoch - 1ms/step\n",
      "Epoch 585/1000\n",
      "45/45 - 0s - loss: 8.8349e-08 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 586/1000\n",
      "45/45 - 0s - loss: 8.6441e-08 - accuracy: 1.0000 - val_loss: 0.2733 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 587/1000\n",
      "45/45 - 0s - loss: 8.2293e-08 - accuracy: 1.0000 - val_loss: 0.2732 - val_accuracy: 0.9750 - 55ms/epoch - 1ms/step\n",
      "Epoch 588/1000\n",
      "45/45 - 0s - loss: 8.2127e-08 - accuracy: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 589/1000\n",
      "45/45 - 0s - loss: 8.0883e-08 - accuracy: 1.0000 - val_loss: 0.2743 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 590/1000\n",
      "45/45 - 0s - loss: 8.2210e-08 - accuracy: 1.0000 - val_loss: 0.2730 - val_accuracy: 0.9722 - 60ms/epoch - 1ms/step\n",
      "Epoch 591/1000\n",
      "45/45 - 0s - loss: 8.0883e-08 - accuracy: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 592/1000\n",
      "45/45 - 0s - loss: 7.8311e-08 - accuracy: 1.0000 - val_loss: 0.2746 - val_accuracy: 0.9750 - 64ms/epoch - 1ms/step\n",
      "Epoch 593/1000\n",
      "45/45 - 0s - loss: 7.7814e-08 - accuracy: 1.0000 - val_loss: 0.2745 - val_accuracy: 0.9750 - 84ms/epoch - 2ms/step\n",
      "Epoch 594/1000\n",
      "45/45 - 0s - loss: 7.7067e-08 - accuracy: 1.0000 - val_loss: 0.2749 - val_accuracy: 0.9750 - 65ms/epoch - 1ms/step\n",
      "Epoch 595/1000\n",
      "45/45 - 0s - loss: 7.6238e-08 - accuracy: 1.0000 - val_loss: 0.2739 - val_accuracy: 0.9722 - 59ms/epoch - 1ms/step\n",
      "Epoch 596/1000\n",
      "45/45 - 0s - loss: 7.6818e-08 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 597/1000\n",
      "45/45 - 0s - loss: 7.2090e-08 - accuracy: 1.0000 - val_loss: 0.2757 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 598/1000\n",
      "45/45 - 0s - loss: 7.0182e-08 - accuracy: 1.0000 - val_loss: 0.2761 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 599/1000\n",
      "45/45 - 0s - loss: 7.0431e-08 - accuracy: 1.0000 - val_loss: 0.2760 - val_accuracy: 0.9750 - 106ms/epoch - 2ms/step\n",
      "Epoch 600/1000\n",
      "45/45 - 0s - loss: 6.8357e-08 - accuracy: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.9750 - 65ms/epoch - 1ms/step\n",
      "Epoch 601/1000\n",
      "45/45 - 0s - loss: 6.9352e-08 - accuracy: 1.0000 - val_loss: 0.2764 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 602/1000\n",
      "45/45 - 0s - loss: 6.8025e-08 - accuracy: 1.0000 - val_loss: 0.2763 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 603/1000\n",
      "45/45 - 0s - loss: 6.6283e-08 - accuracy: 1.0000 - val_loss: 0.2755 - val_accuracy: 0.9722 - 60ms/epoch - 1ms/step\n",
      "Epoch 604/1000\n",
      "45/45 - 0s - loss: 6.6532e-08 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 605/1000\n",
      "45/45 - 0s - loss: 6.4872e-08 - accuracy: 1.0000 - val_loss: 0.2774 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 606/1000\n",
      "45/45 - 0s - loss: 6.2550e-08 - accuracy: 1.0000 - val_loss: 0.2767 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 607/1000\n",
      "45/45 - 0s - loss: 6.2798e-08 - accuracy: 1.0000 - val_loss: 0.2773 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 608/1000\n",
      "45/45 - 0s - loss: 6.2135e-08 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9750 - 63ms/epoch - 1ms/step\n",
      "Epoch 609/1000\n",
      "45/45 - 0s - loss: 6.0890e-08 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 610/1000\n",
      "45/45 - 0s - loss: 5.9812e-08 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 611/1000\n",
      "45/45 - 0s - loss: 5.8319e-08 - accuracy: 1.0000 - val_loss: 0.2773 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 612/1000\n",
      "45/45 - 0s - loss: 5.7074e-08 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 613/1000\n",
      "45/45 - 0s - loss: 5.5249e-08 - accuracy: 1.0000 - val_loss: 0.2794 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 614/1000\n",
      "45/45 - 0s - loss: 5.5747e-08 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 615/1000\n",
      "45/45 - 0s - loss: 5.5996e-08 - accuracy: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.9750 - 84ms/epoch - 2ms/step\n",
      "Epoch 616/1000\n",
      "45/45 - 0s - loss: 5.3341e-08 - accuracy: 1.0000 - val_loss: 0.2793 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 617/1000\n",
      "45/45 - 0s - loss: 5.4337e-08 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 618/1000\n",
      "45/45 - 0s - loss: 5.3590e-08 - accuracy: 1.0000 - val_loss: 0.2811 - val_accuracy: 0.9722 - 57ms/epoch - 1ms/step\n",
      "Epoch 619/1000\n",
      "45/45 - 0s - loss: 5.3590e-08 - accuracy: 1.0000 - val_loss: 0.2802 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 620/1000\n",
      "45/45 - 0s - loss: 5.0355e-08 - accuracy: 1.0000 - val_loss: 0.2799 - val_accuracy: 0.9750 - 63ms/epoch - 1ms/step\n",
      "Epoch 621/1000\n",
      "45/45 - 0s - loss: 4.9359e-08 - accuracy: 1.0000 - val_loss: 0.2805 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 622/1000\n",
      "45/45 - 0s - loss: 5.1516e-08 - accuracy: 1.0000 - val_loss: 0.2804 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 623/1000\n",
      "45/45 - 0s - loss: 4.8779e-08 - accuracy: 1.0000 - val_loss: 0.2808 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 624/1000\n",
      "45/45 - 0s - loss: 4.9028e-08 - accuracy: 1.0000 - val_loss: 0.2805 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 625/1000\n",
      "45/45 - 0s - loss: 4.6622e-08 - accuracy: 1.0000 - val_loss: 0.2819 - val_accuracy: 0.9722 - 59ms/epoch - 1ms/step\n",
      "Epoch 626/1000\n",
      "45/45 - 0s - loss: 4.8862e-08 - accuracy: 1.0000 - val_loss: 0.2809 - val_accuracy: 0.9750 - 63ms/epoch - 1ms/step\n",
      "Epoch 627/1000\n",
      "45/45 - 0s - loss: 4.5626e-08 - accuracy: 1.0000 - val_loss: 0.2807 - val_accuracy: 0.9750 - 95ms/epoch - 2ms/step\n",
      "Epoch 628/1000\n",
      "45/45 - 0s - loss: 4.4465e-08 - accuracy: 1.0000 - val_loss: 0.2822 - val_accuracy: 0.9750 - 72ms/epoch - 2ms/step\n",
      "Epoch 629/1000\n",
      "45/45 - 0s - loss: 4.4963e-08 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 630/1000\n",
      "45/45 - 0s - loss: 4.4880e-08 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.9750 - 64ms/epoch - 1ms/step\n",
      "Epoch 631/1000\n",
      "45/45 - 0s - loss: 4.4797e-08 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 632/1000\n",
      "45/45 - 0s - loss: 4.4382e-08 - accuracy: 1.0000 - val_loss: 0.2823 - val_accuracy: 0.9750 - 63ms/epoch - 1ms/step\n",
      "Epoch 633/1000\n",
      "45/45 - 0s - loss: 4.3469e-08 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 634/1000\n",
      "45/45 - 0s - loss: 4.1976e-08 - accuracy: 1.0000 - val_loss: 0.2821 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 635/1000\n",
      "45/45 - 0s - loss: 4.1561e-08 - accuracy: 1.0000 - val_loss: 0.2827 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 636/1000\n",
      "45/45 - 0s - loss: 4.1230e-08 - accuracy: 1.0000 - val_loss: 0.2826 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 637/1000\n",
      "45/45 - 0s - loss: 4.1810e-08 - accuracy: 1.0000 - val_loss: 0.2837 - val_accuracy: 0.9750 - 73ms/epoch - 2ms/step\n",
      "Epoch 638/1000\n",
      "45/45 - 0s - loss: 4.1396e-08 - accuracy: 1.0000 - val_loss: 0.2831 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 639/1000\n",
      "45/45 - 0s - loss: 4.1313e-08 - accuracy: 1.0000 - val_loss: 0.2833 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 640/1000\n",
      "45/45 - 0s - loss: 3.9488e-08 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 0.9750 - 65ms/epoch - 1ms/step\n",
      "Epoch 641/1000\n",
      "45/45 - 0s - loss: 3.8824e-08 - accuracy: 1.0000 - val_loss: 0.2843 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 642/1000\n",
      "45/45 - 0s - loss: 3.9156e-08 - accuracy: 1.0000 - val_loss: 0.2845 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 643/1000\n",
      "45/45 - 0s - loss: 3.6916e-08 - accuracy: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 644/1000\n",
      "45/45 - 0s - loss: 3.7165e-08 - accuracy: 1.0000 - val_loss: 0.2832 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 645/1000\n",
      "45/45 - 0s - loss: 3.6418e-08 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 646/1000\n",
      "45/45 - 0s - loss: 3.7580e-08 - accuracy: 1.0000 - val_loss: 0.2846 - val_accuracy: 0.9750 - 64ms/epoch - 1ms/step\n",
      "Epoch 647/1000\n",
      "45/45 - 0s - loss: 3.5920e-08 - accuracy: 1.0000 - val_loss: 0.2842 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 648/1000\n",
      "45/45 - 0s - loss: 3.6003e-08 - accuracy: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 649/1000\n",
      "45/45 - 0s - loss: 3.5506e-08 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 650/1000\n",
      "45/45 - 0s - loss: 3.4344e-08 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 0.9750 - 63ms/epoch - 1ms/step\n",
      "Epoch 651/1000\n",
      "45/45 - 0s - loss: 3.4510e-08 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 652/1000\n",
      "45/45 - 0s - loss: 3.4261e-08 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 653/1000\n",
      "45/45 - 0s - loss: 3.3929e-08 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 654/1000\n",
      "45/45 - 0s - loss: 3.3349e-08 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 655/1000\n",
      "45/45 - 0s - loss: 3.2851e-08 - accuracy: 1.0000 - val_loss: 0.2852 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 656/1000\n",
      "45/45 - 0s - loss: 3.2685e-08 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.9750 - 104ms/epoch - 2ms/step\n",
      "Epoch 657/1000\n",
      "45/45 - 0s - loss: 3.3349e-08 - accuracy: 1.0000 - val_loss: 0.2867 - val_accuracy: 0.9750 - 69ms/epoch - 2ms/step\n",
      "Epoch 658/1000\n",
      "45/45 - 0s - loss: 3.3266e-08 - accuracy: 1.0000 - val_loss: 0.2858 - val_accuracy: 0.9750 - 85ms/epoch - 2ms/step\n",
      "Epoch 659/1000\n",
      "45/45 - 0s - loss: 3.0445e-08 - accuracy: 1.0000 - val_loss: 0.2854 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 660/1000\n",
      "45/45 - 0s - loss: 3.2270e-08 - accuracy: 1.0000 - val_loss: 0.2855 - val_accuracy: 0.9750 - 66ms/epoch - 1ms/step\n",
      "Epoch 661/1000\n",
      "45/45 - 0s - loss: 3.0362e-08 - accuracy: 1.0000 - val_loss: 0.2862 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 662/1000\n",
      "45/45 - 0s - loss: 3.0362e-08 - accuracy: 1.0000 - val_loss: 0.2865 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 663/1000\n",
      "45/45 - 0s - loss: 3.0196e-08 - accuracy: 1.0000 - val_loss: 0.2866 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 664/1000\n",
      "45/45 - 0s - loss: 2.9450e-08 - accuracy: 1.0000 - val_loss: 0.2862 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 665/1000\n",
      "45/45 - 0s - loss: 2.9699e-08 - accuracy: 1.0000 - val_loss: 0.2867 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 666/1000\n",
      "45/45 - 0s - loss: 2.9616e-08 - accuracy: 1.0000 - val_loss: 0.2863 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 667/1000\n",
      "45/45 - 0s - loss: 2.9201e-08 - accuracy: 1.0000 - val_loss: 0.2868 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 668/1000\n",
      "45/45 - 0s - loss: 2.8952e-08 - accuracy: 1.0000 - val_loss: 0.2866 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 669/1000\n",
      "45/45 - 0s - loss: 2.8039e-08 - accuracy: 1.0000 - val_loss: 0.2872 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 670/1000\n",
      "45/45 - 0s - loss: 2.8039e-08 - accuracy: 1.0000 - val_loss: 0.2869 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 671/1000\n",
      "45/45 - 0s - loss: 2.7293e-08 - accuracy: 1.0000 - val_loss: 0.2871 - val_accuracy: 0.9750 - 72ms/epoch - 2ms/step\n",
      "Epoch 672/1000\n",
      "45/45 - 0s - loss: 2.6629e-08 - accuracy: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 673/1000\n",
      "45/45 - 0s - loss: 2.7127e-08 - accuracy: 1.0000 - val_loss: 0.2870 - val_accuracy: 0.9750 - 64ms/epoch - 1ms/step\n",
      "Epoch 674/1000\n",
      "45/45 - 0s - loss: 2.7625e-08 - accuracy: 1.0000 - val_loss: 0.2878 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 675/1000\n",
      "45/45 - 0s - loss: 2.7210e-08 - accuracy: 1.0000 - val_loss: 0.2876 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 676/1000\n",
      "45/45 - 0s - loss: 2.5966e-08 - accuracy: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 677/1000\n",
      "45/45 - 0s - loss: 2.5468e-08 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 678/1000\n",
      "45/45 - 0s - loss: 2.5883e-08 - accuracy: 1.0000 - val_loss: 0.2885 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 679/1000\n",
      "45/45 - 0s - loss: 2.5053e-08 - accuracy: 1.0000 - val_loss: 0.2879 - val_accuracy: 0.9750 - 83ms/epoch - 2ms/step\n",
      "Epoch 680/1000\n",
      "45/45 - 0s - loss: 2.6131e-08 - accuracy: 1.0000 - val_loss: 0.2891 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 681/1000\n",
      "45/45 - 0s - loss: 2.5219e-08 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 682/1000\n",
      "45/45 - 0s - loss: 2.4970e-08 - accuracy: 1.0000 - val_loss: 0.2885 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 683/1000\n",
      "45/45 - 0s - loss: 2.3809e-08 - accuracy: 1.0000 - val_loss: 0.2883 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 684/1000\n",
      "45/45 - 0s - loss: 2.4306e-08 - accuracy: 1.0000 - val_loss: 0.2883 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 685/1000\n",
      "45/45 - 0s - loss: 2.3975e-08 - accuracy: 1.0000 - val_loss: 0.2886 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 686/1000\n",
      "45/45 - 0s - loss: 2.3477e-08 - accuracy: 1.0000 - val_loss: 0.2893 - val_accuracy: 0.9750 - 111ms/epoch - 2ms/step\n",
      "Epoch 687/1000\n",
      "45/45 - 0s - loss: 2.3643e-08 - accuracy: 1.0000 - val_loss: 0.2895 - val_accuracy: 0.9750 - 66ms/epoch - 1ms/step\n",
      "Epoch 688/1000\n",
      "45/45 - 0s - loss: 2.3560e-08 - accuracy: 1.0000 - val_loss: 0.2893 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 689/1000\n",
      "45/45 - 0s - loss: 2.3062e-08 - accuracy: 1.0000 - val_loss: 0.2903 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 690/1000\n",
      "45/45 - 0s - loss: 2.3145e-08 - accuracy: 1.0000 - val_loss: 0.2892 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 691/1000\n",
      "45/45 - 0s - loss: 2.3228e-08 - accuracy: 1.0000 - val_loss: 0.2895 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 692/1000\n",
      "45/45 - 0s - loss: 2.2150e-08 - accuracy: 1.0000 - val_loss: 0.2894 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 693/1000\n",
      "45/45 - 0s - loss: 2.2232e-08 - accuracy: 1.0000 - val_loss: 0.2897 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 694/1000\n",
      "45/45 - 0s - loss: 2.1569e-08 - accuracy: 1.0000 - val_loss: 0.2897 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 695/1000\n",
      "45/45 - 0s - loss: 2.1320e-08 - accuracy: 1.0000 - val_loss: 0.2896 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 696/1000\n",
      "45/45 - 0s - loss: 2.0739e-08 - accuracy: 1.0000 - val_loss: 0.2896 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 697/1000\n",
      "45/45 - 0s - loss: 2.1984e-08 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 698/1000\n",
      "45/45 - 0s - loss: 2.1154e-08 - accuracy: 1.0000 - val_loss: 0.2899 - val_accuracy: 0.9750 - 82ms/epoch - 2ms/step\n",
      "Epoch 699/1000\n",
      "45/45 - 0s - loss: 2.1320e-08 - accuracy: 1.0000 - val_loss: 0.2903 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 700/1000\n",
      "45/45 - 0s - loss: 2.0739e-08 - accuracy: 1.0000 - val_loss: 0.2903 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 701/1000\n",
      "45/45 - 0s - loss: 2.0159e-08 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 702/1000\n",
      "45/45 - 0s - loss: 2.0076e-08 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 703/1000\n",
      "45/45 - 0s - loss: 2.0324e-08 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.9750 - 64ms/epoch - 1ms/step\n",
      "Epoch 704/1000\n",
      "45/45 - 0s - loss: 2.0076e-08 - accuracy: 1.0000 - val_loss: 0.2902 - val_accuracy: 0.9750 - 55ms/epoch - 1ms/step\n",
      "Epoch 705/1000\n",
      "45/45 - 0s - loss: 2.0159e-08 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 706/1000\n",
      "45/45 - 0s - loss: 1.9495e-08 - accuracy: 1.0000 - val_loss: 0.2911 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 707/1000\n",
      "45/45 - 0s - loss: 1.9329e-08 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 708/1000\n",
      "45/45 - 0s - loss: 1.8997e-08 - accuracy: 1.0000 - val_loss: 0.2911 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 709/1000\n",
      "45/45 - 0s - loss: 1.8997e-08 - accuracy: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 710/1000\n",
      "45/45 - 0s - loss: 1.8665e-08 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 711/1000\n",
      "45/45 - 0s - loss: 1.8831e-08 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 712/1000\n",
      "45/45 - 0s - loss: 1.8997e-08 - accuracy: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 713/1000\n",
      "45/45 - 0s - loss: 1.8168e-08 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 714/1000\n",
      "45/45 - 0s - loss: 1.8831e-08 - accuracy: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.9750 - 115ms/epoch - 3ms/step\n",
      "Epoch 715/1000\n",
      "45/45 - 0s - loss: 1.7836e-08 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 716/1000\n",
      "45/45 - 0s - loss: 1.8334e-08 - accuracy: 1.0000 - val_loss: 0.2916 - val_accuracy: 0.9750 - 64ms/epoch - 1ms/step\n",
      "Epoch 717/1000\n",
      "45/45 - 0s - loss: 1.7172e-08 - accuracy: 1.0000 - val_loss: 0.2917 - val_accuracy: 0.9750 - 86ms/epoch - 2ms/step\n",
      "Epoch 718/1000\n",
      "45/45 - 0s - loss: 1.7753e-08 - accuracy: 1.0000 - val_loss: 0.2919 - val_accuracy: 0.9750 - 63ms/epoch - 1ms/step\n",
      "Epoch 719/1000\n",
      "45/45 - 0s - loss: 1.8168e-08 - accuracy: 1.0000 - val_loss: 0.2923 - val_accuracy: 0.9750 - 64ms/epoch - 1ms/step\n",
      "Epoch 720/1000\n",
      "45/45 - 0s - loss: 1.7172e-08 - accuracy: 1.0000 - val_loss: 0.2921 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 721/1000\n",
      "45/45 - 0s - loss: 1.6840e-08 - accuracy: 1.0000 - val_loss: 0.2925 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 722/1000\n",
      "45/45 - 0s - loss: 1.6923e-08 - accuracy: 1.0000 - val_loss: 0.2924 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 723/1000\n",
      "45/45 - 0s - loss: 1.7172e-08 - accuracy: 1.0000 - val_loss: 0.2923 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 724/1000\n",
      "45/45 - 0s - loss: 1.6674e-08 - accuracy: 1.0000 - val_loss: 0.2924 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 725/1000\n",
      "45/45 - 0s - loss: 1.6591e-08 - accuracy: 1.0000 - val_loss: 0.2929 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 726/1000\n",
      "45/45 - 0s - loss: 1.6425e-08 - accuracy: 1.0000 - val_loss: 0.2923 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 727/1000\n",
      "45/45 - 0s - loss: 1.6508e-08 - accuracy: 1.0000 - val_loss: 0.2923 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 728/1000\n",
      "45/45 - 0s - loss: 1.6923e-08 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 729/1000\n",
      "45/45 - 0s - loss: 1.6425e-08 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 730/1000\n",
      "45/45 - 0s - loss: 1.6260e-08 - accuracy: 1.0000 - val_loss: 0.2927 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 731/1000\n",
      "45/45 - 0s - loss: 1.6094e-08 - accuracy: 1.0000 - val_loss: 0.2931 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 732/1000\n",
      "45/45 - 0s - loss: 1.5928e-08 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 733/1000\n",
      "45/45 - 0s - loss: 1.5928e-08 - accuracy: 1.0000 - val_loss: 0.2929 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 734/1000\n",
      "45/45 - 0s - loss: 1.6011e-08 - accuracy: 1.0000 - val_loss: 0.2931 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 735/1000\n",
      "45/45 - 0s - loss: 1.7089e-08 - accuracy: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.9750 - 86ms/epoch - 2ms/step\n",
      "Epoch 736/1000\n",
      "45/45 - 0s - loss: 1.5845e-08 - accuracy: 1.0000 - val_loss: 0.2931 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 737/1000\n",
      "45/45 - 0s - loss: 1.5430e-08 - accuracy: 1.0000 - val_loss: 0.2937 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 738/1000\n",
      "45/45 - 0s - loss: 1.5347e-08 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 739/1000\n",
      "45/45 - 0s - loss: 1.6177e-08 - accuracy: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 740/1000\n",
      "45/45 - 0s - loss: 1.5181e-08 - accuracy: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.9750 - 111ms/epoch - 2ms/step\n",
      "Epoch 741/1000\n",
      "45/45 - 0s - loss: 1.4932e-08 - accuracy: 1.0000 - val_loss: 0.2943 - val_accuracy: 0.9750 - 71ms/epoch - 2ms/step\n",
      "Epoch 742/1000\n",
      "45/45 - 0s - loss: 1.5015e-08 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.9750 - 63ms/epoch - 1ms/step\n",
      "Epoch 743/1000\n",
      "45/45 - 0s - loss: 1.5181e-08 - accuracy: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.9750 - 63ms/epoch - 1ms/step\n",
      "Epoch 744/1000\n",
      "45/45 - 0s - loss: 1.4600e-08 - accuracy: 1.0000 - val_loss: 0.2938 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 745/1000\n",
      "45/45 - 0s - loss: 1.5181e-08 - accuracy: 1.0000 - val_loss: 0.2947 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 746/1000\n",
      "45/45 - 0s - loss: 1.4683e-08 - accuracy: 1.0000 - val_loss: 0.2943 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 747/1000\n",
      "45/45 - 0s - loss: 1.4020e-08 - accuracy: 1.0000 - val_loss: 0.2945 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 748/1000\n",
      "45/45 - 0s - loss: 1.4766e-08 - accuracy: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 749/1000\n",
      "45/45 - 0s - loss: 1.4683e-08 - accuracy: 1.0000 - val_loss: 0.2949 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 750/1000\n",
      "45/45 - 0s - loss: 1.4352e-08 - accuracy: 1.0000 - val_loss: 0.2947 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 751/1000\n",
      "45/45 - 0s - loss: 1.4020e-08 - accuracy: 1.0000 - val_loss: 0.2945 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 752/1000\n",
      "45/45 - 0s - loss: 1.4352e-08 - accuracy: 1.0000 - val_loss: 0.2946 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 753/1000\n",
      "45/45 - 0s - loss: 1.4103e-08 - accuracy: 1.0000 - val_loss: 0.2952 - val_accuracy: 0.9750 - 80ms/epoch - 2ms/step\n",
      "Epoch 754/1000\n",
      "45/45 - 0s - loss: 1.4186e-08 - accuracy: 1.0000 - val_loss: 0.2947 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 755/1000\n",
      "45/45 - 0s - loss: 1.4103e-08 - accuracy: 1.0000 - val_loss: 0.2949 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 756/1000\n",
      "45/45 - 0s - loss: 1.3688e-08 - accuracy: 1.0000 - val_loss: 0.2950 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 757/1000\n",
      "45/45 - 0s - loss: 1.4352e-08 - accuracy: 1.0000 - val_loss: 0.2951 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 758/1000\n",
      "45/45 - 0s - loss: 1.4352e-08 - accuracy: 1.0000 - val_loss: 0.2956 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 759/1000\n",
      "45/45 - 0s - loss: 1.3356e-08 - accuracy: 1.0000 - val_loss: 0.2951 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 760/1000\n",
      "45/45 - 0s - loss: 1.3854e-08 - accuracy: 1.0000 - val_loss: 0.2957 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 761/1000\n",
      "45/45 - 0s - loss: 1.3854e-08 - accuracy: 1.0000 - val_loss: 0.2954 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 762/1000\n",
      "45/45 - 0s - loss: 1.3190e-08 - accuracy: 1.0000 - val_loss: 0.2953 - val_accuracy: 0.9750 - 64ms/epoch - 1ms/step\n",
      "Epoch 763/1000\n",
      "45/45 - 0s - loss: 1.3605e-08 - accuracy: 1.0000 - val_loss: 0.2955 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 764/1000\n",
      "45/45 - 0s - loss: 1.3439e-08 - accuracy: 1.0000 - val_loss: 0.2958 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 765/1000\n",
      "45/45 - 0s - loss: 1.3937e-08 - accuracy: 1.0000 - val_loss: 0.2959 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 766/1000\n",
      "45/45 - 0s - loss: 1.3356e-08 - accuracy: 1.0000 - val_loss: 0.2956 - val_accuracy: 0.9750 - 106ms/epoch - 2ms/step\n",
      "Epoch 767/1000\n",
      "45/45 - 0s - loss: 1.3688e-08 - accuracy: 1.0000 - val_loss: 0.2957 - val_accuracy: 0.9750 - 67ms/epoch - 1ms/step\n",
      "Epoch 768/1000\n",
      "45/45 - 0s - loss: 1.3024e-08 - accuracy: 1.0000 - val_loss: 0.2958 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 769/1000\n",
      "45/45 - 0s - loss: 1.3024e-08 - accuracy: 1.0000 - val_loss: 0.2960 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 770/1000\n",
      "45/45 - 0s - loss: 1.2527e-08 - accuracy: 1.0000 - val_loss: 0.2957 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 771/1000\n",
      "45/45 - 0s - loss: 1.3190e-08 - accuracy: 1.0000 - val_loss: 0.2960 - val_accuracy: 0.9750 - 82ms/epoch - 2ms/step\n",
      "Epoch 772/1000\n",
      "45/45 - 0s - loss: 1.3439e-08 - accuracy: 1.0000 - val_loss: 0.2965 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 773/1000\n",
      "45/45 - 0s - loss: 1.2444e-08 - accuracy: 1.0000 - val_loss: 0.2961 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 774/1000\n",
      "45/45 - 0s - loss: 1.3107e-08 - accuracy: 1.0000 - val_loss: 0.2957 - val_accuracy: 0.9750 - 56ms/epoch - 1ms/step\n",
      "Epoch 775/1000\n",
      "45/45 - 0s - loss: 1.3024e-08 - accuracy: 1.0000 - val_loss: 0.2960 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 776/1000\n",
      "45/45 - 0s - loss: 1.2692e-08 - accuracy: 1.0000 - val_loss: 0.2962 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 777/1000\n",
      "45/45 - 0s - loss: 1.2941e-08 - accuracy: 1.0000 - val_loss: 0.2959 - val_accuracy: 0.9750 - 63ms/epoch - 1ms/step\n",
      "Epoch 778/1000\n",
      "45/45 - 0s - loss: 1.2527e-08 - accuracy: 1.0000 - val_loss: 0.2959 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 779/1000\n",
      "45/45 - 0s - loss: 1.2609e-08 - accuracy: 1.0000 - val_loss: 0.2962 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 780/1000\n",
      "45/45 - 0s - loss: 1.2692e-08 - accuracy: 1.0000 - val_loss: 0.2960 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 781/1000\n",
      "45/45 - 0s - loss: 1.2527e-08 - accuracy: 1.0000 - val_loss: 0.2964 - val_accuracy: 0.9750 - 63ms/epoch - 1ms/step\n",
      "Epoch 782/1000\n",
      "45/45 - 0s - loss: 1.2278e-08 - accuracy: 1.0000 - val_loss: 0.2964 - val_accuracy: 0.9750 - 63ms/epoch - 1ms/step\n",
      "Epoch 783/1000\n",
      "45/45 - 0s - loss: 1.2361e-08 - accuracy: 1.0000 - val_loss: 0.2965 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 784/1000\n",
      "45/45 - 0s - loss: 1.2361e-08 - accuracy: 1.0000 - val_loss: 0.2962 - val_accuracy: 0.9750 - 63ms/epoch - 1ms/step\n",
      "Epoch 785/1000\n",
      "45/45 - 0s - loss: 1.2195e-08 - accuracy: 1.0000 - val_loss: 0.2968 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 786/1000\n",
      "45/45 - 0s - loss: 1.2029e-08 - accuracy: 1.0000 - val_loss: 0.2963 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 787/1000\n",
      "45/45 - 0s - loss: 1.1863e-08 - accuracy: 1.0000 - val_loss: 0.2964 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 788/1000\n",
      "45/45 - 0s - loss: 1.2112e-08 - accuracy: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.9750 - 82ms/epoch - 2ms/step\n",
      "Epoch 789/1000\n",
      "45/45 - 0s - loss: 1.2029e-08 - accuracy: 1.0000 - val_loss: 0.2967 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 790/1000\n",
      "45/45 - 0s - loss: 1.2195e-08 - accuracy: 1.0000 - val_loss: 0.2962 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 791/1000\n",
      "45/45 - 0s - loss: 1.1365e-08 - accuracy: 1.0000 - val_loss: 0.2964 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 792/1000\n",
      "45/45 - 0s - loss: 1.1614e-08 - accuracy: 1.0000 - val_loss: 0.2964 - val_accuracy: 0.9750 - 102ms/epoch - 2ms/step\n",
      "Epoch 793/1000\n",
      "45/45 - 0s - loss: 1.1531e-08 - accuracy: 1.0000 - val_loss: 0.2966 - val_accuracy: 0.9750 - 72ms/epoch - 2ms/step\n",
      "Epoch 794/1000\n",
      "45/45 - 0s - loss: 1.1531e-08 - accuracy: 1.0000 - val_loss: 0.2970 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 795/1000\n",
      "45/45 - 0s - loss: 1.1697e-08 - accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 796/1000\n",
      "45/45 - 0s - loss: 1.1033e-08 - accuracy: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 797/1000\n",
      "45/45 - 0s - loss: 1.1531e-08 - accuracy: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 798/1000\n",
      "45/45 - 0s - loss: 1.1531e-08 - accuracy: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 799/1000\n",
      "45/45 - 0s - loss: 1.0701e-08 - accuracy: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 800/1000\n",
      "45/45 - 0s - loss: 1.1780e-08 - accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 801/1000\n",
      "45/45 - 0s - loss: 1.1033e-08 - accuracy: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 802/1000\n",
      "45/45 - 0s - loss: 1.0619e-08 - accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 803/1000\n",
      "45/45 - 0s - loss: 1.0453e-08 - accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 804/1000\n",
      "45/45 - 0s - loss: 1.0867e-08 - accuracy: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 805/1000\n",
      "45/45 - 0s - loss: 1.1282e-08 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.9750 - 83ms/epoch - 2ms/step\n",
      "Epoch 806/1000\n",
      "45/45 - 0s - loss: 1.0784e-08 - accuracy: 1.0000 - val_loss: 0.2967 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 807/1000\n",
      "45/45 - 0s - loss: 1.0784e-08 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 808/1000\n",
      "45/45 - 0s - loss: 1.0287e-08 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 809/1000\n",
      "45/45 - 0s - loss: 1.0701e-08 - accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 810/1000\n",
      "45/45 - 0s - loss: 1.0867e-08 - accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.9750 - 58ms/epoch - 1ms/step\n",
      "Epoch 811/1000\n",
      "45/45 - 0s - loss: 1.0950e-08 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 812/1000\n",
      "45/45 - 0s - loss: 1.0701e-08 - accuracy: 1.0000 - val_loss: 0.2978 - val_accuracy: 0.9750 - 67ms/epoch - 1ms/step\n",
      "Epoch 813/1000\n",
      "45/45 - 0s - loss: 9.7889e-09 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.9750 - 57ms/epoch - 1ms/step\n",
      "Epoch 814/1000\n",
      "45/45 - 0s - loss: 1.0370e-08 - accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 815/1000\n",
      "45/45 - 0s - loss: 1.0287e-08 - accuracy: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.9750 - 63ms/epoch - 1ms/step\n",
      "Epoch 816/1000\n",
      "45/45 - 0s - loss: 1.0121e-08 - accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.9750 - 59ms/epoch - 1ms/step\n",
      "Epoch 817/1000\n",
      "45/45 - 0s - loss: 1.0204e-08 - accuracy: 1.0000 - val_loss: 0.2976 - val_accuracy: 0.9750 - 117ms/epoch - 3ms/step\n",
      "Epoch 818/1000\n",
      "45/45 - 0s - loss: 9.7889e-09 - accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.9750 - 64ms/epoch - 1ms/step\n",
      "Epoch 819/1000\n",
      "45/45 - 0s - loss: 1.0370e-08 - accuracy: 1.0000 - val_loss: 0.2979 - val_accuracy: 0.9750 - 68ms/epoch - 2ms/step\n",
      "Epoch 820/1000\n",
      "45/45 - 0s - loss: 1.0204e-08 - accuracy: 1.0000 - val_loss: 0.2978 - val_accuracy: 0.9750 - 71ms/epoch - 2ms/step\n",
      "Epoch 821/1000\n",
      "45/45 - 0s - loss: 1.0038e-08 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.9750 - 91ms/epoch - 2ms/step\n",
      "Epoch 822/1000\n",
      "45/45 - 0s - loss: 9.5401e-09 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.9750 - 76ms/epoch - 2ms/step\n",
      "Epoch 823/1000\n",
      "45/45 - 0s - loss: 9.6230e-09 - accuracy: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.9750 - 72ms/epoch - 2ms/step\n",
      "Epoch 824/1000\n",
      "45/45 - 0s - loss: 9.1253e-09 - accuracy: 1.0000 - val_loss: 0.2980 - val_accuracy: 0.9750 - 72ms/epoch - 2ms/step\n",
      "Epoch 825/1000\n",
      "45/45 - 0s - loss: 9.6230e-09 - accuracy: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.9750 - 69ms/epoch - 2ms/step\n",
      "Epoch 826/1000\n",
      "45/45 - 0s - loss: 9.5401e-09 - accuracy: 1.0000 - val_loss: 0.2978 - val_accuracy: 0.9750 - 67ms/epoch - 1ms/step\n",
      "Epoch 827/1000\n",
      "45/45 - 0s - loss: 9.6230e-09 - accuracy: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.9750 - 69ms/epoch - 2ms/step\n",
      "Epoch 828/1000\n",
      "45/45 - 0s - loss: 9.7060e-09 - accuracy: 1.0000 - val_loss: 0.2979 - val_accuracy: 0.9750 - 74ms/epoch - 2ms/step\n",
      "Epoch 829/1000\n",
      "45/45 - 0s - loss: 9.4571e-09 - accuracy: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.9750 - 72ms/epoch - 2ms/step\n",
      "Epoch 830/1000\n",
      "45/45 - 0s - loss: 9.5401e-09 - accuracy: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.9750 - 73ms/epoch - 2ms/step\n",
      "Epoch 831/1000\n",
      "45/45 - 0s - loss: 9.6230e-09 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.9750 - 70ms/epoch - 2ms/step\n",
      "Epoch 832/1000\n",
      "45/45 - 0s - loss: 9.2082e-09 - accuracy: 1.0000 - val_loss: 0.2980 - val_accuracy: 0.9750 - 74ms/epoch - 2ms/step\n",
      "Epoch 833/1000\n",
      "45/45 - 0s - loss: 9.0423e-09 - accuracy: 1.0000 - val_loss: 0.2980 - val_accuracy: 0.9750 - 72ms/epoch - 2ms/step\n",
      "Epoch 834/1000\n",
      "45/45 - 0s - loss: 9.2912e-09 - accuracy: 1.0000 - val_loss: 0.2980 - val_accuracy: 0.9750 - 69ms/epoch - 2ms/step\n",
      "Epoch 835/1000\n",
      "45/45 - 0s - loss: 9.2912e-09 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.9750 - 77ms/epoch - 2ms/step\n",
      "Epoch 836/1000\n",
      "45/45 - 0s - loss: 8.8764e-09 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.9750 - 73ms/epoch - 2ms/step\n",
      "Epoch 837/1000\n",
      "45/45 - 0s - loss: 8.8764e-09 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.9750 - 91ms/epoch - 2ms/step\n",
      "Epoch 838/1000\n",
      "45/45 - 0s - loss: 9.1253e-09 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.9750 - 71ms/epoch - 2ms/step\n",
      "Epoch 839/1000\n",
      "45/45 - 0s - loss: 8.8764e-09 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.9750 - 78ms/epoch - 2ms/step\n",
      "Epoch 840/1000\n",
      "45/45 - 0s - loss: 9.1253e-09 - accuracy: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.9750 - 72ms/epoch - 2ms/step\n",
      "Epoch 841/1000\n",
      "45/45 - 0s - loss: 8.3787e-09 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.9750 - 77ms/epoch - 2ms/step\n",
      "Epoch 842/1000\n",
      "45/45 - 0s - loss: 9.1253e-09 - accuracy: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.9750 - 79ms/epoch - 2ms/step\n",
      "Epoch 843/1000\n",
      "45/45 - 0s - loss: 9.0423e-09 - accuracy: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.9750 - 75ms/epoch - 2ms/step\n",
      "Epoch 844/1000\n",
      "45/45 - 0s - loss: 8.6275e-09 - accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 0.9750 - 129ms/epoch - 3ms/step\n",
      "Epoch 845/1000\n",
      "45/45 - 0s - loss: 9.0423e-09 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.9750 - 85ms/epoch - 2ms/step\n",
      "Epoch 846/1000\n",
      "45/45 - 0s - loss: 8.2957e-09 - accuracy: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.9750 - 76ms/epoch - 2ms/step\n",
      "Epoch 847/1000\n",
      "45/45 - 0s - loss: 8.0468e-09 - accuracy: 1.0000 - val_loss: 0.2987 - val_accuracy: 0.9750 - 77ms/epoch - 2ms/step\n",
      "Epoch 848/1000\n",
      "45/45 - 0s - loss: 8.2957e-09 - accuracy: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.9750 - 73ms/epoch - 2ms/step\n",
      "Epoch 849/1000\n",
      "45/45 - 0s - loss: 8.6275e-09 - accuracy: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.9750 - 75ms/epoch - 2ms/step\n",
      "Epoch 850/1000\n",
      "45/45 - 0s - loss: 8.6275e-09 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.9750 - 78ms/epoch - 2ms/step\n",
      "Epoch 851/1000\n",
      "45/45 - 0s - loss: 7.8809e-09 - accuracy: 1.0000 - val_loss: 0.2987 - val_accuracy: 0.9750 - 82ms/epoch - 2ms/step\n",
      "Epoch 852/1000\n",
      "45/45 - 0s - loss: 8.0468e-09 - accuracy: 1.0000 - val_loss: 0.2987 - val_accuracy: 0.9750 - 81ms/epoch - 2ms/step\n",
      "Epoch 853/1000\n",
      "45/45 - 0s - loss: 8.3787e-09 - accuracy: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.9750 - 100ms/epoch - 2ms/step\n",
      "Epoch 854/1000\n",
      "45/45 - 0s - loss: 8.2127e-09 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.9750 - 83ms/epoch - 2ms/step\n",
      "Epoch 855/1000\n",
      "45/45 - 0s - loss: 8.2127e-09 - accuracy: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.9750 - 80ms/epoch - 2ms/step\n",
      "Epoch 856/1000\n",
      "45/45 - 0s - loss: 8.2957e-09 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.9750 - 81ms/epoch - 2ms/step\n",
      "Epoch 857/1000\n",
      "45/45 - 0s - loss: 8.0468e-09 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.9750 - 77ms/epoch - 2ms/step\n",
      "Epoch 858/1000\n",
      "45/45 - 0s - loss: 7.8809e-09 - accuracy: 1.0000 - val_loss: 0.2991 - val_accuracy: 0.9750 - 83ms/epoch - 2ms/step\n",
      "Epoch 859/1000\n",
      "45/45 - 0s - loss: 7.7980e-09 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.9750 - 84ms/epoch - 2ms/step\n",
      "Epoch 860/1000\n",
      "45/45 - 0s - loss: 8.0468e-09 - accuracy: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.9750 - 72ms/epoch - 2ms/step\n",
      "Epoch 861/1000\n",
      "45/45 - 0s - loss: 8.2127e-09 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.9750 - 79ms/epoch - 2ms/step\n",
      "Epoch 862/1000\n",
      "45/45 - 0s - loss: 8.1298e-09 - accuracy: 1.0000 - val_loss: 0.2992 - val_accuracy: 0.9750 - 76ms/epoch - 2ms/step\n",
      "Epoch 863/1000\n",
      "45/45 - 0s - loss: 8.1298e-09 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.9750 - 83ms/epoch - 2ms/step\n",
      "Epoch 864/1000\n",
      "45/45 - 0s - loss: 7.6320e-09 - accuracy: 1.0000 - val_loss: 0.2992 - val_accuracy: 0.9750 - 77ms/epoch - 2ms/step\n",
      "Epoch 865/1000\n",
      "45/45 - 0s - loss: 7.7980e-09 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.9750 - 76ms/epoch - 2ms/step\n",
      "Epoch 866/1000\n",
      "45/45 - 0s - loss: 8.0468e-09 - accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 0.9750 - 83ms/epoch - 2ms/step\n",
      "Epoch 867/1000\n",
      "45/45 - 0s - loss: 7.9639e-09 - accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 0.9750 - 83ms/epoch - 2ms/step\n",
      "Epoch 868/1000\n",
      "45/45 - 0s - loss: 7.7150e-09 - accuracy: 1.0000 - val_loss: 0.2992 - val_accuracy: 0.9750 - 69ms/epoch - 2ms/step\n",
      "Epoch 869/1000\n",
      "45/45 - 0s - loss: 7.7980e-09 - accuracy: 1.0000 - val_loss: 0.2993 - val_accuracy: 0.9750 - 150ms/epoch - 3ms/step\n",
      "Epoch 870/1000\n",
      "45/45 - 0s - loss: 7.3002e-09 - accuracy: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.9750 - 77ms/epoch - 2ms/step\n",
      "Epoch 871/1000\n",
      "45/45 - 0s - loss: 7.7980e-09 - accuracy: 1.0000 - val_loss: 0.2993 - val_accuracy: 0.9750 - 79ms/epoch - 2ms/step\n",
      "Epoch 872/1000\n",
      "45/45 - 0s - loss: 7.6320e-09 - accuracy: 1.0000 - val_loss: 0.2991 - val_accuracy: 0.9750 - 76ms/epoch - 2ms/step\n",
      "Epoch 873/1000\n",
      "45/45 - 0s - loss: 7.8809e-09 - accuracy: 1.0000 - val_loss: 0.2993 - val_accuracy: 0.9750 - 70ms/epoch - 2ms/step\n",
      "Epoch 874/1000\n",
      "45/45 - 0s - loss: 7.8809e-09 - accuracy: 1.0000 - val_loss: 0.2993 - val_accuracy: 0.9750 - 73ms/epoch - 2ms/step\n",
      "Epoch 875/1000\n",
      "45/45 - 0s - loss: 7.3002e-09 - accuracy: 1.0000 - val_loss: 0.2992 - val_accuracy: 0.9750 - 72ms/epoch - 2ms/step\n",
      "Epoch 876/1000\n",
      "45/45 - 0s - loss: 7.0513e-09 - accuracy: 1.0000 - val_loss: 0.2992 - val_accuracy: 0.9750 - 76ms/epoch - 2ms/step\n",
      "Epoch 877/1000\n",
      "45/45 - 0s - loss: 7.3832e-09 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.9750 - 72ms/epoch - 2ms/step\n",
      "Epoch 878/1000\n",
      "45/45 - 0s - loss: 7.9639e-09 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 0.9750 - 74ms/epoch - 2ms/step\n",
      "Epoch 879/1000\n",
      "45/45 - 0s - loss: 7.6320e-09 - accuracy: 1.0000 - val_loss: 0.2992 - val_accuracy: 0.9750 - 69ms/epoch - 2ms/step\n",
      "Epoch 880/1000\n",
      "45/45 - 0s - loss: 7.9639e-09 - accuracy: 1.0000 - val_loss: 0.2991 - val_accuracy: 0.9750 - 66ms/epoch - 1ms/step\n",
      "Epoch 881/1000\n",
      "45/45 - 0s - loss: 7.2173e-09 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 0.9750 - 66ms/epoch - 1ms/step\n",
      "Epoch 882/1000\n",
      "45/45 - 0s - loss: 7.0513e-09 - accuracy: 1.0000 - val_loss: 0.2995 - val_accuracy: 0.9750 - 67ms/epoch - 1ms/step\n",
      "Epoch 883/1000\n",
      "45/45 - 0s - loss: 7.1343e-09 - accuracy: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.9750 - 71ms/epoch - 2ms/step\n",
      "Epoch 884/1000\n",
      "45/45 - 0s - loss: 6.8854e-09 - accuracy: 1.0000 - val_loss: 0.2993 - val_accuracy: 0.9750 - 103ms/epoch - 2ms/step\n",
      "Epoch 885/1000\n",
      "45/45 - 0s - loss: 7.5491e-09 - accuracy: 1.0000 - val_loss: 0.2994 - val_accuracy: 0.9750 - 76ms/epoch - 2ms/step\n",
      "Epoch 886/1000\n",
      "45/45 - 0s - loss: 7.3002e-09 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 0.9750 - 79ms/epoch - 2ms/step\n",
      "Epoch 887/1000\n",
      "45/45 - 0s - loss: 7.4661e-09 - accuracy: 1.0000 - val_loss: 0.2994 - val_accuracy: 0.9750 - 77ms/epoch - 2ms/step\n",
      "Epoch 888/1000\n",
      "45/45 - 0s - loss: 6.8854e-09 - accuracy: 1.0000 - val_loss: 0.2995 - val_accuracy: 0.9750 - 69ms/epoch - 2ms/step\n",
      "Epoch 889/1000\n",
      "45/45 - 0s - loss: 7.3832e-09 - accuracy: 1.0000 - val_loss: 0.3004 - val_accuracy: 0.9750 - 81ms/epoch - 2ms/step\n",
      "Epoch 890/1000\n",
      "45/45 - 0s - loss: 7.9639e-09 - accuracy: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.9750 - 69ms/epoch - 2ms/step\n",
      "Epoch 891/1000\n",
      "45/45 - 0s - loss: 7.4661e-09 - accuracy: 1.0000 - val_loss: 0.2999 - val_accuracy: 0.9750 - 76ms/epoch - 2ms/step\n",
      "Epoch 892/1000\n",
      "45/45 - 0s - loss: 7.5491e-09 - accuracy: 1.0000 - val_loss: 0.2999 - val_accuracy: 0.9750 - 74ms/epoch - 2ms/step\n",
      "Epoch 893/1000\n",
      "45/45 - 0s - loss: 7.2173e-09 - accuracy: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.9750 - 128ms/epoch - 3ms/step\n",
      "Epoch 894/1000\n",
      "45/45 - 0s - loss: 6.8025e-09 - accuracy: 1.0000 - val_loss: 0.2999 - val_accuracy: 0.9750 - 81ms/epoch - 2ms/step\n",
      "Epoch 895/1000\n",
      "45/45 - 0s - loss: 7.0513e-09 - accuracy: 1.0000 - val_loss: 0.2999 - val_accuracy: 0.9750 - 77ms/epoch - 2ms/step\n",
      "Epoch 896/1000\n",
      "45/45 - 0s - loss: 7.6320e-09 - accuracy: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.9750 - 78ms/epoch - 2ms/step\n",
      "Epoch 897/1000\n",
      "45/45 - 0s - loss: 7.3002e-09 - accuracy: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.9750 - 73ms/epoch - 2ms/step\n",
      "Epoch 898/1000\n",
      "45/45 - 0s - loss: 6.8025e-09 - accuracy: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.9750 - 70ms/epoch - 2ms/step\n",
      "Epoch 899/1000\n",
      "45/45 - 0s - loss: 7.3832e-09 - accuracy: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.9750 - 99ms/epoch - 2ms/step\n",
      "Epoch 900/1000\n",
      "45/45 - 0s - loss: 7.2173e-09 - accuracy: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.9750 - 75ms/epoch - 2ms/step\n",
      "Epoch 901/1000\n",
      "45/45 - 0s - loss: 7.2173e-09 - accuracy: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.9750 - 76ms/epoch - 2ms/step\n",
      "Epoch 902/1000\n",
      "45/45 - 0s - loss: 7.1343e-09 - accuracy: 1.0000 - val_loss: 0.2999 - val_accuracy: 0.9750 - 73ms/epoch - 2ms/step\n",
      "Epoch 903/1000\n",
      "45/45 - 0s - loss: 7.3002e-09 - accuracy: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.9750 - 79ms/epoch - 2ms/step\n",
      "Epoch 904/1000\n",
      "45/45 - 0s - loss: 7.2173e-09 - accuracy: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.9750 - 76ms/epoch - 2ms/step\n",
      "Epoch 905/1000\n",
      "45/45 - 0s - loss: 6.9684e-09 - accuracy: 1.0000 - val_loss: 0.3002 - val_accuracy: 0.9750 - 72ms/epoch - 2ms/step\n",
      "Epoch 906/1000\n",
      "45/45 - 0s - loss: 6.9684e-09 - accuracy: 1.0000 - val_loss: 0.3001 - val_accuracy: 0.9750 - 80ms/epoch - 2ms/step\n",
      "Epoch 907/1000\n",
      "45/45 - 0s - loss: 6.6366e-09 - accuracy: 1.0000 - val_loss: 0.3003 - val_accuracy: 0.9750 - 71ms/epoch - 2ms/step\n",
      "Epoch 908/1000\n",
      "45/45 - 0s - loss: 6.8854e-09 - accuracy: 1.0000 - val_loss: 0.2999 - val_accuracy: 0.9750 - 73ms/epoch - 2ms/step\n",
      "Epoch 909/1000\n",
      "45/45 - 0s - loss: 7.2173e-09 - accuracy: 1.0000 - val_loss: 0.3007 - val_accuracy: 0.9750 - 74ms/epoch - 2ms/step\n",
      "Epoch 910/1000\n",
      "45/45 - 0s - loss: 7.0513e-09 - accuracy: 1.0000 - val_loss: 0.3005 - val_accuracy: 0.9750 - 78ms/epoch - 2ms/step\n",
      "Epoch 911/1000\n",
      "45/45 - 0s - loss: 7.3832e-09 - accuracy: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.9750 - 70ms/epoch - 2ms/step\n",
      "Epoch 912/1000\n",
      "45/45 - 0s - loss: 6.8854e-09 - accuracy: 1.0000 - val_loss: 0.3004 - val_accuracy: 0.9750 - 71ms/epoch - 2ms/step\n",
      "Epoch 913/1000\n",
      "45/45 - 0s - loss: 7.1343e-09 - accuracy: 1.0000 - val_loss: 0.2999 - val_accuracy: 0.9750 - 71ms/epoch - 2ms/step\n",
      "Epoch 914/1000\n",
      "45/45 - 0s - loss: 7.7980e-09 - accuracy: 1.0000 - val_loss: 0.3012 - val_accuracy: 0.9750 - 97ms/epoch - 2ms/step\n",
      "Epoch 915/1000\n",
      "45/45 - 0s - loss: 7.2173e-09 - accuracy: 1.0000 - val_loss: 0.3004 - val_accuracy: 0.9750 - 69ms/epoch - 2ms/step\n",
      "Epoch 916/1000\n",
      "45/45 - 0s - loss: 6.4706e-09 - accuracy: 1.0000 - val_loss: 0.3007 - val_accuracy: 0.9750 - 72ms/epoch - 2ms/step\n",
      "Epoch 917/1000\n",
      "45/45 - 0s - loss: 7.0513e-09 - accuracy: 1.0000 - val_loss: 0.3007 - val_accuracy: 0.9750 - 120ms/epoch - 3ms/step\n",
      "Epoch 918/1000\n",
      "45/45 - 0s - loss: 7.0513e-09 - accuracy: 1.0000 - val_loss: 0.3006 - val_accuracy: 0.9750 - 74ms/epoch - 2ms/step\n",
      "Epoch 919/1000\n",
      "45/45 - 0s - loss: 7.1343e-09 - accuracy: 1.0000 - val_loss: 0.3009 - val_accuracy: 0.9750 - 73ms/epoch - 2ms/step\n",
      "Epoch 920/1000\n",
      "45/45 - 0s - loss: 6.3877e-09 - accuracy: 1.0000 - val_loss: 0.3006 - val_accuracy: 0.9750 - 71ms/epoch - 2ms/step\n",
      "Epoch 921/1000\n",
      "45/45 - 0s - loss: 6.7195e-09 - accuracy: 1.0000 - val_loss: 0.3009 - val_accuracy: 0.9750 - 74ms/epoch - 2ms/step\n",
      "Epoch 922/1000\n",
      "45/45 - 0s - loss: 6.7195e-09 - accuracy: 1.0000 - val_loss: 0.3007 - val_accuracy: 0.9750 - 71ms/epoch - 2ms/step\n",
      "Epoch 923/1000\n",
      "45/45 - 0s - loss: 6.3877e-09 - accuracy: 1.0000 - val_loss: 0.3009 - val_accuracy: 0.9750 - 77ms/epoch - 2ms/step\n",
      "Epoch 924/1000\n",
      "45/45 - 0s - loss: 7.2173e-09 - accuracy: 1.0000 - val_loss: 0.3012 - val_accuracy: 0.9750 - 75ms/epoch - 2ms/step\n",
      "Epoch 925/1000\n",
      "45/45 - 0s - loss: 6.8025e-09 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.9750 - 72ms/epoch - 2ms/step\n",
      "Epoch 926/1000\n",
      "45/45 - 0s - loss: 7.2173e-09 - accuracy: 1.0000 - val_loss: 0.3013 - val_accuracy: 0.9750 - 78ms/epoch - 2ms/step\n",
      "Epoch 927/1000\n",
      "45/45 - 0s - loss: 6.3877e-09 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.9750 - 78ms/epoch - 2ms/step\n",
      "Epoch 928/1000\n",
      "45/45 - 0s - loss: 6.8025e-09 - accuracy: 1.0000 - val_loss: 0.3011 - val_accuracy: 0.9750 - 69ms/epoch - 2ms/step\n",
      "Epoch 929/1000\n",
      "45/45 - 0s - loss: 6.8854e-09 - accuracy: 1.0000 - val_loss: 0.3013 - val_accuracy: 0.9750 - 93ms/epoch - 2ms/step\n",
      "Epoch 930/1000\n",
      "45/45 - 0s - loss: 6.5536e-09 - accuracy: 1.0000 - val_loss: 0.3011 - val_accuracy: 0.9750 - 74ms/epoch - 2ms/step\n",
      "Epoch 931/1000\n",
      "45/45 - 0s - loss: 7.1343e-09 - accuracy: 1.0000 - val_loss: 0.3014 - val_accuracy: 0.9750 - 69ms/epoch - 2ms/step\n",
      "Epoch 932/1000\n",
      "45/45 - 0s - loss: 6.4706e-09 - accuracy: 1.0000 - val_loss: 0.3012 - val_accuracy: 0.9750 - 71ms/epoch - 2ms/step\n",
      "Epoch 933/1000\n",
      "45/45 - 0s - loss: 7.3832e-09 - accuracy: 1.0000 - val_loss: 0.3009 - val_accuracy: 0.9750 - 71ms/epoch - 2ms/step\n",
      "Epoch 934/1000\n",
      "45/45 - 0s - loss: 6.6366e-09 - accuracy: 1.0000 - val_loss: 0.3017 - val_accuracy: 0.9750 - 69ms/epoch - 2ms/step\n",
      "Epoch 935/1000\n",
      "45/45 - 0s - loss: 6.5536e-09 - accuracy: 1.0000 - val_loss: 0.3015 - val_accuracy: 0.9750 - 68ms/epoch - 2ms/step\n",
      "Epoch 936/1000\n",
      "45/45 - 0s - loss: 6.3047e-09 - accuracy: 1.0000 - val_loss: 0.3016 - val_accuracy: 0.9750 - 74ms/epoch - 2ms/step\n",
      "Epoch 937/1000\n",
      "45/45 - 0s - loss: 6.8025e-09 - accuracy: 1.0000 - val_loss: 0.3016 - val_accuracy: 0.9750 - 66ms/epoch - 1ms/step\n",
      "Epoch 938/1000\n",
      "45/45 - 0s - loss: 6.8854e-09 - accuracy: 1.0000 - val_loss: 0.3017 - val_accuracy: 0.9750 - 67ms/epoch - 1ms/step\n",
      "Epoch 939/1000\n",
      "45/45 - 0s - loss: 6.3877e-09 - accuracy: 1.0000 - val_loss: 0.3017 - val_accuracy: 0.9750 - 73ms/epoch - 2ms/step\n",
      "Epoch 940/1000\n",
      "45/45 - 0s - loss: 6.8025e-09 - accuracy: 1.0000 - val_loss: 0.3015 - val_accuracy: 0.9750 - 72ms/epoch - 2ms/step\n",
      "Epoch 941/1000\n",
      "45/45 - 0s - loss: 7.1343e-09 - accuracy: 1.0000 - val_loss: 0.3020 - val_accuracy: 0.9750 - 68ms/epoch - 2ms/step\n",
      "Epoch 942/1000\n",
      "45/45 - 0s - loss: 6.3877e-09 - accuracy: 1.0000 - val_loss: 0.3017 - val_accuracy: 0.9750 - 70ms/epoch - 2ms/step\n",
      "Epoch 943/1000\n",
      "45/45 - 0s - loss: 6.4706e-09 - accuracy: 1.0000 - val_loss: 0.3016 - val_accuracy: 0.9750 - 141ms/epoch - 3ms/step\n",
      "Epoch 944/1000\n",
      "45/45 - 0s - loss: 6.6366e-09 - accuracy: 1.0000 - val_loss: 0.3015 - val_accuracy: 0.9750 - 77ms/epoch - 2ms/step\n",
      "Epoch 945/1000\n",
      "45/45 - 0s - loss: 6.4706e-09 - accuracy: 1.0000 - val_loss: 0.3017 - val_accuracy: 0.9750 - 71ms/epoch - 2ms/step\n",
      "Epoch 946/1000\n",
      "45/45 - 0s - loss: 6.2218e-09 - accuracy: 1.0000 - val_loss: 0.3021 - val_accuracy: 0.9750 - 72ms/epoch - 2ms/step\n",
      "Epoch 947/1000\n",
      "45/45 - 0s - loss: 6.2218e-09 - accuracy: 1.0000 - val_loss: 0.3018 - val_accuracy: 0.9750 - 73ms/epoch - 2ms/step\n",
      "Epoch 948/1000\n",
      "45/45 - 0s - loss: 7.3002e-09 - accuracy: 1.0000 - val_loss: 0.3023 - val_accuracy: 0.9750 - 72ms/epoch - 2ms/step\n",
      "Epoch 949/1000\n",
      "45/45 - 0s - loss: 6.7195e-09 - accuracy: 1.0000 - val_loss: 0.3019 - val_accuracy: 0.9750 - 69ms/epoch - 2ms/step\n",
      "Epoch 950/1000\n",
      "45/45 - 0s - loss: 6.6366e-09 - accuracy: 1.0000 - val_loss: 0.3018 - val_accuracy: 0.9750 - 72ms/epoch - 2ms/step\n",
      "Epoch 951/1000\n",
      "45/45 - 0s - loss: 6.7195e-09 - accuracy: 1.0000 - val_loss: 0.3022 - val_accuracy: 0.9750 - 73ms/epoch - 2ms/step\n",
      "Epoch 952/1000\n",
      "45/45 - 0s - loss: 6.1388e-09 - accuracy: 1.0000 - val_loss: 0.3019 - val_accuracy: 0.9750 - 72ms/epoch - 2ms/step\n",
      "Epoch 953/1000\n",
      "45/45 - 0s - loss: 6.5536e-09 - accuracy: 1.0000 - val_loss: 0.3018 - val_accuracy: 0.9750 - 69ms/epoch - 2ms/step\n",
      "Epoch 954/1000\n",
      "45/45 - 0s - loss: 6.6366e-09 - accuracy: 1.0000 - val_loss: 0.3025 - val_accuracy: 0.9750 - 69ms/epoch - 2ms/step\n",
      "Epoch 955/1000\n",
      "45/45 - 0s - loss: 6.4706e-09 - accuracy: 1.0000 - val_loss: 0.3025 - val_accuracy: 0.9750 - 71ms/epoch - 2ms/step\n",
      "Epoch 956/1000\n",
      "45/45 - 0s - loss: 6.3047e-09 - accuracy: 1.0000 - val_loss: 0.3022 - val_accuracy: 0.9750 - 70ms/epoch - 2ms/step\n",
      "Epoch 957/1000\n",
      "45/45 - 0s - loss: 6.4706e-09 - accuracy: 1.0000 - val_loss: 0.3022 - val_accuracy: 0.9750 - 72ms/epoch - 2ms/step\n",
      "Epoch 958/1000\n",
      "45/45 - 0s - loss: 6.5536e-09 - accuracy: 1.0000 - val_loss: 0.3023 - val_accuracy: 0.9750 - 94ms/epoch - 2ms/step\n",
      "Epoch 959/1000\n",
      "45/45 - 0s - loss: 6.7195e-09 - accuracy: 1.0000 - val_loss: 0.3022 - val_accuracy: 0.9750 - 73ms/epoch - 2ms/step\n",
      "Epoch 960/1000\n",
      "45/45 - 0s - loss: 7.0513e-09 - accuracy: 1.0000 - val_loss: 0.3026 - val_accuracy: 0.9750 - 77ms/epoch - 2ms/step\n",
      "Epoch 961/1000\n",
      "45/45 - 0s - loss: 6.1388e-09 - accuracy: 1.0000 - val_loss: 0.3023 - val_accuracy: 0.9750 - 70ms/epoch - 2ms/step\n",
      "Epoch 962/1000\n",
      "45/45 - 0s - loss: 6.5536e-09 - accuracy: 1.0000 - val_loss: 0.3025 - val_accuracy: 0.9750 - 72ms/epoch - 2ms/step\n",
      "Epoch 963/1000\n",
      "45/45 - 0s - loss: 6.1388e-09 - accuracy: 1.0000 - val_loss: 0.3027 - val_accuracy: 0.9750 - 69ms/epoch - 2ms/step\n",
      "Epoch 964/1000\n",
      "45/45 - 0s - loss: 6.6366e-09 - accuracy: 1.0000 - val_loss: 0.3025 - val_accuracy: 0.9750 - 71ms/epoch - 2ms/step\n",
      "Epoch 965/1000\n",
      "45/45 - 0s - loss: 6.1388e-09 - accuracy: 1.0000 - val_loss: 0.3025 - val_accuracy: 0.9750 - 70ms/epoch - 2ms/step\n",
      "Epoch 966/1000\n",
      "45/45 - 0s - loss: 6.5536e-09 - accuracy: 1.0000 - val_loss: 0.3032 - val_accuracy: 0.9750 - 124ms/epoch - 3ms/step\n",
      "Epoch 967/1000\n",
      "45/45 - 0s - loss: 6.5536e-09 - accuracy: 1.0000 - val_loss: 0.3030 - val_accuracy: 0.9750 - 76ms/epoch - 2ms/step\n",
      "Epoch 968/1000\n",
      "45/45 - 0s - loss: 6.3047e-09 - accuracy: 1.0000 - val_loss: 0.3028 - val_accuracy: 0.9750 - 73ms/epoch - 2ms/step\n",
      "Epoch 969/1000\n",
      "45/45 - 0s - loss: 6.0559e-09 - accuracy: 1.0000 - val_loss: 0.3028 - val_accuracy: 0.9750 - 72ms/epoch - 2ms/step\n",
      "Epoch 970/1000\n",
      "45/45 - 0s - loss: 6.5536e-09 - accuracy: 1.0000 - val_loss: 0.3031 - val_accuracy: 0.9750 - 68ms/epoch - 2ms/step\n",
      "Epoch 971/1000\n",
      "45/45 - 0s - loss: 5.9729e-09 - accuracy: 1.0000 - val_loss: 0.3027 - val_accuracy: 0.9750 - 73ms/epoch - 2ms/step\n",
      "Epoch 972/1000\n",
      "45/45 - 0s - loss: 7.1343e-09 - accuracy: 1.0000 - val_loss: 0.3029 - val_accuracy: 0.9750 - 96ms/epoch - 2ms/step\n",
      "Epoch 973/1000\n",
      "45/45 - 0s - loss: 5.8070e-09 - accuracy: 1.0000 - val_loss: 0.3028 - val_accuracy: 0.9750 - 73ms/epoch - 2ms/step\n",
      "Epoch 974/1000\n",
      "45/45 - 0s - loss: 6.0559e-09 - accuracy: 1.0000 - val_loss: 0.3032 - val_accuracy: 0.9750 - 73ms/epoch - 2ms/step\n",
      "Epoch 975/1000\n",
      "45/45 - 0s - loss: 6.6366e-09 - accuracy: 1.0000 - val_loss: 0.3032 - val_accuracy: 0.9750 - 69ms/epoch - 2ms/step\n",
      "Epoch 976/1000\n",
      "45/45 - 0s - loss: 6.4706e-09 - accuracy: 1.0000 - val_loss: 0.3034 - val_accuracy: 0.9750 - 76ms/epoch - 2ms/step\n",
      "Epoch 977/1000\n",
      "45/45 - 0s - loss: 6.5536e-09 - accuracy: 1.0000 - val_loss: 0.3036 - val_accuracy: 0.9722 - 69ms/epoch - 2ms/step\n",
      "Epoch 978/1000\n",
      "45/45 - 0s - loss: 5.9729e-09 - accuracy: 1.0000 - val_loss: 0.3037 - val_accuracy: 0.9750 - 73ms/epoch - 2ms/step\n",
      "Epoch 979/1000\n",
      "45/45 - 0s - loss: 6.7195e-09 - accuracy: 1.0000 - val_loss: 0.3036 - val_accuracy: 0.9750 - 71ms/epoch - 2ms/step\n",
      "Epoch 980/1000\n",
      "45/45 - 0s - loss: 6.0559e-09 - accuracy: 1.0000 - val_loss: 0.3031 - val_accuracy: 0.9750 - 75ms/epoch - 2ms/step\n",
      "Epoch 981/1000\n",
      "45/45 - 0s - loss: 7.0513e-09 - accuracy: 1.0000 - val_loss: 0.3035 - val_accuracy: 0.9750 - 81ms/epoch - 2ms/step\n",
      "Epoch 982/1000\n",
      "45/45 - 0s - loss: 6.0559e-09 - accuracy: 1.0000 - val_loss: 0.3034 - val_accuracy: 0.9750 - 70ms/epoch - 2ms/step\n",
      "Epoch 983/1000\n",
      "45/45 - 0s - loss: 6.3047e-09 - accuracy: 1.0000 - val_loss: 0.3033 - val_accuracy: 0.9750 - 73ms/epoch - 2ms/step\n",
      "Epoch 984/1000\n",
      "45/45 - 0s - loss: 6.7195e-09 - accuracy: 1.0000 - val_loss: 0.3037 - val_accuracy: 0.9750 - 71ms/epoch - 2ms/step\n",
      "Epoch 985/1000\n",
      "45/45 - 0s - loss: 6.4706e-09 - accuracy: 1.0000 - val_loss: 0.3033 - val_accuracy: 0.9750 - 74ms/epoch - 2ms/step\n",
      "Epoch 986/1000\n",
      "45/45 - 0s - loss: 6.1388e-09 - accuracy: 1.0000 - val_loss: 0.3040 - val_accuracy: 0.9722 - 93ms/epoch - 2ms/step\n",
      "Epoch 987/1000\n",
      "45/45 - 0s - loss: 6.0559e-09 - accuracy: 1.0000 - val_loss: 0.3034 - val_accuracy: 0.9750 - 68ms/epoch - 2ms/step\n",
      "Epoch 988/1000\n",
      "45/45 - 0s - loss: 6.3877e-09 - accuracy: 1.0000 - val_loss: 0.3039 - val_accuracy: 0.9750 - 66ms/epoch - 1ms/step\n",
      "Epoch 989/1000\n",
      "45/45 - 0s - loss: 6.1388e-09 - accuracy: 1.0000 - val_loss: 0.3040 - val_accuracy: 0.9750 - 71ms/epoch - 2ms/step\n",
      "Epoch 990/1000\n",
      "45/45 - 0s - loss: 6.1388e-09 - accuracy: 1.0000 - val_loss: 0.3040 - val_accuracy: 0.9750 - 73ms/epoch - 2ms/step\n",
      "Epoch 991/1000\n",
      "45/45 - 0s - loss: 5.7240e-09 - accuracy: 1.0000 - val_loss: 0.3045 - val_accuracy: 0.9750 - 131ms/epoch - 3ms/step\n",
      "Epoch 992/1000\n",
      "45/45 - 0s - loss: 6.3047e-09 - accuracy: 1.0000 - val_loss: 0.3044 - val_accuracy: 0.9750 - 78ms/epoch - 2ms/step\n",
      "Epoch 993/1000\n",
      "45/45 - 0s - loss: 6.1388e-09 - accuracy: 1.0000 - val_loss: 0.3044 - val_accuracy: 0.9750 - 65ms/epoch - 1ms/step\n",
      "Epoch 994/1000\n",
      "45/45 - 0s - loss: 5.8070e-09 - accuracy: 1.0000 - val_loss: 0.3045 - val_accuracy: 0.9750 - 62ms/epoch - 1ms/step\n",
      "Epoch 995/1000\n",
      "45/45 - 0s - loss: 6.2218e-09 - accuracy: 1.0000 - val_loss: 0.3045 - val_accuracy: 0.9750 - 64ms/epoch - 1ms/step\n",
      "Epoch 996/1000\n",
      "45/45 - 0s - loss: 5.9729e-09 - accuracy: 1.0000 - val_loss: 0.3039 - val_accuracy: 0.9750 - 61ms/epoch - 1ms/step\n",
      "Epoch 997/1000\n",
      "45/45 - 0s - loss: 6.3877e-09 - accuracy: 1.0000 - val_loss: 0.3045 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 998/1000\n",
      "45/45 - 0s - loss: 5.9729e-09 - accuracy: 1.0000 - val_loss: 0.3045 - val_accuracy: 0.9750 - 63ms/epoch - 1ms/step\n",
      "Epoch 999/1000\n",
      "45/45 - 0s - loss: 5.9729e-09 - accuracy: 1.0000 - val_loss: 0.3044 - val_accuracy: 0.9750 - 60ms/epoch - 1ms/step\n",
      "Epoch 1000/1000\n",
      "45/45 - 0s - loss: 6.3047e-09 - accuracy: 1.0000 - val_loss: 0.3044 - val_accuracy: 0.9750 - 81ms/epoch - 2ms/step\n",
      "12/12 - 0s - loss: 0.3044 - accuracy: 0.9750 - 29ms/epoch - 2ms/step\n",
      "Dokładność testowa: 97.50%\n"
     ]
    }
   ],
   "source": [
    "# Trenuj model\n",
    "history = model.fit(X_train, y_train, epochs=1000, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "# Oceń model na zestawie testowym\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Dokładność testowa: {test_accuracy:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
