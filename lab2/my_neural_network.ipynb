{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # algebra liniowa\n",
    "import matplotlib.pyplot as plt # używane do rysowania wykresów\n",
    "from sklearn.datasets import load_digits # importowanie zbioru danych\n",
    "from sklearn.model_selection import train_test_split # podział danych na część treningową i testową\n",
    "from sklearn.preprocessing import MinMaxScaler # normalizacja danych\n",
    "from sklearn.preprocessing import OneHotEncoder # kodowanie one-hot\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import optuna # do hiperparametryzacji\n",
    "import warnings # ignorowanie ostrzeżeń\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (64, 64)\n",
    "\n",
    "def load_train_data(input_dir, newSize=(64,64)):\n",
    "    '''\n",
    "    '''\n",
    "\n",
    "    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    from skimage.io import imread\n",
    "    import cv2 as cv\n",
    "    from pathlib import Path\n",
    "    import random\n",
    "    from shutil import copyfile, rmtree\n",
    "    import json\n",
    "\n",
    "\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    import matplotlib\n",
    "    \n",
    "    image_dir = Path(input_dir)\n",
    "    categories_name = []\n",
    "    for file in os.listdir(image_dir):\n",
    "        d = os.path.join(image_dir, file)\n",
    "        if os.path.isdir(d):\n",
    "            categories_name.append(file)\n",
    "\n",
    "    folders = [directory for directory in image_dir.iterdir() if directory.is_dir()]\n",
    "\n",
    "    train_img = []\n",
    "    categories_count=[]\n",
    "    labels=[]\n",
    "    for i, direc in enumerate(folders):\n",
    "        count = 0\n",
    "        for obj in direc.iterdir():\n",
    "            if os.path.isfile(obj) and os.path.basename(os.path.normpath(obj)) != 'desktop.ini':\n",
    "                labels.append(os.path.basename(os.path.normpath(direc)))\n",
    "                count += 1\n",
    "                img = imread(obj)#zwraca ndarry postaci xSize x ySize x colorDepth\n",
    "                img = cv.resize(img, newSize, interpolation=cv.INTER_AREA)# zwraca ndarray\n",
    "                img = img / 255#normalizacja\n",
    "                train_img.append(img)\n",
    "        categories_count.append(count)\n",
    "    X={}\n",
    "    X[\"values\"] = np.array(train_img)\n",
    "    X[\"categories_name\"] = categories_name\n",
    "    X[\"categories_count\"] = categories_count\n",
    "    X[\"labels\"]=labels\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(input_dir, newSize=(64,64)):\n",
    "    '''\n",
    "    '''\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    from skimage.io import imread\n",
    "    import cv2 as cv\n",
    "    from pathlib import Path\n",
    "    import random\n",
    "    from shutil import copyfile, rmtree\n",
    "    import json\n",
    "\n",
    "\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    import matplotlib\n",
    "\n",
    "\n",
    "\n",
    "    image_path = Path(input_dir)\n",
    "\n",
    "    labels_path = image_path.parents[0] / 'test_labels.json'\n",
    "\n",
    "    #with labels_path.open(\"r\", encoding =\"utf-8\") as f:\n",
    "    jsonString = labels_path.read_text()\n",
    "    objects = json.loads(jsonString)\n",
    "\n",
    "    #print(objects)\n",
    "\n",
    "    categories_name = []\n",
    "    categories_count=[]\n",
    "    count = 0\n",
    "    c = objects[0]['value']\n",
    "    for e in  objects:\n",
    "        if e['value'] != c:\n",
    "            #print(count)\n",
    "            #print(c)\n",
    "            categories_count.append(count)\n",
    "            c = e['value']\n",
    "            count = 1\n",
    "        else:\n",
    "            count += 1\n",
    "        if not e['value'] in categories_name:\n",
    "            categories_name.append(e['value'])\n",
    "\n",
    "    categories_count.append(count)\n",
    "\n",
    "\n",
    "\n",
    "    test_img = []\n",
    "\n",
    "    labels=[]\n",
    "    for e in objects:\n",
    "        p = image_path / e['filename']\n",
    "        img = imread(p)#zwraca ndarry postaci xSize x ySize x colorDepth\n",
    "        img = cv.resize(img, newSize, interpolation=cv.INTER_AREA)# zwraca ndarray\n",
    "        img = img / 255#normalizacja\n",
    "        test_img.append(img)\n",
    "        labels.append(e['value'])\n",
    "\n",
    "\n",
    "    X={}\n",
    "    X[\"values\"] = np.array(test_img)\n",
    "    X[\"categories_name\"] = categories_name\n",
    "    X[\"categories_count\"] = categories_count\n",
    "    X[\"labels\"]=labels\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\"\n",
    "    Prosta sieć neuronowa z jedną warstwą ukrytą.\n",
    "\n",
    "    Parametry:\n",
    "    -----------\n",
    "    input_size: int\n",
    "        Liczba cech wejściowych\n",
    "    hidden_size: int\n",
    "        Liczba neuronów w warstwie ukrytej\n",
    "    output_size: int\n",
    "        Liczba neuronów w warstwie wyjściowej\n",
    "    loss_func: str\n",
    "        Funkcja straty do użycia. Opcje to 'mse' dla błędu średniokwadratowego, 'log_loss' dla straty logistycznej i 'categorical_crossentropy' dla krzyżowej entropii kategorycznej.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size, loss_func='mse'):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.loss_func = loss_func\n",
    "        \n",
    "        # Inicjalizacja wag i przesunięć\n",
    "        self.weights1 = np.random.randn(self.input_size, self.hidden_size)\n",
    "        self.bias1 = np.zeros((1, self.hidden_size))\n",
    "        self.weights2 = np.random.randn(self.hidden_size, self.output_size)\n",
    "        self.bias2 = np.zeros((1, self.output_size))\n",
    "\n",
    "        # Śledzenie straty\n",
    "        self.train_loss = []\n",
    "        self.test_loss = []\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Wyświetl architekturę sieci neuronowej.\n",
    "        \"\"\"\n",
    "        return f\"Układ Sieci Neuronowej:\\nWarstwa Wejściowa: {self.input_size} neuronów\\nWarstwa Ukryta: {self.hidden_size} neuronów\\nWarstwa Wyjściowa: {self.output_size} neuronów\\nFunkcja Straty: {self.loss_func}\"\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Przeprowadź propagację w przód.\n",
    "        \n",
    "        Parametry:\n",
    "        -----------\n",
    "        X: numpy array\n",
    "            Dane wejściowe\n",
    "        \n",
    "        Zwraca:\n",
    "        --------\n",
    "        numpy array\n",
    "            Przewidziane wyjście\n",
    "        \"\"\"\n",
    "        # Przeprowadź propagację w przód\n",
    "        self.z1 = np.dot(X, self.weights1) + self.bias1\n",
    "        self.a1 = self.sigmoid(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.weights2) + self.bias2\n",
    "        if self.loss_func == 'categorical_crossentropy':\n",
    "            self.a2 = self.softmax(self.z2)\n",
    "        else:\n",
    "            self.a2 = self.sigmoid(self.z2)\n",
    "        return self.a2\n",
    "    \n",
    "    def backward(self, X, y, learning_rate):\n",
    "        \"\"\"\n",
    "        Przeprowadź propagację wsteczną.\n",
    "\n",
    "        Parametry:\n",
    "        -----------\n",
    "        X: numpy array\n",
    "            Dane wejściowe\n",
    "        y: numpy array\n",
    "            Docelowe wyjście\n",
    "        learning_rate: float\n",
    "            Współczynnik uczenia\n",
    "        \"\"\"\n",
    "        # Przeprowadź propagację wsteczną\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        # Oblicz gradienty\n",
    "        if self.loss_func == 'mse':\n",
    "            self.dz2 = self.a2 - y\n",
    "        elif self.loss_func == 'log_loss':\n",
    "            self.dz2 = -(y/self.a2 - (1-y)/(1-self.a2))\n",
    "        elif self.loss_func == 'categorical_crossentropy':\n",
    "            self.dz2 = self.a2 - y\n",
    "        else:\n",
    "            raise ValueError('Nieprawidłowa funkcja straty')\n",
    "        \n",
    "        self.dw2 = (1 / m) * np.dot(self.a1.T, self.dz2)\n",
    "        self.db2 = (1 / m) * np.sum(self.dz2, axis=0)\n",
    "        self.dz1 = np.dot(self.dz2, self.weights2.T) * self.sigmoid_derivative(self.a1)\n",
    "        self.dw1 = (1 / m) * np.dot(X.T, self.dz1)\n",
    "        self.db1 = (1 / m) * np.sum(self.dz1, axis=0)\n",
    "        \n",
    "        # Zaktualizuj wagi i przesunięcia\n",
    "        self.weights2 -= learning_rate * self.dw2\n",
    "        self.bias2 -= learning_rate * self.db2\n",
    "        self.weights1 -= learning_rate * self.dw1\n",
    "        self.bias1 -= learning_rate * self.db1\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        Funkcja aktywacji sigmoidalna.\n",
    "        \n",
    "        Parametry:\n",
    "        -----------\n",
    "        x: numpy array\n",
    "            Dane wejściowe\n",
    "        \n",
    "        Zwraca:\n",
    "        --------\n",
    "        numpy array\n",
    "            Wynik funkcji sigmoidalnej\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        \"\"\"\n",
    "        Pochodna funkcji aktywacji sigmoidalnej.\n",
    "\n",
    "        Parametry:\n",
    "        -----------\n",
    "        x: numpy array\n",
    "            Dane wejściowe\n",
    "        \n",
    "        Zwraca:\n",
    "        --------\n",
    "        numpy array\n",
    "            Wynik pochodnej funkcji sigmoidalnej\n",
    "        \"\"\"\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        \"\"\"\n",
    "        Funkcja aktywacji softmax.\n",
    "\n",
    "        Parametry:\n",
    "        -----------\n",
    "        x: numpy array\n",
    "            Dane wejściowe\n",
    "        \n",
    "        Zwraca:\n",
    "        --------\n",
    "        numpy array\n",
    "            Wynik funkcji softmax\n",
    "        \"\"\"\n",
    "        exps = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exps/np.sum(exps, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \"\"\"\n",
    "    Klasa do trenowania sieci neuronowej.\n",
    "\n",
    "    Parametry:\n",
    "    -----------\n",
    "    model: NeuralNetwork\n",
    "        Model sieci neuronowej do trenowania\n",
    "    loss_func: str\n",
    "        Funkcja straty do użycia. Opcje to 'mse' dla błędu średniokwadratowego, 'log_loss' dla straty logistycznej, i 'categorical_crossentropy' dla krzyżowej entropii kategorycznej.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, loss_func='mse'):\n",
    "        self.model = model\n",
    "        self.loss_func = loss_func\n",
    "        self.train_loss = []\n",
    "        self.test_loss = []\n",
    "\n",
    "    def calculate_loss(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Oblicz stratę.\n",
    "\n",
    "        Parametry:\n",
    "        -----------\n",
    "        y_true: numpy array\n",
    "            Prawdziwe wyjście\n",
    "        y_pred: numpy array\n",
    "            Przewidziane wyjście\n",
    "        \n",
    "        Zwraca:\n",
    "        --------\n",
    "        float\n",
    "            Strata\n",
    "        \"\"\"\n",
    "        if self.loss_func == 'mse':\n",
    "            return np.mean((y_pred - y_true)**2)\n",
    "        elif self.loss_func == 'log_loss':\n",
    "            return -np.mean(y_true*np.log(y_pred) + (1-y_true)*np.log(1-y_pred))\n",
    "        elif self.loss_func == 'categorical_crossentropy':\n",
    "            return -np.mean(y_true*np.log(y_pred))\n",
    "        else:\n",
    "            raise ValueError('Nieprawidłowa funkcja straty')\n",
    "\n",
    "    def train(self, X_train, y_train, X_test, y_test, epochs, learning_rate):\n",
    "        \"\"\"\n",
    "        Trenuj sieć neuronową.\n",
    "\n",
    "        Parametry:\n",
    "        -----------\n",
    "        X_train: numpy array\n",
    "            Dane wejściowe treningowe\n",
    "        y_train: numpy array\n",
    "            Docelowe wyjście treningowe\n",
    "        X_test: numpy array\n",
    "            Dane wejściowe testowe\n",
    "        y_test: numpy array\n",
    "            Docelowe wyjście testowe\n",
    "        epochs: int\n",
    "            Liczba epok trenowania modelu\n",
    "        learning_rate: float\n",
    "            Współczynnik uczenia\n",
    "        \"\"\"\n",
    "        for _ in range(epochs):\n",
    "            self.model.forward(X_train)\n",
    "            self.model.backward(X_train, y_train, learning_rate)\n",
    "            train_loss = self.calculate_loss(y_train, self.model.a2)\n",
    "            self.train_loss.append(train_loss)\n",
    "            \n",
    "            self.model.forward(X_test)\n",
    "            test_loss = self.calculate_loss(y_test, self.model.a2)\n",
    "            self.test_loss.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enhance data function\n",
    "def enhance_train_data(x_to_augment, y_to_augment):\n",
    "   augmented_images = []\n",
    "   augmented_labels = []\n",
    "\n",
    "   for image,label in zip(x_to_augment, y_to_augment):\n",
    "        augmented_images.append(image)\n",
    "        augmented_labels.append(label)\n",
    "        for _ in range(10):\n",
    "           augmented = augment(image)\n",
    "           augmented_images.append(augmented.numpy())\n",
    "           augmented_labels.append(label)\n",
    "   \n",
    "   return augmented_images, augmented_labels\n",
    "\n",
    "\n",
    "def augment(image):\n",
    "    import tensorflow as tf\n",
    "    delta = 0.09 # maximum relative change in brigtness\n",
    "    \n",
    "    image = tf.cast(image, tf.float64)\n",
    "    image = tf.image.random_brightness(image, delta)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_contrast(image, 0.8, 1.2)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train data\n",
    "data_train = load_train_data('./train_test_sw/train_sw')\n",
    "x_train = data_train['values']\n",
    "y_train = data_train['labels']\n",
    "\n",
    "data_test = load_test_data('./train_test_sw/test_sw')\n",
    "x_test = data_test['values']\n",
    "y_test = data_test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = LabelEncoder()\n",
    "y_train_enc = labelEncoder.fit_transform(y_train)\n",
    "y_test_enc = labelEncoder.transform(y_test)\n",
    "\n",
    "y_train_onehot = pd.get_dummies(y_train_enc).values\n",
    "y_test_onehot = pd.get_dummies(y_test_enc).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights1: [[ 0.16392107 -0.32263778  1.50135676 ... -0.6541985  -0.67688741\n",
      "  -0.61773415]\n",
      " [ 0.12973136  1.31168135 -0.17987189 ...  1.0485188   1.77674088\n",
      "   0.12759092]\n",
      " [ 1.65569515  0.21175994 -1.08258564 ... -0.79100025 -0.93241461\n",
      "   0.34821402]\n",
      " ...\n",
      " [ 1.06908187 -2.11565351 -0.21363295 ... -2.59768568  0.19454726\n",
      "  -0.00519726]\n",
      " [-1.32716449  0.92981691 -0.29465818 ...  0.58127687  0.33488062\n",
      "   1.13709671]\n",
      " [ 0.52698673 -0.05882928 -0.56810379 ...  2.40154746  1.18550033\n",
      "  -0.7801925 ]]\n"
     ]
    }
   ],
   "source": [
    "input_layer_size = 64*64*4\n",
    "hidden_layer_size = 128\n",
    "output_layer_size = 5\n",
    "\n",
    "model = NeuralNetwork(input_size=input_layer_size, hidden_size=hidden_layer_size, output_size=output_layer_size)\n",
    "\n",
    "trainer = Trainer(model)\n",
    "\n",
    "trainer.train(x_train.reshape(-1, input_layer_size), y_train_onehot.reshape(-1, output_layer_size), x_test.reshape(-1, input_layer_size), y_test_onehot.reshape(-1, output_layer_size), epochs=100, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uczenie sieci ale z rozszerzeonymi danymi 10-krotnie:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kazde zdjecie dostanie 10 swoich kopii, ktore bedą np. odbite w poziomie co powinno pozwalić na ulepszenie sieci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba zdjęć przed rozszerzeniem: 1027\n",
      "Liczba zdjęć po rozszerzeniu: 11297\n"
     ]
    }
   ],
   "source": [
    "print(f'Liczba zdjęć przed rozszerzeniem: {len(x_train)}')\n",
    "augmented_x, augmented_y = enhance_train_data(x_train, y_train)\n",
    "print(f'Liczba zdjęć po rozszerzeniu: {len(augmented_x)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentedLabelEncoder = LabelEncoder()\n",
    "augmented_y_train_enc = labelEncoder.fit_transform(augmented_y)\n",
    "y_test_enc = labelEncoder.transform(y_test)\n",
    "\n",
    "augmented_y_train_onehot = pd.get_dummies(augmented_y_train_enc).values\n",
    "y_test_onehot = pd.get_dummies(y_test_enc).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights1: [[-2.22658743 -1.09990585 -1.76567076 ...  0.19680946 -1.09891141\n",
      "   1.72901562]\n",
      " [ 0.70284078  0.61073378 -1.34384783 ... -0.64566589  0.36656696\n",
      "  -0.68061175]\n",
      " [-1.14708402  0.46067666  1.10404425 ... -0.20408476 -0.33615866\n",
      "  -1.36204744]\n",
      " ...\n",
      " [ 1.60915407 -0.19566548 -0.52328543 ...  0.80360749  0.8952532\n",
      "   1.23354477]\n",
      " [-0.7452284  -0.69611798  0.07603561 ... -0.17472887 -0.11474636\n",
      "  -1.49150965]\n",
      " [-0.21212946  1.17414529  1.60164679 ... -1.74865019  0.38801534\n",
      "  -0.81499657]]\n"
     ]
    }
   ],
   "source": [
    "input_layer_size = 64*64*4\n",
    "hidden_layer_size = 128\n",
    "output_layer_size = 5\n",
    "\n",
    "model_with_augmented_data = NeuralNetwork(input_size=input_layer_size, hidden_size=hidden_layer_size, output_size=output_layer_size)\n",
    "\n",
    "trainer_with_augmented_data = Trainer(model_with_augmented_data)\n",
    "\n",
    "trainer_with_augmented_data.train(np.array(augmented_x).reshape(-1, input_layer_size), augmented_y_train_onehot.reshape(-1, output_layer_size), x_test.reshape(-1, input_layer_size), y_test_onehot.reshape(-1, output_layer_size), epochs=100, learning_rate=0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
