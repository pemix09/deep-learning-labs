{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "confidential-bennett",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "import numpy as np\n",
    "\n",
    "required = { 'scikit-image'}\n",
    "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
    "missing = required - installed\n",
    "\n",
    "if missing:\n",
    "    python = sys.executable\n",
    "    subprocess.check_call([python, '-m', 'pip', 'install', *missing], stdout=subprocess.DEVNULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-genealogy",
   "metadata": {},
   "source": [
    "###### 1. Opis danych dla pierwszych 6 zajęć laboratoryjnych\n",
    "\n",
    "Dane są dostępne w postaci spakowanej w pliku <a href=\"http://fraktal.faculty.wmi.amu.edu.pl/symulowanie_wizualne/train_test_sw.zip\">train_test_sw.zip</a>. Po rozpakowaniu otrzymujmemy katalog <i>train_test_sw</i> zawierający:\n",
    "\n",
    "<ol>\n",
    "        <li>katalog <i>train_sw</i> - katalog z listą podkatalogów przechowujących obrazy treningowe (format 4-bajtowy rgba) podzielone na kategorie - nazwa katalogu odpowiada nazwie kategorii\n",
    "     <li>katalog <i>test_sw</i> - katalog z listą plików zawierających obrazy testowe   \n",
    "     <li>plik <i>test_labels.json</i> - zawiera etykiety obrazów testowych  w formacie JSON - pojedyncza dana to słownik  \n",
    "         <p>\n",
    "             <code>\n",
    "                 {\n",
    "                    \"filename\": nazwa pliku,\n",
    "                    \"value\": nazwa_kategorii\n",
    "                 }\n",
    "            </code>\n",
    " </ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-mattress",
   "metadata": {},
   "source": [
    "#### 2. Funkcja <code>load_train_data(input_dir, newSize=(64,64))</code>\n",
    "\n",
    "Funkcja ta wczytuje dane teningowe, przeskalowuje je do rozmiaru podanego w drugim parametrze (z interpolacją typu cv2.INTER_AREA), przeprowadza ich normalizację  i zwraca słownik w formacie:\n",
    "<p>\n",
    "<code>\n",
    "{  \"data\" - lista (typ <code>list</code>) obrazów, gdzie pojedynczy obraz jest tablicą <code>numpy.array</code> zapisaną wierszowo blokami rgb\n",
    "   \"categories_name\" - lista nazw kategorii klasyfikacyjnych, gdzie pojedyncza nazwa kategorii jest typu <code>str</code>\n",
    "   \"categories_count\" - lista ilości przykładów z pozszczególnych kategorii w danych treningowych \n",
    "   \"labels\" - lista etykiet wszystkich danych treningowych\n",
    " }\n",
    " </code>\n",
    " \n",
    " Parametry:\n",
    "    \n",
    " - <code>input_dir</code> przyjmuje wartość  ścieżki katalogu 'train_sw'\n",
    " - <code>newSize</code> przyjmuje wartość  krotki określającej rozmiar przeskalowanych obrazów   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "indirect-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_train_data(input_dir, newSize=(64,64)):\n",
    "    '''\n",
    "    '''\n",
    "\n",
    "    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    from skimage.io import imread\n",
    "    import cv2 as cv\n",
    "    from pathlib import Path\n",
    "    import random\n",
    "    from shutil import copyfile, rmtree\n",
    "    import json\n",
    "\n",
    "\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    import matplotlib\n",
    "    \n",
    "    image_dir = Path(input_dir)\n",
    "    categories_name = []\n",
    "    for file in os.listdir(image_dir):\n",
    "        d = os.path.join(image_dir, file)\n",
    "        if os.path.isdir(d):\n",
    "            categories_name.append(file)\n",
    "\n",
    "    folders = [directory for directory in image_dir.iterdir() if directory.is_dir()]\n",
    "\n",
    "    train_img = []\n",
    "    categories_count=[]\n",
    "    labels=[]\n",
    "    for i, direc in enumerate(folders):\n",
    "        count = 0\n",
    "        for obj in direc.iterdir():\n",
    "            if os.path.isfile(obj) and os.path.basename(os.path.normpath(obj)) != 'desktop.ini':\n",
    "                labels.append(os.path.basename(os.path.normpath(direc)))\n",
    "                count += 1\n",
    "                img = imread(obj)#zwraca ndarry postaci xSize x ySize x colorDepth\n",
    "                img = cv.resize(img, newSize, interpolation=cv.INTER_AREA)# zwraca ndarray\n",
    "                img = img / 255#normalizacja\n",
    "                train_img.append(img)\n",
    "        categories_count.append(count)\n",
    "    X={}\n",
    "    X[\"values\"] = np.array(train_img)\n",
    "    X[\"categories_name\"] = categories_name\n",
    "    X[\"categories_count\"] = categories_count\n",
    "    X[\"labels\"]=labels\n",
    "    return X\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "precise-vocabulary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mean', 'Lemon', 'Gardenia', 'Beech', 'Tomato']\n",
      "[206, 206, 206, 203, 206]\n",
      "['Mean', 'Mean', 'Lemon']\n",
      "[0.12156862745098039, 0.12156862745098039, 0.10588235294117647, 1.0]\n"
     ]
    }
   ],
   "source": [
    "data = load_train_data('./train_test_sw/train_sw')\n",
    "print(data['categories_name'])\n",
    "print(data['categories_count'])\n",
    "print([data[\"labels\"][50],data[\"labels\"][200],data[\"labels\"][300]])\n",
    "print(list(data[\"values\"][100][1][10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-talent",
   "metadata": {},
   "source": [
    "#### 3. Funkcja <code>load_test_data(input_dir, newSize=(64,64))</code>\n",
    "\n",
    "Funkcja ta  wczytuje dane testowe, przeskalowuje je do rozmiaru podanego w drugim parametrze (z \n",
    "interpolacją typu cv2.INTER_AREA), przeprowadza ich normalizację  i zwraca słownik w formacie:\n",
    "<p>\n",
    "    \n",
    "<code>\n",
    "{  \"data\" - lista (typ <code>list</code>) obrazów, gdzie pojedynczy obraz jest tablicą <code>numpy.array</code> zapisaną wierszowo blokami rgb\n",
    "   \"categories_name\" - lista nazw kategorii klasyfikacyjnych, gdzie pojedyncza nazwa kategorii jest typu <code>str</code>\n",
    "   \"categories_count\" - lista ilości przykładów z pozszczególnych kategorii w danych testowych \n",
    "   \"labels\" - lista etykiet wszystkich danych testowych\n",
    " }\n",
    " </code>\n",
    " \n",
    " Parametry:\n",
    "    \n",
    " - <code>input_dir</code> przyjmuje wartość  ścieżki katalogu 'test_sw'\n",
    " - <code>newSize</code> przyjmuje wartość  krotki określającej rozmiar przeskalowanych obrazów   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "difficult-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(input_dir, newSize=(64,64)):\n",
    "    '''\n",
    "    '''\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    from skimage.io import imread\n",
    "    import cv2 as cv\n",
    "    from pathlib import Path\n",
    "    import random\n",
    "    from shutil import copyfile, rmtree\n",
    "    import json\n",
    "\n",
    "\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    import matplotlib\n",
    "\n",
    "\n",
    "\n",
    "    image_path = Path(input_dir)\n",
    "\n",
    "    labels_path = image_path.parents[0] / 'test_labels.json'\n",
    "\n",
    "    #with labels_path.open(\"r\", encoding =\"utf-8\") as f:\n",
    "    jsonString = labels_path.read_text()\n",
    "    objects = json.loads(jsonString)\n",
    "\n",
    "    #print(objects)\n",
    "\n",
    "    categories_name = []\n",
    "    categories_count=[]\n",
    "    count = 0\n",
    "    c = objects[0]['value']\n",
    "    for e in  objects:\n",
    "        if e['value'] != c:\n",
    "            #print(count)\n",
    "            #print(c)\n",
    "            categories_count.append(count)\n",
    "            c = e['value']\n",
    "            count = 1\n",
    "        else:\n",
    "            count += 1\n",
    "        if not e['value'] in categories_name:\n",
    "            categories_name.append(e['value'])\n",
    "\n",
    "    categories_count.append(count)\n",
    "\n",
    "\n",
    "\n",
    "    test_img = []\n",
    "\n",
    "    labels=[]\n",
    "    for e in objects:\n",
    "        p = image_path / e['filename']\n",
    "        img = imread(p)#zwraca ndarry postaci xSize x ySize x colorDepth\n",
    "        img = cv.resize(img, newSize, interpolation=cv.INTER_AREA)# zwraca ndarray\n",
    "        img = img / 255#normalizacja\n",
    "        test_img.append(img)\n",
    "        labels.append(e['value'])\n",
    "\n",
    "\n",
    "    X={}\n",
    "    X[\"values\"] = np.array(test_img)\n",
    "    X[\"categories_name\"] = categories_name\n",
    "    X[\"categories_count\"] = categories_count\n",
    "    X[\"labels\"]=labels\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "smaller-cookie",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Beech', 'Gardenia', 'Lemon', 'Mean', 'Tomato']\n",
      "[51, 52, 52, 52, 52]\n",
      "['Beech', 'Beech', 'Beech']\n",
      "[0.058823529411764705, 0.00784313725490196, 0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "data = load_test_data('./train_test_sw/test_sw')\n",
    "print(data['categories_name'])\n",
    "print(data['categories_count'])\n",
    "print([data[\"labels\"][10],data[\"labels\"][20],data[\"labels\"][30]])\n",
    "print(list(data[\"values\"][10][1][10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-purchase",
   "metadata": {},
   "source": [
    "#### 4.  Zadanie 1 (4pkt): \n",
    "\n",
    "Napisz kod klasy <code>KNearestNeighbor</code> implementującej klasyfikator <i>knn</i>. Należy zimplementować następujące  metody:\n",
    "\n",
    "    \n",
    " - <code>konstruktor</code> pobierający listę obrazów treningowych (zgodną zw składową 'values' wczytanego słownika) oraz listę ich etykiet\n",
    " - metoda <code>l_p_metric(image1, image2, p):</code> zwracająca wartość odległości pomiędzy dwoma obrazami, mierzoną normą typu <i>l_p</i> - parametr <code>p</code> określa 'potęgę' normy\n",
    " - metoda <code>predict(test_images, k,p):</code> zwracająca listę prognozowanych etykiet dla obrazów testowych (parametr <code>test_images</code>). Paramter drugi określa liczbę przeszukiwanych sąsiadów, natomiast paramter trzeci określa potęgę wybranej metryki.\n",
    " - metoda <code>accuracy(test_images, k,p)</code> zwracająca dokładność klasyfikatora na zbiorze testowym. Parametr drugi i trzeci są jak w metodzie <code>predict()</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "great-earthquake",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-50c8d2866e4d875e",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2799840554.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[14], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    # END SOLUTION\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "class KNearestNeighbor(object):\n",
    "    # BEGIN SOLUTION \n",
    "   \n",
    "    \n",
    "    # END SOLUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-globe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data_train = load_train_data(\"../../train_test_sw/train_sw\",newSize=(256,256))\n",
    "X_train = data_train['values']\n",
    "y_train = data_train['labels']\n",
    "\n",
    "\n",
    "data_test = load_test_data(\"../../train_test_sw/test_sw\",newSize=(256,256))\n",
    "X_test = data_test['values']\n",
    "y_test = data_test['labels']\n",
    "\n",
    "\n",
    "\n",
    "class_le = LabelEncoder()\n",
    "y_train_enc = class_le.fit_transform(y_train)\n",
    "\n",
    "Knn  = KNearestNeighbor(X_train, y_train_enc)\n",
    "\n",
    "y_test_enc = class_le.fit_transform(y_test)\n",
    "\n",
    "pred = Knn.predict(X_test, K=1,P=1)\n",
    "print(Knn.accuracy(y_test_enc,pred))\n",
    "\n",
    "pred = Knn.predict(X_test, K=1,P=2)\n",
    "print(Knn.accuracy(y_test_enc,pred)\n",
    "\n",
    "pred = Knn.predict(X_test, K=5,P=1)\n",
    "print(Knn.accuracy(y_test_enc,pred)\n",
    "      \n",
    "pred = Knn.predict(X_test, K=5,P=2)\n",
    "print(Knn.accuracy(y_test_enc,pred)\n",
    "\n",
    "pred = Knn.predict(X_test, K=10,P=1)\n",
    "print(Knn.accuracy(y_test_enc,pred)\n",
    "      \n",
    "pred = Knn.predict(X_test, K=10,P=2)\n",
    "print(Knn.accuracy(y_test_enc,pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-replacement",
   "metadata": {},
   "source": [
    "####  5. Zadanie 2 (2pkt): \n",
    "\n",
    "Napisz kod funkcji  <code>crossValidation(X,y, n = 10,  k=1,p=1  ):</code> obliczającą algorytm <code>knn </code> z n-krotną walidacją krzyżową."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def crossValidation(X,y, n = 10,  k=1,p=1  ):\n",
    "        '''\n",
    "        :param X: train data\n",
    "        :param y: encoded labels of train data\n",
    "        :param n: value for n-fold cross validation\n",
    "        :param k: k value  for knn\n",
    "        :param p: p value for l_p metric\n",
    "        :return:\n",
    "        '''\n",
    "\n",
    "\n",
    "        # BEGIN SOLUTION \n",
    "        \n",
    "        #END SOLUTION \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de3d84b-b8fb-418f-9491-df333e387ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res = crossValidation(X_train, y_train_enc,n=len(X_train), k=5,p=1)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85bb37f",
   "metadata": {},
   "source": [
    "#### 6.  Zadanie 3 (4pkt): \n",
    "\n",
    "Napisz kod klasy <code>LogisticRegression</code> implementującej klasyfikator <i>wieloklasowej regresji logistycznej</i> z funkcją <code>softmax()</code> (ze standardowymi nazwami dwóch kluczowych funkcji: <i>fit()</i>, <i>predict()</i>).  Zastosuj ten kod do pobranych danych (zbiór walidacyjny losujemy ze zbioru treningowego) - oblicz następujące charakterystyki modelu dla danych walidacyjnych oraz treningowych: dokładność (accuracy), precyzję (precision), czułość(recall) oraz F1 - dla poszczególnych klas oraz globalnie (zob. np. <a href=\"https://medium.com/synthesio-engineering/precision-accuracy-and-f1-score-for-multi-label-classification-34ac6bdfb404\">tu</a>).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e433be08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION (zad. 3)\n",
    "        \n",
    "#END SOLUTION "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8326ba",
   "metadata": {},
   "source": [
    "#### 7.  Zadanie 4 (1pkt): \n",
    "\n",
    "Oblicz ile danych z poszczególnych klas znajduje się po dodatniej/ujemnej stronie hiperpłaszczyzny klasyfikacyjnej dla danej klasy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f0a567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION (zad. 4)\n",
    "        \n",
    "#END SOLUTION "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0cb483",
   "metadata": {},
   "source": [
    "#### 8. Dwa uzupełnienia\n",
    "\n",
    "W pliku [lab1_add](lab1_add.ipynb) znajdują się  minimalne podstawy teoretyczne związane z konstrukcją funkcji kosztu oraz algorytmami optymalizacji."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
